% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={R Without Statistics},
  pdfauthor={David Keyes},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{R Without Statistics}
\author{David Keyes}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{about-the-book}{%
\chapter*{About the Book}\label{about-the-book}}
\addcontentsline{toc}{chapter}{About the Book}

This is the in-progress version of \emph{R Without Statistics}, a forthcoming book from \href{https://www.nostarch.com/}{No Starch Press}.

Since R was invented in 1993, it has become a widely used programming language for statistical analysis. From academia to the tech world and beyond, R is used for a wide range of statistical analysis.

R's ubiquity in the world of statistics leads many to assume that it is only useful to those who do complex statistical work. But as R has grown in popularity, the number of ways it can be used has grown as well. Today, R is used for:

\begin{itemize}
\item
  Data visualization
\item
  Map making
\item
  Sharing results through reports, slides, and websites
\item
  Automating processes
\item
  And much more!
\end{itemize}

The idea that R is only for statistical analysis is outdated and inaccurate. But, without a single book that demonstrates the power of R for non-statistical purposes, this perception persists.

\textbf{Enter R Without Statistics.}

R Without Statistics will show ways that R can be used beyond complex statistical analysis. Readers will learn about a range of uses for R, many of which they have likely never even considered.

Each chapter will, using a consistent format, cover one novel way of using R.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Readers will first be introduced to an R user who has done something novel and learn how using R in this way transformed their work.
\item
  Following this, there will be code samples that demonstrate exactly how the R user did the thing they are being profiled for.
\item
  Finally, there will be a summary, with lessons learned from this novel way of using R.
\end{enumerate}

Written by David Keyes, Founder and CEO of \href{https://rfortherestofus.com/}{R for the Rest of Us}, R Without Statistics will be published by \href{https://nostarch.com/}{No Starch Press}.

\hypertarget{part-introduction}{%
\part*{Introduction}\label{part-introduction}}
\addcontentsline{toc}{part}{Introduction}

\hypertarget{why-r-without-statistics}{%
\chapter{Why R Without Statistics?}\label{why-r-without-statistics}}

In early 2020, as COVID spread across the world, the government of New Zealand began planning their response. New Zealand had one major advantage that other countries lacked: being a remote island. This bought the country some time, but those working in the government knew that this head start would not last forever. Unless they quickly developed a plan to tackle COVID, New Zealand faced the same bleak future that other countries were already beginning to experience.

Of course, New Zealand did develop a plan to tackle COVID. As one of the few countries to largely keep COVID out in 2020 and 2021, New Zealand came to be seen as a model for how to respond to a global pandemic. While other countries were forced into repeated lockdowns due out of control COVID spread, life in New Zealand remained largely normal.

There are many reasons why New Zealand was so successful in tackling COVID. One of these was its use of R. Yes, R.

To understand how R helped New Zealand tackle COVID, let's go back a bit before the pandemic. In the years leading up to 2020, the Ministry of Health had begun to transition from SAS to R. So when COVID finally arrived on the shores of New Zealand in February 2020, they had the knowledge of R to use it as their main analysis and reporting tool.

But while people at Ministry of Health had R skills, they did not have a reporting system in place for a virus like COVID. Government officials and the general public needed to know how many cases there were in New Zealand and whether these cases were the result of international arrivals or community spread. And they didn't need to know just once. They needed to know every day. As Chris Knox, who led a team at the Ministry of Health focused on the COVID response in 2021 and 2022 told me,

\begin{quote}
Our general infectious disease reporting was not designed to be day to day. There were systems in place for reporting at the end of the year after everything had been tidied up.
\end{quote}

Creating a system to report daily on COVID data was no small feat. But because the Ministry of Health was already using R, they were able to leverage its power to make their reporting efficient.

The work did involve complex analysis. Case reports from across New Zealand would go into a database. The Ministry of Health team would then pull data to generate reports on cases throughout the country. But the reporting requirements were high. The team had to produce three daily reports:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A 9:00am summary of cases for high-level government officials.
\item
  An 11:00am situation report, complete with charts and tables, sent out to a wide range of government officials.
\item
  A 1:00pm public release of data on a Ministry of Health website.
\end{enumerate}

There were a few tricky steps along the way. The team had to make sure to not double count cases from previous days before separating out international arrival and community spread cases. But, again, these reports did not involve any complex statistics. They were, quite literally, counting cases.

So why am I discussing the New Zealand Ministry of Health's use of R, a tool designed for statistics, to generate reports where the most complex statistic is counting? I'm using this example to highlight the power of R because it shows things that R can do that go beyond complex statistics.

Specifically, the way that the New Zealand Ministry of Health used R shows the power of a code-based tool to make work more reproducible. Reproducible is really just a fancy way of saying that it was way, way easier to make those three daily reports using R than it would have been with a point-and-click tool like Excel.

Reproducibility is a fancy word that often hides its true value. I used to hear it and think it referred to scientists recreating each other's experiments in order to validate their results. But reproducibility really just means that code you write today can be run in another context. Sometimes this means someone else running your code. But sometimes it means you running the code you wrote last week. If last week's code works when you run it again this week, it's reproducible.

Getting previously written code to run day after day was key to the success of the New Zealand Ministry of Health team reporting on COVID cases. Producing the three daily reports manually would have quickly become untenable. But the process become viable because they wrote R code once and reused it day after day.

This isn't to say that the original code the team wrote never changed. Reporting requirements shifted with time and the team at the Ministry of Health had to adapt. Chris Knox told me that, ``at some points, the reporting requirements changed every day.'' Fortunately, they could tweak their R code and re-run it to produce reports that met the new reporting needs.

R was an important tool in enabling a small team to generate daily reports that were key to New Zealand's successful COVID response. It allowed a team of five or six people to produce reports much more efficiently than would otherwise have been possible. In spite of this, the intensity of the work led to some burnout. As team members left and new members joined, the Ministry of Health found that, again, R was key to their success. Because the team used code for their work, a new team member could read it, get themselves up to speed, and quickly begin contributing. The public nature of a code-based workflow stands in marked contrast the all-too-common situation where an outsized amount of institutional knowledge is found in one person's brain (let's call him Larry). If Larry leaves, the team's work grinds to a halt. R not only makes work more efficient, it also ensures long-term continuity. Chris Knox described how this played out at the New Zealand Ministry of Health:

\begin{quote}
Setting up Larry's analysis in Excel is usually faster than writing it up in code, but it's harder to onboard people into that type of environment. If you have to just sit down, run this code, look for error messages, almost anyone can do that.
\end{quote}

R also made collaboration among the Ministry of Health team easier. Being able to review code allowed team members to improve their collective work and learn from each other. To understand the true benefit this offers, consider again our friend Larry. If Larry works in Excel, say, so much of his work is hidden. Team members can't see the set of points-and-clicks that Larry carries out to do his analysis. His colleagues can't improve his work, and it's much harder for them to learn from Larry.

R often feels intimidating to newcomers, especially those new to coding. But what the story of New Zealand's COVID response shows us it that the power of R is huge. R was the main tool in a workflow that made it possible for a small team to produce regular reports every day for months on end. These reports didn't involve any kind of complex statistics -- they were literally counts of COVID cases. But the reproducibility of their R-based workflow is where the true value is found. As Chris Knox put it, ``trying to do what we did in a point-and-click environment is not possible.'' But with R, a small team helped a small island stay safe from COVID.

\hypertarget{how-i-came-to-use-r}{%
\section*{How I Came to Use R}\label{how-i-came-to-use-r}}
\addcontentsline{toc}{section}{How I Came to Use R}

My own relationship with R goes back to 2016. At the time, I was a consultant, helping non-profits, government agencies, and educational institutions to measure the effectiveness of their work is (a field known as \href{https://www.cdc.gov/evaluation/index.htm}{program evaluation}). A lot of my work involved conducting surveys, analyzing the resulting the data, and sharing the results with clients.

The work itself was fine, but the tools I was using to do it were getting on my nerves. Well, one tool really: Excel.

Now look, this is not a place for an anti-Excel rant. Excel is a fine tool that has empowered millions to work with data in ways they would never have been able to otherwise.

But I found Excel extremely tedious. The amount of pointing and clicking I had to do when working with the amount of data I had got old fast. Each time I would conduct a survey, I'd know that it would yield an avalanche of data and that my wrists would end up exhausted from hours of pointing and clicking.

No matter what I did, analyzing data and creating charts in Excel just involved a lot of repetitive pointing and clicking. Kind of like this:

\includegraphics[width=1\linewidth]{introduction_files/figure-latex/unnamed-chunk-2-1}

Endless pointing and clicking was just one problem I faced using Excel. Annoying though it was, it didn't affect the quality of my work. Or so I thought until I recalled a project I had worked on a few years earlier.

In this project, I was looking at which school districts in the state of Oregon have \href{https://oregonstate.app.box.com/s/83g5sjdm88xgqdxfze0ri7qo4uff5sj7}{outdoor education programs known as Outdoor School}. As part of this project, I had to download data on all school districts throughout Oregon, filter to only include relevant districts with fifth or sixth graders (the ages Outdoor School takes place), and then merge this with data that I collected as part of a survey I conducted.

I did the work in Excel, using a lot of (you guessed it!) pointing and clicking. The problem came when I was almost done with the project. I've blocked the details from my memory (as I've done with most things Excel-related), but what I do recall is not being 100\% certain I had done my filtering and joining correctly. And, to make it worse, I had no way to check my work. Why? Because all my pointing and clicking was ephemeral, gone in the ether as soon as I had completed it.

I finished the Outdoor School project and submitted my report. The work I did was \emph{probably} accurate, but maybe it wasn't?

Now, you may be reading this thinking: why didn't you write down the steps you used in Excel so you could retrace them later? Sure, I could (and should) have done that. But let's be honest: most of us don't.

We're human. We're lazy. We all make mistakes. And without a straightforward way to audit your work (and keeping a list of all of your Excel points and clicks in a separate document is not, in my view, straightforward), mistakes will happen. If you've used Excel to work with data, I guarantee you've made a mistake, just like me.

The good news is that it's okay. There's a solution. And that solution is R.

If I were to redo that project on Outdoor School with R, here's what I'd do differently. Rather than watching points and clicks disappear into the ether, I'd write code that would serve as a record of everything I did. This code would:

Download data on all school districts:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Download the data directly from the Oregon Department of Education website}
\FunctionTok{download.file}\NormalTok{(}\AttributeTok{url =} \StringTok{"https://www.oregon.gov/ode/educator{-}resources/assessment/Documents/TestResults2019/pagr\_schools\_ela\_tot\_raceethnicity\_1819.xlsx"}\NormalTok{,}
              \AttributeTok{destfile =}\NormalTok{ here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data/pagr\_schools\_ela\_tot\_raceethnicity\_1819.xlsx"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Import the downloaded data and use the \textasciigrave{}clean\_names()\textasciigrave{} function to make the variable names easy to work with}
\NormalTok{oregon\_schools }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data/pagr\_schools\_ela\_tot\_raceethnicity\_1819.xlsx"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{clean\_names}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Filter to only include districts with fifth or sixth graders:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Start with the oregon\_schools data from above}
\NormalTok{oregon\_schools\_fifth\_sixth\_grade }\OtherTok{\textless{}{-}}\NormalTok{ oregon\_schools }\SpecialCharTok{\%\textgreater{}\%} 
  
  \CommentTok{\# Only keep schools with fifth or sixth graders}
  \FunctionTok{filter}\NormalTok{(grade\_level }\SpecialCharTok{==} \StringTok{"Grade 5"} \SpecialCharTok{|}\NormalTok{ grade\_level }\SpecialCharTok{==} \StringTok{"Grade 6"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  
  \CommentTok{\# Only keep the variables we need}
  \FunctionTok{select}\NormalTok{(district\_id}\SpecialCharTok{:}\NormalTok{school) }\SpecialCharTok{\%\textgreater{}\%} 
  
  \CommentTok{\# There are multiple observations of the same school, just keep one of each}
  \FunctionTok{distinct}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Join the filtered data on school districts with my survey data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use the school\_id variable to join the survey data with the oregon\_schools\_fifth\_sixth\_grade from above }
\FunctionTok{left\_join}\NormalTok{(survey\_data, oregon\_schools\_fifth\_sixth\_grade,}
          \AttributeTok{by =} \StringTok{"school\_id"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{code-is-just-a-written-record-of-your-work}{%
\section*{Code is Just a Written Record of Your Work}\label{code-is-just-a-written-record-of-your-work}}
\addcontentsline{toc}{section}{Code is Just a Written Record of Your Work}

Code can be scary. Having to write code is one of the reasons many people never learn R. But code is just a list of things you want to do to your data. It may be written in a hard-to-parse syntax (though it gets easier over time), but it's just a set of steps. The same steps that we should write out when we're working in Excel, but never do. Rather than having a separate document with my steps written down, I can see my steps in my code. See that line that says filter? Guess what it's doing? Yep, it's filtering!

If I had done things this way when working on the Outdoor School project, I could have looked back at any point to make sure what I thought was happening to my data was in fact happening. That nagging sensation I had near the end of the project that I may have made a mistake in one of my early points or clicks? It never would have come up because I could have just reviewed my code to make sure it did what I thought it did. And if it didn't, I could rewrite and rerun my code to get updated results.

Using R won't mean you'll never make mistakes again (trust me, you will). But it will mean that you can easily spot your mistakes, make changes, and fix any issues.

I started learning R to avoid tedious pointing and clicking. But what I found was that R improved my work in ways I never expected. It's not just that my wrists are less tired. I now have more confidence that my work is accurate.

\hypertarget{r-can-do-much-more-than-just-statistics}{%
\section*{R Can Do Much More Than Just Statistics}\label{r-can-do-much-more-than-just-statistics}}
\addcontentsline{toc}{section}{R Can Do Much More Than Just Statistics}

I used to feel ashamed about the way I use R. I use R, a tool for statistical analysis, but I don't use it for complex statistical analysis. I don't do machine learning. I don't know what a random forest is. I've never run a regression in R. \href{https://rfortherestofus.com/2018/12/descriptive-stats-r/}{The only statistics I do in R are descriptive statistics}: counts, sums, averages, that type of thing.

For a long time, I felt like I wasn't a ``real'' R user. Real R users, in my mind, used R for hardcore stats. I ``only'' used R for descriptive stats. I sometimes felt like I was using a souped up sports car to drive 20 miles an hour to the grocery store. What was the point in using a high-powered machine like R to do ``simple'' things?

Eventually, I realized that this framing misses the point. \href{https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2018.01169.x}{R started out as a tool created by statisticians for other statisticians}. But, over a quarter century since its creation, R can do much more than statistical analysis.

My own use of R is an example of this. I think of my work with R in three buckets:

\textbf{Illuminate} through data visualization: making graphs, maps, and tables that look good and share results effectively.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/psc-sample} \caption{Sample pages from a report on housing in demographics in Hartford, Connecticut}\label{fig:unnamed-chunk-7}
\end{figure}

\textbf{Communicate} by doing reporting with R Markdown: moving away from the inefficient and error-prone workflow of using multiple tools to create reports by instead doing it all in the one tool that I think of as \href{https://rfortherestofus.com/2019/03/r-killer-feature-rmarkdown/}{R's killer feature}.

A typical workflow looks like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Analyze data in SPSS
\item
  Copy data into Excel to make graphs
\item
  Copy graphs into Word and write your report
\end{enumerate}

\begin{figure}
\includegraphics[width=1\linewidth]{assets/non-r-workflow} \caption{A typical non-R workflow}\label{fig:unnamed-chunk-8}
\end{figure}

What happens, though, if you forget to include some data at step one? Or if you need to produce the same report with new data? You have to manually repeat the steps. It's painful.

With R, things are different. You do your data analysis, make your graphs, and write your report all in one tool (RStudio). Once you like what you have, you export it to a format (like Word) to share.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/r-workflow} \caption{An R-based workflow}\label{fig:unnamed-chunk-9}
\end{figure}

And, best of all, if you forget to include data or need to produce your report again with new data, just re-run your code and you end up with a new Word document, ready to share.

\textbf{Automate} tedious practices: Remember my Excel-burdened wrists? Since I moved to R I've found so many ways to automate tedious practices, from gathering data directly from the U.S. Census Bureau to pulling survey results in from Google Sheets and more.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/google-sheets-workflow} \caption{An workflow that brings data from Google Sheets directly into R}\label{fig:unnamed-chunk-10}
\end{figure}

The main reason I've come to accept that my way of using R is as valid as anyone else's has come through realizing that more ``sophisticated'' R users are doing many of the same things I am. Sure, they may also be doing statistical analyses that I am not, but everyone who uses R needs to illuminate, communicate, and automate.

Canadian statistician Sharla Gelfand has \href{https://twitter.com/sharlagelfand/status/1135962094938009601}{talked about how they used R to automate an annual report on nursing registration exams in Ontario}. Sharla told me in 2019 that, despite being a statistician, \href{https://rfortherestofus.com/2019/09/my-r-journey-sharla-gelfand/}{the most statistical thing they did was calculating a median}.

Take a look at the R community on Twitter (where users congregate under the \#rstats hashtag). What gets people most excited is not the latest complex statistical analysis. \href{https://twitter.com/dgkeyes/status/1479473689225695234}{It's tips and tricks on the foundational work that everyone who uses R needs to do}. Things like:

\begin{itemize}
\item
  \href{https://twitter.com/CedScherer/status/1220843943224578050}{Making illuminating data visualizations} as part of the \href{https://github.com/rfordatascience/tidytuesday}{Tidy Tuesday project}.
\item
  \href{https://twitter.com/spcanelon/status/1424932510065209348}{Video tutorials on how to communicate through effective presentations using R}.
\item
  \href{https://twitter.com/WeAreRLadies/status/1228049014601342976}{Love letters to the \texttt{clean\_names()} function from the \texttt{janitor} package, which automates the process of making messy variable names easy to work with in R}.
\end{itemize}

No matter what else you do in R, you have to \textbf{illuminate} your findings and \textbf{communicate} your results. And, the more you use R, the more you'll find yourself wanting to \textbf{automate} things you used to do manually (your wrists will thank you). I realize now that the things that I use R for \emph{are} the things that everyone uses R for. R was created for statistics. But today people are just as likely to use R without statistics.

Ten years ago, if you had told me I'd be writing a book on R, I'd have laughed. As someone with an extremely non-quantitative background (I did a PhD in anthropology) who never used R in graduate school, I never thought I'd be in a position to teach people about R. But here we are. And I'm excited to be your guide on this journey through the ways you can use R without statistics.

If I only used R for the things I thought ``real'' R users used it for, I wouldn't be writing this book. But, instead of slogging away in the world of complex statistical analysis, far outside of my area of expertise, I have found a place for myself in the world of R. Expanding my conception of what this tool can do has enabled me to get more out of R.

And here's the thing: if I, a qualitatively-trained anthropologist whose most complex statistical use for R is calculating averages, can find value in R, so can you. No matter what your background or what you think about R right now, using R without statistics can transform how you work in the future.

\hypertarget{how-this-book-works}{%
\section*{How This Book Works}\label{how-this-book-works}}
\addcontentsline{toc}{section}{How This Book Works}

This book shows the many ways that people use R without statistics. It's not comprehensive (trust me, there are many ways people use R not covered here). But I hope the ideas inspire you to think about learning to use R (if you're not yet an R user) or (if you are already on board the R train) learning to use R in ways you hadn't previously considered.

Each chapter focuses on one novel use of R. You'll begin by learning about a user or users who have transformed their work using R. You'll learn about a problem they had and how R helped them to solve it.We'll dive into their code, analyzing it line by line in order to help you understand how they used R. Each chapter will conclude with a short summary, offering lessons you can take from this novel way of using R.

I've tried to choose topics for each chapter that are relevant to a broad audience. Things like data visualization, report generation, and creating your own functions are things that anyone, no matter what you use R for, will find valuable.

There are some great topics that I thought to include but were just too narrow in their focus (for example, \href{https://blog.djnavarro.net/posts/2021-10-19_rtistry-posts/}{the world of generative art made with R}. If, at any point while you're reading this book, you think, ``why didn't David include X topic?'' please know that X might be a great topic, but I can only cover so much. The fact that you're able to come up with other ideas for things that R can do is a) fantastic and b) a further display of R's versatility. I eagerly await your follow-up book highlighting the myriad other things R can do that I am unable to cover in this book!

\hypertarget{a-favor-to-ask}{%
\section*{A Favor to Ask}\label{a-favor-to-ask}}
\addcontentsline{toc}{section}{A Favor to Ask}

Pedants of the world (as one of you, I come in peace), I have a favor to ask.

This book is called R Without Statistics. But it's not meant to be taken literally. Of course it's true that if you're making a graph you're using statistics. So, before you start typing an angry email to me, please know that R Without Statistics is a mindset rather than a literal statement.

We're all using R with statistics already. Let's also learn to use R without statistics.

\hypertarget{part-illuminate}{%
\part*{Illuminate}\label{part-illuminate}}
\addcontentsline{toc}{part}{Illuminate}

\hypertarget{data-viz-chapter}{%
\chapter{Principles of Data Visualization}\label{data-viz-chapter}}

In the spring of 2021, nearly all of the American West was in a drought. By April of that year, officials in Southern California had declared a water emergency, citing unprecedented conditions.

This wouldn't have come as news to those living in California and other Western states. Drought conditions like those in the West in 2021 are becoming increasingly common. Yet communicating the extent of problem remains difficult. How can we show the data in a way that accurately represents it while making it compelling enough to get people to take notice?
This was the challenge that data-visualization designers Cédric Scherer and Georgios Karamanis took on in the fall of 2021. Working with the magazine \emph{Scientific American} to create a data visualization of drought conditions over the last two decades in the United States, they turned to the ggplot2 package to transform what could have been dry data (pardon the pun) into a visually arresting and impactful graph.

In this chapter, I show how Scherer and Karamanis made their data visualization. We begin by looking at why the data visualization is effective. Next, we talk about the grammar of graphics, a theory to make sense of graphs that underlies the ggplot2 package that Scherer, Karamanis, and millions of others use to make data visualization. We then return to the drought graph, recreating it step-by-step using ggplot2. In the process, we pull out some key principles of high-quality data visualization that you can use to improve your own work.

\hypertarget{the-drought-visualization}{%
\section*{The Drought Visualization}\label{the-drought-visualization}}
\addcontentsline{toc}{section}{The Drought Visualization}

There was nothing unique about the data that Scherer and Karamanis used. Other news organizations had relied on the same data, from the National Drought Center, in their stories. But Scherer and Karamanis visualized it in a way that it both grabs attention and communicates the scale of the phenomenon. Figure \ref{fig:final-viz} shows a section of the final visualization. Showing four regions over the last two decades, the increase in drought conditions, especially in California and the Southwest, is made apparent.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/final-viz-1} \caption{A section of the final drought visualization. If you’re incredibly eagle-eyed, you’ll see a few minor elements that differ from the version published in *Scientific American*. These are things I had to change to make the plots fit in this book (for example, altering the text size and putting legend text on two rows) or things that *Scientific American* added in post-production (such as annotations).}\label{fig:final-viz}
\end{figure}

To understand why this visualization is effective, let's break it down into pieces. At the broadest level, the data visualization is notable for its minimalist aesthetic. There are, for example, no grid lines and few text labels, as well as little text along the axes. What Scherer and Karamanis have done is remove what statistician Edward Tufte, in his 1983 book \emph{The Visual Display of Quantitative Information}, calls \emph{chartjunk}. Tufte wrote (and researchers, as well as data visualization designers since, have generally agreed) that extraneous elements often hinder, rather than help, our understanding of charts.

Need proof that Scherer and Karamanis's decluttered graph is better than the alternative? Figure \ref{fig:cluttered-viz} shows a version with a few small tweaks to the code to include grid lines and text labels on axes. Prepare yourself for clutter!

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/cluttered-viz-1} \caption{The cluttered version of the drought visualization}\label{fig:cluttered-viz}
\end{figure}

Again, it's not just that this cluttered version looks worse. The clutter actively inhibits understanding. Rather than focus on overall drought patterns (the point of the graph), our brain gets stuck reading repetitive and unnecessary axis text.

One of the best ways to reduce clutter is to break a single chart into what are known as \emph{small multiples}. When we look closely at the data visualization, we see that it is not one chart but actually a set of charts. Each rectangle represents one region in one year. If we filter to show the Southwest region in 2003 and add axis titles, we can see in Figure \ref{fig:viz-sw-2003} that the x axis shows the week while the y axis shows the percentage of that region at different drought levels.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/viz-sw-2003-1} \caption{A drought visualization for the Southwest in 2003}\label{fig:viz-sw-2003}
\end{figure}

Zooming in on a single region in a single year also makes the color choices more obvious. The lightest bars show the percentage of the region that is abnormally dry while the darkest bars show the percentage in exceptional drought conditions. These colors, as we'll see shortly, are intentionally chosen to make differences in the drought levels visible to all readers.
When I asked Scherer and Karamanis to speak with me about this data visualization, they initially told me that the code for this piece might be too simple to highlight the power of R for data visualization. No, I told them, I want to speak with you precisely because the code is not super complex. The fact that Scherer and Karamanis were able to produce this complex graph with relatively simple code shows the power of R for data visualization. And it is possible \emph{because} of a theory called the grammar of graphics.

\hypertarget{the-grammar-of-graphics}{%
\section*{The Grammar of Graphics}\label{the-grammar-of-graphics}}
\addcontentsline{toc}{section}{The Grammar of Graphics}

If you've used Excel to make graphs, you're probably familiar with the menu shown in Figure \ref{fig:excel-chart-chooser}. When working in Excel, your graph-making journey begins by selecting the type of graph you want to make. Want a bar chart? Click the bar chart icon. Want a line chart? Click the line chart icon.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/excel-chart-chooser} \caption{The Excel chart chooser menu}\label{fig:excel-chart-chooser}
\end{figure}

f you've only ever made data visualization in Excel, this first step may seem so obvious that you've never even considered the process of creating data visualization in any other way. But there are different models for thinking about graphs. Rather than conceptualizing graphs types as being distinct, we can recognize the things that they have in common and use these commonalities as the starting point for making them.

This approach to thinking about graphs comes from the late statistician Leland Wilkinson. For years, Wilkinson thought deeply about what data visualization is and how we can describe it. In 1999, he published a book called \emph{The Grammar of Graphics} that sought to develop a consistent way of describing all graphs. In it, Wilkinson argued that we should think of plots not as distinct types à la Excel, but as following a grammar that we can use to describe \emph{any} plot. Just as English grammar tells us that a noun is typically followed by a verb (which is why ``he goes'' works, while the opposite, ``goes he,'' does not), knowledge of the grammar of graphics allows us to understand why certain graph types ``work.''

Thinking about data visualization through the lens of the grammar of graphics allow us to see, for example, that graphs typically have some data that is plotted on the x axis and other data that is plotted on the y axis. This is the case no matter whether the graph is a bar chart or a line chart, for example. Consider Figure \ref{fig:bar-line-chart}, which shows two charts that use identical data on life expectancy in Afghanistan.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/bar-line-chart-1} \caption{A bar chart and a line chart showing identical data on Afghanistan life expectancy}\label{fig:bar-line-chart}
\end{figure}

While they look different (and would, to the Excel user, be different types of graphs), Wilkinson's grammar of graphics allows us to see their similarities. (Incidentally, Wilkinson's feelings on graph-making tools like Excel became clear when he wrote that ``most charting packages channel user requests into a rigid array of chart types.'')

When Wilkinson wrote his book, no data visualization tool could implement his grammar of graphics. This would change in 2010, when Hadley Wickham announced the ggplot2 package for R in an article titled ``A Layered Grammar of Graphics.'' By providing the tools to implement Wilkinson's ideas, ggplot2 would come to revolutionize the world of data visualization.

\hypertarget{working-with-ggplot2}{%
\section*{Working With ggplot2}\label{working-with-ggplot2}}
\addcontentsline{toc}{section}{Working With ggplot2}

The ggplot2 R package (which I, like nearly everyone in the data visualization world, will refer to simply as ggplot) relies on the idea of plots having multiple layers. Let's walk through some of the most important layers. We'll begin by selecting variables to map to aesthetic properties. Then we'll choose a geometric object to use to represent our data. Next we'll change the aesthetic properties of our chart (the color scheme, for example) using a \texttt{scale\_} function. And finally we'll use a \texttt{theme\_} function to set the overall look-and-feel of our plot.

\hypertarget{the-first-layer-mapping-data-to-aesthetic-properties}{%
\subsection*{The First Layer: Mapping Data to Aesthetic Properties}\label{the-first-layer-mapping-data-to-aesthetic-properties}}
\addcontentsline{toc}{subsection}{The First Layer: Mapping Data to Aesthetic Properties}

When creating a graph with ggplot, we begin by mapping data to aesthetic properties. All this really means is that we use things like the x or y axis, color, and size (the so-called aesthetic properties) to represent variables. To make this concrete, we'll use the data on life expectancy in Afghanistan, introduced in the previous section, to generate a plot. We can create this data with the following code:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}

\NormalTok{gapminder\_10\_rows }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"https://data.rwithoutstatistics.com/gapminder\_10\_rows.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Here's what the \texttt{gapminder\_10\_rows} data frame looks like:

\begin{verbatim}
#> # A tibble: 10 x 6
#>    country     continent  year lifeExp      pop gdpPercap
#>    <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>
#>  1 Afghanistan Asia       1952    28.8  8425333      779.
#>  2 Afghanistan Asia       1957    30.3  9240934      821.
#>  3 Afghanistan Asia       1962    32.0 10267083      853.
#>  4 Afghanistan Asia       1967    34.0 11537966      836.
#>  5 Afghanistan Asia       1972    36.1 13079460      740.
#>  6 Afghanistan Asia       1977    38.4 14880372      786.
#>  7 Afghanistan Asia       1982    39.9 12881816      978.
#>  8 Afghanistan Asia       1987    40.8 13867957      852.
#>  9 Afghanistan Asia       1992    41.7 16317921      649.
#> 10 Afghanistan Asia       1997    41.8 22227415      635.
\end{verbatim}

If we want to make a chart with ggplot, we need to first decide which variable to put on the x axis and which to put on the y axis. Let's say we want to show life expectancy over time. That means we would use the variable \texttt{year} on the x axis and the variable \texttt{lifeExp} on the y axis. To do so, we begin by using the \texttt{ggplot()} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder\_10\_rows,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ year,}
    \AttributeTok{y =}\NormalTok{ lifeExp}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Within this function, we tell R that we're using the data frame \texttt{gapminder\_10\_rows}. This is the filtered version we created from the full \texttt{gapminder} data frame, which includes over 1,700 rows of data. The line following this tells R to use \texttt{year} on the x axis and \texttt{lifeExp} on the y axis. When we run the code, what we get in Figure \ref{fig:blank-ggplot} doesn't look like much.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/blank-ggplot-1} \caption{A blank chart}\label{fig:blank-ggplot}
\end{figure}

But, if you look closely, you can see the beginnings of a plot. Remember that x axis using \texttt{year}? There it is! And \texttt{lifeExp} on the y axis? Yup, it's there too. I can also see that the values on the x and y axes match up to our data. In the \texttt{gapminder\_10\_rows} data frame, the first year is 1952 and the last year is 1997. The range of the x axis seems to have been created with this data, which goes from 1952 to 1997, in mind (spoiler: it was). And \texttt{lifeExp}, which goes from about 28 to about 42 will fit nicely on our y axis.

\hypertarget{the-second-layer-choosing-the-geoms}{%
\subsection*{The Second Layer: Choosing the geoms}\label{the-second-layer-choosing-the-geoms}}
\addcontentsline{toc}{subsection}{The Second Layer: Choosing the geoms}

Axes are nice, but we're missing any type of visual representation of the data. To get this, we need to add the next layer in ggplot: geoms. Short for geometric objects, geoms are functions that provide different ways of representing data. For example, if we want to add points, we use \texttt{geom\_point()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder\_10\_rows,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ year,}
    \AttributeTok{y =}\NormalTok{ lifeExp}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Now, in Figure \ref{fig:gapminder-points-plot}, we see that people in 1952 had a life expectancy of about 28 and that this value rose through every year in our data.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/gapminder-points-plot-1} \caption{The same chart but with points added}\label{fig:gapminder-points-plot}
\end{figure}

Let's say we change our mind and want to make a line chart instead. Well, all we have to do is replace \texttt{geom\_point()} with \texttt{geom\_line()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder\_10\_rows,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ year,}
    \AttributeTok{y =}\NormalTok{ lifeExp}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:gapminder-line-plot} shows the result.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/gapminder-line-plot-1} \caption{The data as a line chart}\label{fig:gapminder-line-plot}
\end{figure}

To really get fancy, what if we add both \texttt{geom\_point()} and \texttt{geom\_line()}?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder\_10\_rows,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ year,}
    \AttributeTok{y =}\NormalTok{ lifeExp}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This code generates a line chart with points, as seen in Figure \ref{fig:gapminder-points-line-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/gapminder-points-line-plot-1} \caption{The data with points and a line}\label{fig:gapminder-points-line-plot}
\end{figure}

We can extend this idea further, as seen in Figure \ref{fig:gapminder-bar-plot}, swapping in \texttt{geom\_col()} to create a bar chart:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder\_10\_rows,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ year,}
    \AttributeTok{y =}\NormalTok{ lifeExp}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Note that the y axis range has been automatically updated, going from 0 to 40 to account for the different geom.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/gapminder-bar-plot-1} \caption{The data as a bar chart}\label{fig:gapminder-bar-plot}
\end{figure}

As you can see, the difference between a line chart and a bar chart isn't as great as the Excel chart-type picker might have us think. Both can have the same aesthetic properties (namely, putting years on the x axis and life expectancies on the y axis). They simply use different geometric objects to visually represent the data.

\hypertarget{the-third-layer-altering-aesthetic-properties}{%
\subsection*{The Third Layer: Altering Aesthetic Properties}\label{the-third-layer-altering-aesthetic-properties}}
\addcontentsline{toc}{subsection}{The Third Layer: Altering Aesthetic Properties}

Before we return to the drought data visualization, let's look at a few additional layers that can help us can alter our bar chart. Say we want to change the color of our bars. In the grammar of graphics approach to chart-making, this means mapping some variable to the aesthetic property of \texttt{fill}. (Slightly confusingly, the aesthetic property of \texttt{color} would, for a bar chart, change only the outline of each bar). In the same way that we mapped \texttt{year} to the x axis and y to \texttt{lifeExp}, we can also map fill to a variable, such as year:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder\_10\_rows,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ year,}
    \AttributeTok{y =}\NormalTok{ lifeExp,}
    \AttributeTok{fill =}\NormalTok{ year}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

The result is shown in Figure \ref{fig:gapminder-bar-colors-plot}. We see now that, for earlier years, the fill is darker, while for later years, it is lighter (the legend, added to the right of our plot, shows this).

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/gapminder-bar-colors-plot-1} \caption{The same chart, now with added colors}\label{fig:gapminder-bar-colors-plot}
\end{figure}

What if we want to change the fill colors? For that, we use a new \emph{scale layer}. In this case, I'll use the \texttt{scale\_fill\_viridis\_c()} function. The c at the end of the function name refers to the fact that the data is continuous, meaning it can take any numeric value:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder\_10\_rows,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ year,}
    \AttributeTok{y =}\NormalTok{ lifeExp,}
    \AttributeTok{fill =}\NormalTok{ year}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This function changes the default palette to one that is colorblind-friendly and prints well in grayscale. The \texttt{scale\_fill\_viridis\_c()} function is just one of many that start with \texttt{scale\_} and can alter the fill scale.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/gapminder-viridis-plot-1} \caption{The same chart with a colorblind-friendly palette}\label{fig:gapminder-viridis-plot}
\end{figure}

\hypertarget{the-fourth-layer-setting-a-theme}{%
\subsection*{The Fourth Layer: Setting a Theme}\label{the-fourth-layer-setting-a-theme}}
\addcontentsline{toc}{subsection}{The Fourth Layer: Setting a Theme}

A final layer we'll look at is the theme layer. This layer allows us to change the overall look-and-feel of plots (plot backgrounds, grid lines, and so on). Just as there are a number of \texttt{scale\_} functions, there are also a number of functions that start with \texttt{theme\_.} Here, we've added \texttt{theme\_minimal()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder\_10\_rows,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ year,}
    \AttributeTok{y =}\NormalTok{ lifeExp,}
    \AttributeTok{fill =}\NormalTok{ year}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Notice in Figure \ref{fig:gapminder-theme-plot} that this theme starts to declutter our plot.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/gapminder-theme-plot-1} \caption{The same chart with `theme_minimal()` added}\label{fig:gapminder-theme-plot}
\end{figure}

We've now seen why Hadley Wickham described the ggplot2 package as using a layered grammar of graphics. It implements Wilkinson's theory through the creation of multiple layers. First, we select variables to map to aesthetic properties, such as x or y axes, color, and fill. Second, we choose the geometric object (or geom) we want to use to represent our data. Third, if we want to change aesthetic properties (for example, to use a different palette), we do this with a \texttt{scale\_} function. Fourth, we use a \texttt{theme\_} function to set the overall look-and-feel of our plot.

We could improve the plot we've been working on in many ways. But rather than adding to an ugly plot, let's instead return to the drought data visualization by Cédric Scherer and Georgios Karamanis. Going through their code will show us some familiar aspects of ggplot and reveal tips on how to make high-quality data visualization with R.

\hypertarget{recreating-the-drought-visualization-with-ggplot}{%
\section*{Recreating the Drought Visualization with ggplot}\label{recreating-the-drought-visualization-with-ggplot}}
\addcontentsline{toc}{section}{Recreating the Drought Visualization with ggplot}

The drought visualization code relies on a combination of ggplot fundamentals and some less-well-known tweaks that make it really shine. In order to understand how Scherer and Karamanis made their data visualization, we'll start out with a simplified version of their code. We'll build it up layer by layer, adding elements as we go.

First, let's import the data. Scherer and Karamanis do this with the \texttt{import()} function from the \texttt{rio} package. This function is helpful because the data they are working with is in JSON format, which can be complicated to work with. The \texttt{rio} package simplifies it into just one line:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rio)}

\NormalTok{dm\_perc\_cat\_hubs\_raw }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"https://data.rwithoutstatistics.com/dm\_export\_20000101\_20210909\_perc\_cat\_hubs.json"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{plotting-one-region-and-year}{%
\subsection*{Plotting One Region and Year}\label{plotting-one-region-and-year}}
\addcontentsline{toc}{subsection}{Plotting One Region and Year}

Let's start by looking at just one region (the Southwest) in one year (2003). First, we filter our data and save it as a new object called \texttt{southwest\_2003}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{southwest\_2003 }\OtherTok{\textless{}{-}}\NormalTok{ dm\_perc\_cat\_hubs }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(hub }\SpecialCharTok{==} \StringTok{"Southwest"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{2003}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can take a look at this object to see the variables we have to work with:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{southwest\_2003 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 10 x 7}
\CommentTok{\#\textgreater{}    date       hub       category perce\textasciitilde{}1  year  week max\_w\textasciitilde{}2}
\CommentTok{\#\textgreater{}    \textless{}date\textgreater{}     \textless{}fct\textgreater{}     \textless{}fct\textgreater{}      \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 2003{-}12{-}30 Southwest D0        0.0718  2003    52      52}
\CommentTok{\#\textgreater{}  2 2003{-}12{-}30 Southwest D1        0.0828  2003    52      52}
\CommentTok{\#\textgreater{}  3 2003{-}12{-}30 Southwest D2        0.269   2003    52      52}
\CommentTok{\#\textgreater{}  4 2003{-}12{-}30 Southwest D3        0.311   2003    52      52}
\CommentTok{\#\textgreater{}  5 2003{-}12{-}30 Southwest D4        0.0796  2003    52      52}
\CommentTok{\#\textgreater{}  6 2003{-}12{-}23 Southwest D0        0.0823  2003    51      52}
\CommentTok{\#\textgreater{}  7 2003{-}12{-}23 Southwest D1        0.131   2003    51      52}
\CommentTok{\#\textgreater{}  8 2003{-}12{-}23 Southwest D2        0.189   2003    51      52}
\CommentTok{\#\textgreater{}  9 2003{-}12{-}23 Southwest D3        0.382   2003    51      52}
\CommentTok{\#\textgreater{} 10 2003{-}12{-}23 Southwest D4        0.0828  2003    51      52}
\CommentTok{\#\textgreater{} \# ... with abbreviated variable names 1: percentage,}
\CommentTok{\#\textgreater{} \#   2: max\_week}
\end{Highlighting}
\end{Shaded}

The \texttt{date} variable represents the start date of the week in which the observation took place. The \texttt{hub} variable is the region, and \texttt{category} is level of drought (a value of \texttt{D0} indicates the lowest level of drought, while \texttt{D5} indicates the highest level). The \texttt{percentage} variable is the percentage of that region that is in that drought category, ranging from \texttt{0} to \texttt{1}. The \texttt{year} and \texttt{week} variables are the observation year and week number (beginning with week 1). The \texttt{max\_week} variable is the maximum number of weeks in a given year.

Now we can use this \texttt{southwest\_2003} object for our plotting:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ southwest\_2003,}
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ week,}
    \AttributeTok{y =}\NormalTok{ percentage,}
    \AttributeTok{fill =}\NormalTok{ category}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

In the \texttt{ggplot()} function, we tell R to put \texttt{week} on the x axis and \texttt{percentage} on the y axis. We also use the \texttt{category} variable for our \texttt{fill} color. We then use \texttt{geom\_col()} to create a bar chart in which the fill color of each bar represents the percentage of the region in a single week at each drought level. You can see the result in in \ref{fig:southwest-2003-no-style-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/southwest-2003-no-style-plot-1} \caption{One year and region of the drought visualization}\label{fig:southwest-2003-no-style-plot}
\end{figure}

The colors don't match the final version of the plot, but we can start to see the outlines of Scherer and Karamanis's data visualization.

\hypertarget{changing-aesthetic-properties}{%
\subsection*{Changing Aesthetic Properties}\label{changing-aesthetic-properties}}
\addcontentsline{toc}{subsection}{Changing Aesthetic Properties}

Scherer and Karamanis next selected different \texttt{fill} colors for their bars. To do so, they used the \texttt{scale\_fill\_viridis\_d()} function. The \emph{d} here means that the data to which the fill scale is being applied has discrete categories, called D0, D1, D2, D3, D4, and D5:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ southwest\_2003,}
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ week,}
    \AttributeTok{y =}\NormalTok{ percentage,}
    \AttributeTok{fill =}\NormalTok{ category}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_d}\NormalTok{(}
    \AttributeTok{option =} \StringTok{"rocket"}\NormalTok{,}
    \AttributeTok{direction =} \SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

They used the argument \texttt{option\ =\ "rocket"} to select the rocket palette (the function has several other palettes). Then they used the \texttt{direction\ =\ -1} argument to reverse the order of fill colors so that darker colors mean higher drought conditions.
Scherer and Karamanis also tweaked the appearance of the x and y axes:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ southwest\_2003,}
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ week,}
    \AttributeTok{y =}\NormalTok{ percentage,}
    \AttributeTok{fill =}\NormalTok{ category}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_d}\NormalTok{(}
    \AttributeTok{option =} \StringTok{"rocket"}\NormalTok{,}
    \AttributeTok{direction =} \SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{name =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{guide =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{name =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{labels =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{position =} \StringTok{"right"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

On the x axis, they removed both the axis title (``week'') using \texttt{name\ =\ NULL} and the 0--50 text with \texttt{guide\ =\ "none"}. On the y axis, they removed the title and text showing percentages using \texttt{labels\ =\ NULL}, which functionally does the same thing as \texttt{guide\ =\ "none"}. They also moved the axis lines themselves to the right side using \texttt{position\ =\ "right"}. These axis lines are only apparent as tick marks at this point but will become more visible later. Figure \ref{fig:southwest-2003-xy-scales-plot} shows the result of these tweaks.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/southwest-2003-xy-scales-plot-1} \caption{One year and region of the drought visualization with adjustments to the x and y axes}\label{fig:southwest-2003-xy-scales-plot}
\end{figure}

Up to this point, we've focused on one of the single plots that make up the larger data visualization. But the final product that Scherer and Karamanis made is actually 176 plots visualizing 22 years and eight regions. Let's discuss the ggplot feature they used to create all of these plots.

\hypertarget{faceting-the-plot}{%
\subsection*{Faceting the Plot}\label{faceting-the-plot}}
\addcontentsline{toc}{subsection}{Faceting the Plot}

One of the most useful features of ggplot is what's known as \emph{faceting} (or, more commonly in the data visualization world, \emph{small multiples}). Faceting takes a single plot and makes it into multiple plots using a variable (think: a line chart showing life expectancy by country over time, but instead of multiple lines on one plot, we get multiple plots with one line per plot). With the \texttt{facet\_grid()} function, we can select which variable to put in rows and which to put in columns of our faceted plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dm\_perc\_cat\_hubs }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(hub }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"Northwest"}\NormalTok{, }
                    \StringTok{"California"}\NormalTok{, }
                    \StringTok{"Southwest"}\NormalTok{, }
                    \StringTok{"Northern Plains"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ week, }
             \AttributeTok{y =}\NormalTok{ percentage,}
             \AttributeTok{fill =}\NormalTok{ category)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_d}\NormalTok{(}
    \AttributeTok{option =} \StringTok{"rocket"}\NormalTok{,}
    \AttributeTok{direction =} \SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{name =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{guide =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{name =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{labels =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{position =} \StringTok{"right"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(}\AttributeTok{rows =} \FunctionTok{vars}\NormalTok{(year), }
             \AttributeTok{cols =} \FunctionTok{vars}\NormalTok{(hub), }
             \AttributeTok{switch =} \StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Scherer and Karamanis put \texttt{year} in rows and \texttt{hub} (region) in columns. The \texttt{switch\ =\ "y"} argument moves the year label from the right side (where it appears by default) to the left. With this code in place, we can see the final plot coming together in Figure \ref{fig:drought-viz-faceted-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/drought-viz-faceted-plot-1} \caption{The faceted version of the drought visualization. Space considerations require me to include only four regions, but you get the idea.}\label{fig:drought-viz-faceted-plot}
\end{figure}

Incredibly, the broad outlines of the plot took us just 10 lines to create. The rest of the code falls into the category of small polishes. That's not to minimize how important small polishes are (very) or the time it takes to create them (lots). It does show, however, that a little bit of ggplot goes a long way.

\hypertarget{applying-small-polishes}{%
\subsection*{Applying Small Polishes}\label{applying-small-polishes}}
\addcontentsline{toc}{subsection}{Applying Small Polishes}

Let's look at a few of the small polishes that Scherer and Karamanis made. The first is to apply a theme, as seen in Figure \ref{fig:drought-viz-theme-tweaks-plot}. They used \texttt{theme\_light()}, which removes the default gray background and changes the font to Roboto.

The \texttt{theme\_light()} function is what's known as a complete theme. So-called complete themes change the overall look-and-feel of a plot. But Scherer and Karamanis didn't stop there. They then used the theme() function to make additional tweaks to what \texttt{theme\_light()} gave them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dm\_perc\_cat\_hubs }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(hub }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"Northwest"}\NormalTok{, }
                    \StringTok{"California"}\NormalTok{, }
                    \StringTok{"Southwest"}\NormalTok{, }
                    \StringTok{"Northern Plains"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ week, }
             \AttributeTok{y =}\NormalTok{ percentage,}
             \AttributeTok{fill =}\NormalTok{ category)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_d}\NormalTok{(}
    \AttributeTok{option =} \StringTok{"rocket"}\NormalTok{,}
    \AttributeTok{direction =} \SpecialCharTok{{-}}\DecValTok{1}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{name =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{guide =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{name =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{labels =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{position =} \StringTok{"right"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(}\AttributeTok{rows =} \FunctionTok{vars}\NormalTok{(year), }
             \AttributeTok{cols =} \FunctionTok{vars}\NormalTok{(hub), }
             \AttributeTok{switch =} \StringTok{"y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_light}\NormalTok{(}\AttributeTok{base\_family =} \StringTok{"Roboto"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{axis.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{14}\NormalTok{, }
                              \AttributeTok{color =} \StringTok{"black"}\NormalTok{),}
    \AttributeTok{axis.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{family =} \StringTok{"Roboto Mono"}\NormalTok{, }
                             \AttributeTok{size =} \DecValTok{11}\NormalTok{),}
    \AttributeTok{axis.line.x =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.line.y =} \FunctionTok{element\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }
                               \AttributeTok{size =}\NormalTok{ .}\DecValTok{2}\NormalTok{),}
    \AttributeTok{axis.ticks.y =} \FunctionTok{element\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }
                                \AttributeTok{size =}\NormalTok{ .}\DecValTok{2}\NormalTok{),}
    \AttributeTok{axis.ticks.length.y =} \FunctionTok{unit}\NormalTok{(}\DecValTok{2}\NormalTok{, }\StringTok{"mm"}\NormalTok{),}
    \AttributeTok{legend.position =} \StringTok{"top"}\NormalTok{,}
    \AttributeTok{legend.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#2DAADA"}\NormalTok{, }
                                \AttributeTok{face =} \StringTok{"bold"}\NormalTok{),}
    \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#2DAADA"}\NormalTok{),}
    \AttributeTok{strip.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }
                                \AttributeTok{face =} \StringTok{"plain"}\NormalTok{, }
                                \AttributeTok{color =} \StringTok{"black"}\NormalTok{, }
                                \AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}\AttributeTok{t =} \DecValTok{20}\NormalTok{, }\AttributeTok{b =} \DecValTok{5}\NormalTok{)),}
    \AttributeTok{strip.text.y.left =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{0}\NormalTok{, }
                                     \AttributeTok{vjust =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }
                                     \AttributeTok{face =} \StringTok{"plain"}\NormalTok{, }
                                     \AttributeTok{color =} \StringTok{"black"}\NormalTok{),}
    \AttributeTok{strip.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"transparent"}\NormalTok{, }
                                    \AttributeTok{color =} \StringTok{"transparent"}\NormalTok{),}
    \AttributeTok{panel.grid.minor =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{panel.grid.major =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{panel.spacing.x =} \FunctionTok{unit}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\StringTok{"lines"}\NormalTok{),}
    \AttributeTok{panel.spacing.y =} \FunctionTok{unit}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\StringTok{"lines"}\NormalTok{),}
    \AttributeTok{panel.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"transparent"}\NormalTok{, }
                                    \AttributeTok{color =} \StringTok{"transparent"}\NormalTok{),}
    \AttributeTok{panel.border =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{color =} \StringTok{"transparent"}\NormalTok{, }
                                \AttributeTok{size =} \DecValTok{0}\NormalTok{),}
    \AttributeTok{plot.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"transparent"}\NormalTok{, }
                                   \AttributeTok{color =} \StringTok{"transparent"}\NormalTok{, }
                                   \AttributeTok{size =}\NormalTok{ .}\DecValTok{4}\NormalTok{),}
    \AttributeTok{plot.margin =} \FunctionTok{margin}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{4}\NormalTok{))}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

The code in the \texttt{theme()} function does many different things, but let's take a look at a few of the most important. First, it moves the legend from the right side (the default) to the top of the plot. Then, an \texttt{angle\ =\ 0} argument rotates the year text in the columns so that it is no longer angled. Without this argument, the years would be much less readable.

Next, the \texttt{theme()} function makes the distinctive axis lines and ticks that show up on the right side of the final plot. Calling \texttt{element\_blank()} removes all grid lines. Finally, three lines remove the borders and make each of the individual plots have a transparent background.

Keen readers such as yourself may now be thinking, ``Wait. Didn't the individual plots have a gray background behind them?'' Yes, dear reader, they did. Scherer and Karamanis made these with a separate geom, \texttt{geom\_rect()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{geom\_rect}\NormalTok{(}
  \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{xmin =}\NormalTok{ .}\DecValTok{5}\NormalTok{,}
    \AttributeTok{xmax =}\NormalTok{ max\_week }\SpecialCharTok{+}\NormalTok{ .}\DecValTok{5}\NormalTok{,}
    \AttributeTok{ymin =} \SpecialCharTok{{-}}\FloatTok{0.005}\NormalTok{,}
    \AttributeTok{ymax =} \DecValTok{1}
\NormalTok{  ),}
  \AttributeTok{fill =} \StringTok{"\#f4f4f9"}\NormalTok{,}
  \AttributeTok{color =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{size =} \FloatTok{0.4}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

They set some additional aesthetic properties specific to this geom: \texttt{xmin}, \texttt{xmax}, \texttt{ymin}, and \texttt{ymax}, which determine the boundaries of the rectangle it produces. The result is a gray background drawn behind each small multiple, as seen in Figure \ref{fig:drought-viz-theme-tweaks-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/drought-viz-theme-tweaks-plot-1} \caption{Figure 1-16   Faceted version of the drought visualization with gray backgrounds behind each small multiple}\label{fig:drought-viz-theme-tweaks-plot}
\end{figure}

Finally, consider the tweaks made to the legend. We previously saw a simplified version of the \texttt{scale\_fill\_viridis\_d()} function. Here is a more complete version:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{scale\_fill\_viridis\_d}\NormalTok{(}
  \AttributeTok{option =} \StringTok{"rocket"}\NormalTok{,}
  \AttributeTok{direction =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}
  \AttributeTok{name =} \StringTok{"Category:"}\NormalTok{,}
  \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"Abnormally Dry"}\NormalTok{,}
    \StringTok{"Moderate Drought"}\NormalTok{,}
    \StringTok{"Severe Drought"}\NormalTok{,}
    \StringTok{"Extreme Drought"}\NormalTok{,}
    \StringTok{"Exceptional Drought"}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{name} argument sets the legend title, and the \texttt{labels} argument determines the labels that show up in the legend. Figure \ref{fig:drought-viz-legend-tweaks} shows the result of these changes.

\begin{figure}
\includegraphics[width=1\linewidth]{data-viz_files/figure-latex/drought-viz-legend-tweaks-1} \caption{Drought visualization with changes made to the legend text}\label{fig:drought-viz-legend-tweaks}
\end{figure}

Rather than D0, D1, D2, D3, and D4, we now have Abnormally Dry, Moderate Drought, Severe Drought, Extreme Drought, and Exceptional Drought.

\hypertarget{the-complete-visualization-code}{%
\subsection*{The Complete Visualization Code}\label{the-complete-visualization-code}}
\addcontentsline{toc}{subsection}{The Complete Visualization Code}

While I've showed you a nearly complete version of the code, I have made some small changes along the way to make it easier to understand. If you're curious to see the full code Cédric and Georgios used to create the data viz, here it is. There are a few additional tweaks to colors and spacing, but nothing major beyond what we've seen so far.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dm\_perc\_cat\_hubs, }\FunctionTok{aes}\NormalTok{(week, percentage)) }\SpecialCharTok{+}
  \FunctionTok{geom\_rect}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}
      \AttributeTok{xmin =}\NormalTok{ .}\DecValTok{5}\NormalTok{,}
      \AttributeTok{xmax =}\NormalTok{ max\_week }\SpecialCharTok{+}\NormalTok{ .}\DecValTok{5}\NormalTok{,}
      \AttributeTok{ymin =} \SpecialCharTok{{-}}\FloatTok{0.005}\NormalTok{,}
      \AttributeTok{ymax =} \DecValTok{1}
\NormalTok{    ),}
    \AttributeTok{fill =} \StringTok{"\#f4f4f9"}\NormalTok{,}
    \AttributeTok{color =} \ConstantTok{NA}\NormalTok{,}
    \AttributeTok{size =} \FloatTok{0.4}\NormalTok{,}
    \AttributeTok{show.legend =} \ConstantTok{FALSE}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}
      \AttributeTok{fill =}\NormalTok{ category,}
      \AttributeTok{fill =} \FunctionTok{after\_scale}\NormalTok{(}\FunctionTok{addmix}\NormalTok{(}\FunctionTok{darken}\NormalTok{(fill, .}\DecValTok{05}\NormalTok{, }
                                       \AttributeTok{space =} \StringTok{"HLS"}\NormalTok{), }
                                \StringTok{"\#d8005a"}\NormalTok{, }
\NormalTok{                                .}\DecValTok{15}\NormalTok{)),}
      \AttributeTok{color =} \FunctionTok{after\_scale}\NormalTok{(}\FunctionTok{darken}\NormalTok{(fill, .}\DecValTok{2}\NormalTok{, }
                                 \AttributeTok{space =} \StringTok{"HLS"}\NormalTok{))}
\NormalTok{    ),}
    \AttributeTok{width =}\NormalTok{ .}\DecValTok{9}\NormalTok{,}
    \AttributeTok{size =} \FloatTok{0.12}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{facet\_grid}\NormalTok{(}\AttributeTok{rows =} \FunctionTok{vars}\NormalTok{(year), }
             \AttributeTok{cols =} \FunctionTok{vars}\NormalTok{(hub), }
             \AttributeTok{switch =} \StringTok{"y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{clip =} \StringTok{"off"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{expand =} \FunctionTok{c}\NormalTok{(.}\DecValTok{02}\NormalTok{, .}\DecValTok{02}\NormalTok{), }
                     \AttributeTok{guide =} \StringTok{"none"}\NormalTok{, }
                     \AttributeTok{name =} \ConstantTok{NULL}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{expand =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }
                     \AttributeTok{position =} \StringTok{"right"}\NormalTok{, }
                     \AttributeTok{labels =} \ConstantTok{NULL}\NormalTok{, }
                     \AttributeTok{name =} \ConstantTok{NULL}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_d}\NormalTok{(}
    \AttributeTok{option =} \StringTok{"rocket"}\NormalTok{,}
    \AttributeTok{name =} \StringTok{"Category:"}\NormalTok{,}
    \AttributeTok{direction =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{begin =}\NormalTok{ .}\DecValTok{17}\NormalTok{,}
    \AttributeTok{end =}\NormalTok{ .}\DecValTok{97}\NormalTok{,}
    \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}
      \StringTok{"Abnormally Dry"}\NormalTok{,}
      \StringTok{"Moderate Drought"}\NormalTok{,}
      \StringTok{"Severe Drought"}\NormalTok{,}
      \StringTok{"Extreme Drought"}\NormalTok{,}
      \StringTok{"Exceptional Drought"}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{guides}\NormalTok{(}\AttributeTok{fill =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{nrow =} \DecValTok{2}\NormalTok{,}
                             \AttributeTok{override.aes =} \FunctionTok{list}\NormalTok{(}\AttributeTok{size =} \DecValTok{1}\NormalTok{))) }\SpecialCharTok{+}
  \FunctionTok{theme\_light}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{18}\NormalTok{, }
              \AttributeTok{base\_family =} \StringTok{"Roboto"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{axis.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{14}\NormalTok{, }
                              \AttributeTok{color =} \StringTok{"black"}\NormalTok{),}
    \AttributeTok{axis.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{family =} \StringTok{"Roboto Mono"}\NormalTok{, }
                             \AttributeTok{size =} \DecValTok{11}\NormalTok{),}
    \AttributeTok{axis.line.x =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.line.y =} \FunctionTok{element\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }
                               \AttributeTok{size =}\NormalTok{ .}\DecValTok{2}\NormalTok{),}
    \AttributeTok{axis.ticks.y =} \FunctionTok{element\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }
                                \AttributeTok{size =}\NormalTok{ .}\DecValTok{2}\NormalTok{),}
    \AttributeTok{axis.ticks.length.y =} \FunctionTok{unit}\NormalTok{(}\DecValTok{2}\NormalTok{, }\StringTok{"mm"}\NormalTok{),}
    \AttributeTok{legend.position =} \StringTok{"top"}\NormalTok{,}
    \AttributeTok{legend.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#2DAADA"}\NormalTok{, }
                                \AttributeTok{size =} \DecValTok{18}\NormalTok{, }
                                \AttributeTok{face =} \StringTok{"bold"}\NormalTok{),}
    \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#2DAADA"}\NormalTok{, }
                               \AttributeTok{size =} \DecValTok{16}\NormalTok{),}
    \AttributeTok{strip.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{16}\NormalTok{, }
                                \AttributeTok{hjust =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }
                                \AttributeTok{face =} \StringTok{"plain"}\NormalTok{, }
                                \AttributeTok{color =} \StringTok{"black"}\NormalTok{, }
                                \AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}\AttributeTok{t =} \DecValTok{20}\NormalTok{, }\AttributeTok{b =} \DecValTok{5}\NormalTok{)),}
    \AttributeTok{strip.text.y.left =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{18}\NormalTok{, }
                                     \AttributeTok{angle =} \DecValTok{0}\NormalTok{, }
                                     \AttributeTok{vjust =}\NormalTok{ .}\DecValTok{5}\NormalTok{, }
                                     \AttributeTok{face =} \StringTok{"plain"}\NormalTok{, }
                                     \AttributeTok{color =} \StringTok{"black"}\NormalTok{),}
    \AttributeTok{strip.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"transparent"}\NormalTok{, }
                                    \AttributeTok{color =} \StringTok{"transparent"}\NormalTok{),}
    \AttributeTok{panel.grid.minor =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{panel.grid.major =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{panel.spacing.x =} \FunctionTok{unit}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\StringTok{"lines"}\NormalTok{),}
    \AttributeTok{panel.spacing.y =} \FunctionTok{unit}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\StringTok{"lines"}\NormalTok{),}
    \AttributeTok{panel.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"transparent"}\NormalTok{, }
                                    \AttributeTok{color =} \StringTok{"transparent"}\NormalTok{),}
    \AttributeTok{panel.border =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{color =} \StringTok{"transparent"}\NormalTok{, }
                                \AttributeTok{size =} \DecValTok{0}\NormalTok{),}
    \AttributeTok{plot.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"transparent"}\NormalTok{, }
                                   \AttributeTok{color =} \StringTok{"transparent"}\NormalTok{, }
                                   \AttributeTok{size =}\NormalTok{ .}\DecValTok{4}\NormalTok{),}
    \AttributeTok{plot.margin =} \FunctionTok{margin}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{4}\NormalTok{))}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

There are a few additional tweaks to colors and spacing, but most of the code reflects what you've seen so far.

\hypertarget{in-conclusion-ggplot-is-your-data-viz-secret-weapon}{%
\section*{In Conclusion: ggplot is Your Data Viz Secret Weapon}\label{in-conclusion-ggplot-is-your-data-viz-secret-weapon}}
\addcontentsline{toc}{section}{In Conclusion: ggplot is Your Data Viz Secret Weapon}

You may start to think of ggplot as a solution to all of your data visualization problems. And yes, you have a new hammer, but no, everything is not a nail. If you look at the version of the data visualization that appeared in \emph{Scientific American} in November 2021, you'll see that some of its annotations aren't visible in our recreation. That's because they were added in post-production. While you could have found ways to create them in ggplot, it's often not the best use of your time. Get yourself 90 percent of the way there with ggplot and then use Illustrator, Figma, or a similar tool to finish your work.

Even so, ggplot is a very powerful hammer, used to make plots that you've seen in \emph{The New York Times}, FiveThirtyEight, the BBC, and other well-known news outlets. Although not the only tool that can generate high-quality data visualization, it makes the process straightforward. The graph by Scherer and Karamanis shows this in several ways:

\begin{itemize}
\item
  \textbf{It strips away extraneous elements, such as grid lines, in order to keep the focus on the data itself}. Complete themes such as \texttt{theme\_light()} and the \texttt{theme()} function allowed Scherer and Karamanis to create a decluttered visualization that communicates effectively.
\item
  \textbf{It uses well-chosen colors}. The \texttt{scale\_fill\_viridis\_d()} allowed them to create a color scheme that demonstrates differences between groups, is colorblind friendly, and shows up well when printed in grayscale.
\item
  \textbf{It uses small multiples to break data from two decades and eight regions into a set of graphs that come together to create a single plot}. With a single call to the \texttt{facet\_grid()} function, Scherer and Karamanis created over 100 small multiples that the tool automatically combined into a single plot.
\end{itemize}

Learning to create data visualization in ggplot involves a significant time investment. But the long-term payoff is even greater. Once you learn how ggplot works, you can look at others' code and learn how to improve your own. By contrast, when you make a data visualization in Excel, the series of point-and-click steps disappears into the ether. To recreate a visualization you made last week, you'll need to remember the exact steps you used, and to make someone else's data visualization, you'll need them to write up their process for you.

Because code-based data visualization tools allow you to keep that record of the steps you made, you don't have to be the most talented designer to make high-quality data visualization with ggplot. You can study others' code, adapt it to your own needs, and create your own data visualization that is beautiful and communicates effectively.

\hypertarget{custom-theme-chapter}{%
\chapter{Making Your Own Theme}\label{custom-theme-chapter}}

In 2018, BBC data journalists Nassos Stylianou and Clara Guibourg, along with their team, developed a custom ggplot theme that matches the BBC's style. By introducing this bbplot package for others to use, they changed their organization's culture, removed bottlenecks, and allowed the BBC to visualize data more creatively.

To understand the significance of these changes, it's helpful to know how things worked at the BBC before the introduction of \texttt{bbplot.} In the mid-2010s, journalists who wanted to make data visualization had two choices:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  They could use an internal tool. This tool could create data visualizations but was limited to the predefined charts it had been designed to generate.
\item
  They could use Excel to create mockups and then work with a graphic designer to finalize the charts. This approach led to better results, and was way more flexible, but required extensive, time-consuming back-and-forth with a designer.
\end{enumerate}

Neither of these choices was ideal, and they limited the BBC's data visualization output. R freed the journalists from having to work with a designer. It wasn't that the designers were bad (they weren't), but ggplot allowed the journalists to explore different visualizations on their own. Working with a designer required the journalists to have a fully-formed idea that the designer could take and improve upon.

As the team improved their ggplot skills, they realized that it might be possible to produce more than just exploratory data visualizations. Could they create production-ready charts in R that could go straight onto the BBC website? In this chapter, I discuss the power of custom ggplot themes. I then go through the code in the \texttt{bbplot} package to learn how custom themes work. I wrap up the chapter by exploring the impact that bbplot had, not only on a technical level, but also as a catalyst for a larger culture change.

\hypertarget{the-power-of-a-theme}{%
\section*{The Power of a Theme}\label{the-power-of-a-theme}}
\addcontentsline{toc}{section}{The Power of a Theme}

As Stylianou, Guibourg, and their colleagues realized, so much of the work involved in making a professional chart consists of small tweaks. What font should you use? Where should the legend go? Should axes have titles? Should charts have grid lines? These questions may seem small, but they have a big impact on the final product.

And these are the types of questions to which a custom theme can provide answers. Custom themes force everyone who uses them follows style guidelines and ensures that all data visualization is on brand. What's more, when more experienced R users in an organization make a custom theme, other less experienced users can take advantage of their work to make sure their plots follow organizational style guidelines. Custom themes, as we'll see below when we dive into the bbplot code, involve a set of code that makes a set of small tweaks to all plots. Rather than forcing everyone to copy the long code to tweak each plot they make, putting this code into a custom theme allows everyone to apply the theme with one line of code.

\hypertarget{using-bbplot-to-style-a-penguin-plot}{%
\section*{Using bbplot to Style a Penguin Plot}\label{using-bbplot-to-style-a-penguin-plot}}
\addcontentsline{toc}{section}{Using bbplot to Style a Penguin Plot}

The bbplot package has two functions: \texttt{bbc\_style()} and \texttt{finalise\_plot()}. The latter deals with things like adding the BBC logo, saving plots in the correct dimensions, and other tasks done after the plot is complete (we'll discuss it a bit later on). For now, let's look at the \texttt{bbc\_style()} function, which applies a custom ggplot theme to any plot, making all plots look consistent and follow BBC style guidelines.

\hypertarget{creating-an-example-plot}{%
\section*{Creating an Example Plot}\label{creating-an-example-plot}}
\addcontentsline{toc}{section}{Creating an Example Plot}

To show how this function works, let's create a plot. We'll do so using the \texttt{palmerpenguins} package, which has data on penguins living on three islands in Antarctica. To give you a sense of what this data looks like, let's load the \texttt{palmerpenguins} and \texttt{tidyverse} packages.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(palmerpenguins)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

We now have data that we can work with in an object called \texttt{penguins}. Here's what the first ten rows look like.

\begin{verbatim}
#> # A tibble: 344 x 8
#>    species island    bill_le~1 bill_~2 flipp~3 body_~4 sex  
#>    <fct>   <fct>         <dbl>   <dbl>   <int>   <int> <fct>
#>  1 Adelie  Torgersen      39.1    18.7     181    3750 male 
#>  2 Adelie  Torgersen      39.5    17.4     186    3800 fema~
#>  3 Adelie  Torgersen      40.3    18       195    3250 fema~
#>  4 Adelie  Torgersen      NA      NA        NA      NA <NA> 
#>  5 Adelie  Torgersen      36.7    19.3     193    3450 fema~
#>  6 Adelie  Torgersen      39.3    20.6     190    3650 male 
#>  7 Adelie  Torgersen      38.9    17.8     181    3625 fema~
#>  8 Adelie  Torgersen      39.2    19.6     195    4675 male 
#>  9 Adelie  Torgersen      34.1    18.1     193    3475 <NA> 
#> 10 Adelie  Torgersen      42      20.2     190    4250 <NA> 
#> # ... with 334 more rows, 1 more variable: year <int>, and
#> #   abbreviated variable names 1: bill_length_mm,
#> #   2: bill_depth_mm, 3: flipper_length_mm, 4: body_mass_g
\end{verbatim}

To get our data in a more usable format, let's count how many penguins live on each island. We do this with the \texttt{count()} function from the \texttt{dplyr} package (one of several packages that are loaded when we load the \texttt{tidyverse}). This gives us some simple data that we can use for plotting:

This gives us some simple data that we can use for plotting below.

\begin{verbatim}
#> # A tibble: 3 x 2
#>   island        n
#>   <fct>     <int>
#> 1 Biscoe      168
#> 2 Dream       124
#> 3 Torgersen    52
\end{verbatim}

Because we're going to use this data multiple times below, let's save it as an object called \texttt{penguins\_summary}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_summary }\OtherTok{\textless{}{-}}\NormalTok{ penguins }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(island)}
\end{Highlighting}
\end{Shaded}

Now that we've got some data to work with, we're ready to create a plot. Before showing what \texttt{bbplot} does, let's make our plot with the ggplot defaults. Here is the code we'll use:

We use our \texttt{penguins\_summary} data frame, putting the island on the x axis and the count of the number of penguins (n) on the y axis, and making each bar a different color with the fill aesthetic property. We'll modify this plot multiple times, so to simplify this process, we save it as an object called penguins\_plot. The resulting plot is seen in Figure \ref{fig:basic-penguins-plot-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/basic-penguins-plot-plot-1} \caption{A chart with the default theme}\label{fig:basic-penguins-plot-plot}
\end{figure}

It isn't the most aesthetically pleasing chart. The gray background is ugly, the y axis title is hard to read because it's angled, and the text size overall is quite small. But don't worry: we'll be improving it soon!

\hypertarget{applying-the-bbc_style-function}{%
\subsection*{\texorpdfstring{Applying the \texttt{bbc\_style()} Function}{Applying the bbc\_style() Function}}\label{applying-the-bbc_style-function}}
\addcontentsline{toc}{subsection}{Applying the \texttt{bbc\_style()} Function}

Now that we have a basic plot to work with, let's make it look like a BBC chart. To do this, we load the \texttt{bbplot} package:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(bbplot)}
\end{Highlighting}
\end{Shaded}

We can then apply the \texttt{bbc\_style()} function to our \texttt{penguins\_plot}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot }\SpecialCharTok{+}
  \FunctionTok{bbc\_style}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Take a look at what happens in Figure \ref{fig:penguins-bbc-style-plot} with the application of \texttt{bbc\_style()} to our plot.

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/penguins-bbc-style-plot-1} \caption{The same chart with BBC style}\label{fig:penguins-bbc-style-plot}
\end{figure}

Way different, right? Larger font size, legend on top, no axis titles, stripped down grid lines, and a white background. These are the major changes that the \texttt{bbc\_style()} function makes. Let's look at them one by one.

\hypertarget{breaking-down-the-custom-theme}{%
\subsection*{Breaking Down the Custom Theme}\label{breaking-down-the-custom-theme}}
\addcontentsline{toc}{subsection}{Breaking Down the Custom Theme}

Here is the code for the bbc\_style() function (taken from the \texttt{bbplot} GitHub repository at \url{https://github.com/bbc/bbplot}, with some minor tweaks for readability). The first line gives the function a name and indicates that what follows is, in fact, a function definition. We'll discuss functions more in Chapter \ref{functions}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bbc\_style }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{  font }\OtherTok{\textless{}{-}} \StringTok{"Helvetica"}
  
\NormalTok{  ggplot2}\SpecialCharTok{::}\FunctionTok{theme}\NormalTok{(}
    
    \CommentTok{\# TEXT FORMAT}
    \CommentTok{\# This sets the font, size, type and colour }
    \CommentTok{\# of text for the chart\textquotesingle{}s title}
    \AttributeTok{plot.title =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{28}\NormalTok{,}
      \AttributeTok{face =} \StringTok{"bold"}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    ),}
    \CommentTok{\# This sets the font, size, type and colour}
    \CommentTok{\# of text for the chart\textquotesingle{}s subtitle,}
    \CommentTok{\# as well as setting a margin between the title and the subtitle}
    \AttributeTok{plot.subtitle =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{22}\NormalTok{,}
      \AttributeTok{margin =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{margin}\NormalTok{(}\DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{    ),}
    \CommentTok{\# This leaves the caption text element empty, }
    \CommentTok{\# because it is set elsewhere in the finalise plot function}
    \AttributeTok{plot.caption =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    
    \CommentTok{\# LEGEND FORMAT}
    \CommentTok{\# This sets the position and alignment of the legend, }
    \CommentTok{\# removes a title and background for it}
    \CommentTok{\# and sets the requirements for any text within the legend.}
    \CommentTok{\# The legend may often need some more manual tweaking }
    \CommentTok{\# when it comes to its exact position based on the plot coordinates.}
    \AttributeTok{legend.position =} \StringTok{"top"}\NormalTok{,}
    \AttributeTok{legend.text.align =} \DecValTok{0}\NormalTok{,}
    \AttributeTok{legend.background =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.title =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.key =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.text =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{18}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    ),}
    
    \CommentTok{\# AXIS FORMAT}
    \CommentTok{\# This sets the text font, size and colour for the axis test, }
    \CommentTok{\# as well as setting the margins and removes lines and ticks.}
    \CommentTok{\# In some cases, axis lines and axis ticks are things we would }
    \CommentTok{\# want to have in the chart {-} }
    \CommentTok{\# the cookbook shows examples of how to do so.}
    \AttributeTok{axis.title =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.text =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{18}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    ),}
    \AttributeTok{axis.text.x =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_text}\NormalTok{(}\AttributeTok{margin =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{margin}\NormalTok{(}\DecValTok{5}\NormalTok{, }\AttributeTok{b =} \DecValTok{10}\NormalTok{)),}
    \AttributeTok{axis.ticks =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.line =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    
    \CommentTok{\# GRID LINES}
    \CommentTok{\# This removes all minor gridlines and adds major y gridlines.}
    \CommentTok{\# In many cases you will want to change this to remove }
    \CommentTok{\# y gridlines and add x gridlines.}
    \CommentTok{\# The cookbook shows you examples for doing so.}
    \AttributeTok{panel.grid.minor =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{panel.grid.major.y =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#cbcbcb"}\NormalTok{),}
    \AttributeTok{panel.grid.major.x =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    
    \CommentTok{\# BLANK BACKGROUND}
    \CommentTok{\# This sets the panel background as blank, removing the standard }
    \CommentTok{\# grey ggplot background colour from the plot.}
    \AttributeTok{panel.background =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_blank}\NormalTok{(),}
    
    \CommentTok{\# STRIP BACKGROUND}
    \CommentTok{\# This sets the panel background for facet{-}wrapped plots to white,}
    \CommentTok{\# removing the standard grey ggplot background colour and sets the }
    \CommentTok{\# title size of the facet{-}wrap title to font size 22.}
    \AttributeTok{strip.background =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"white"}\NormalTok{),}
    \AttributeTok{strip.text =}\NormalTok{ ggplot2}\SpecialCharTok{::}\FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{22}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{)}
\NormalTok{  )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

You'll see that instead of loading the package \texttt{ggplot2} with the code \texttt{library(ggplot2)} and then using the \texttt{theme()} function, the code below uses \texttt{ggplot2::theme()}. This indicates that the \texttt{theme()} function comes from the \texttt{ggplot2} package. Writing code in this way is something that is done when making an R package, something we'll discuss in Chapter \ref{custom-packages}.

Nearly all of the code in the \texttt{bbc\_style()} function exists within the \texttt{theme()} function from ggplot2. Remember from Chapter \ref{data-viz-chapter} that \texttt{theme()} makes additional tweaks to an existing theme; it isn't a complete theme like \texttt{theme\_light()}, which will change the whole look-and-feel of your plot. In other words, by jumping straight into the \texttt{theme()} function, \texttt{bbc\_style()} makes tweaks to the ggplot defaults.

As you can see, the \texttt{bbc\_style()} function does a lot of tweaking. Let's go through the changes it makes, section by section.

\hypertarget{text-formatting}{%
\subsection*{Text Formatting}\label{text-formatting}}
\addcontentsline{toc}{subsection}{Text Formatting}

The first code section formats the text. It defines a variable called \texttt{font} and assigns it the value \texttt{Helvetica.} This allows later sections to simply write font rather than repeating \texttt{Helvetica} over and over again. Also, if the BBC team ever wanted to use a different font, they could change \texttt{Helvetica} to, say, \texttt{Comic\ Sans} and update the font of all BBC plots (though I suspect higher-ups at the BBC might not be on board).

Subsequent pieces of this section make changes to the title, subtitle, and caption using the following pattern:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AREA\_OF\_CHART }\OtherTok{=} \FunctionTok{ELEMENT\_TYPE}\NormalTok{(}
  \AttributeTok{PROPERTY =}\NormalTok{ VALUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We begin by selecting an area of the chart (for example, \texttt{plot.title}). Then, we say what type of element it is: \texttt{element\_text()}, \texttt{element\_line()}, \texttt{element\_rect()}, or \texttt{element\_blank()}. For now, we're working with \texttt{element\_text()} to handle formatting the title, subtitle, and caption. Within the element type, we give values to properties. This can be, say, setting the font family (the property) to Helvetica (the value).

One of the main things the \texttt{bbc\_style()} function does is bump up the text size. Increasing font size helps with legibility, especially when plots made using the bbplot package are viewed on smaller mobile devices. The code first formats the title (with \texttt{plot.title}) using Helvetica 28-point bold font in a nearly black color (that's the hex code \#222222). The subtitle (using \texttt{plot.subtitle}) is 22-point Helvetica. Some spacing is added between the title and subtitle using the margin() function, which gives the spacing, in points, for the top (9), right (0), bottom (9), and left (0) sides. Finally, the caption (through the \texttt{plot.caption} argument) is removed using the \texttt{element\_blank()} function. This is done because the \texttt{finalise\_plot()} function in the \texttt{bbplot} package adds elements, including a caption and the BBC logo to the bottom of plots.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{28}\NormalTok{,}
      \AttributeTok{face =} \StringTok{"bold"}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    ),}
    \AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{22}\NormalTok{,}
      \AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}\DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{    ),}
    \AttributeTok{plot.caption =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We can see these changes in Figure \ref{fig:penguins-plot-text-formatting-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/penguins-plot-text-formatting-plot-1} \caption{Our chart with only text formatting changed}\label{fig:penguins-plot-text-formatting-plot}
\end{figure}

We then save our plot as an object in order to work with it in the next section.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot\_text }\OtherTok{\textless{}{-}}\NormalTok{ penguins\_plot }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{28}\NormalTok{,}
      \AttributeTok{face =} \StringTok{"bold"}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    ),}
    \AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{22}\NormalTok{,}
      \AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}\DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{    ),}
    \AttributeTok{plot.caption =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{legend-formatting}{%
\subsection*{Legend Formatting}\label{legend-formatting}}
\addcontentsline{toc}{subsection}{Legend Formatting}

Next, we deal with the legend, putting it on top of the plot and left-aligning the text within it. Then, we remove the legend background (which would show up only if the background color of the entire plot were different), title, and legend key (the borders on the red, green, and blue boxes that show the island names). Finally, we make the legend's text 18-point Helvetica with the same nearly black color.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot\_text }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position =} \StringTok{"top"}\NormalTok{,}
    \AttributeTok{legend.text.align =} \DecValTok{0}\NormalTok{,}
    \AttributeTok{legend.background =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.title =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.key =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{18}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We can see the result in Figure \ref{fig:penguins-plot-legend-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/penguins-plot-legend-plot-1} \caption{Our chart with changes to the legend}\label{fig:penguins-plot-legend-plot}
\end{figure}

And again, we save this plot so we can continue to alter it below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot\_legend }\OtherTok{\textless{}{-}}\NormalTok{ penguins\_plot\_text }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position =} \StringTok{"top"}\NormalTok{,}
    \AttributeTok{legend.text.align =} \DecValTok{0}\NormalTok{,}
    \AttributeTok{legend.background =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.title =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.key =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{18}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{axis-formatting}{%
\subsection*{Axis Formatting}\label{axis-formatting}}
\addcontentsline{toc}{subsection}{Axis Formatting}

Next are the axes. The code first removes axis titles because, as Nassos told me, these tend to take up a lot of chart real estate, and you can use the title and subtitle to make it clear what the axes show.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot\_legend }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{axis.title =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.text =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{18}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    ),}
    \AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}\DecValTok{5}\NormalTok{, }\AttributeTok{b =} \DecValTok{10}\NormalTok{)),}
    \AttributeTok{axis.ticks =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.line =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

All text on axes becomes 18-point Helevetica and nearly black. The text on the x axis (in our case, Biscoe, Dream, and Torgersen) gets a bit of spacing around it. And, finally, we remove both axis ticks and axis lines. We can see the changes to our axes in Figure \ref{fig:penguins-plot-axes-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/penguins-plot-axes-plot-1} \caption{Our chart with changes to axis formatting}\label{fig:penguins-plot-axes-plot}
\end{figure}

Let's now save this plot as an object for future tweaks.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot\_axes }\OtherTok{\textless{}{-}}\NormalTok{ penguins\_plot\_legend }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{axis.title =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.text =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{family =}\NormalTok{ font,}
      \AttributeTok{size =} \DecValTok{18}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"\#222222"}
\NormalTok{    ),}
    \AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}\DecValTok{5}\NormalTok{, }\AttributeTok{b =} \DecValTok{10}\NormalTok{)),}
    \AttributeTok{axis.ticks =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.line =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{grid-lines-formatting}{%
\subsection*{Grid Lines Formatting}\label{grid-lines-formatting}}
\addcontentsline{toc}{subsection}{Grid Lines Formatting}

Now that we've tweaked overall text formatting, the legend, and the axes, let's move onto grid lines. The approach here is fairly straightforward: remove all minor grid lines and the major grid lines on the x axis, keeping only major grid lines on the y axis, but making them a light gray (using the \#cbcbcb hex code).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot\_axes }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{panel.grid.minor =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{panel.grid.major.y =} \FunctionTok{element\_line}\NormalTok{(}\AttributeTok{color =} \StringTok{"\#cbcbcb"}\NormalTok{),}
    \AttributeTok{panel.grid.major.x =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We can see the result of these tweaks to the grid lines in Figure \ref{fig:penguins-plot-gridlines-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/penguins-plot-gridlines-plot-1} \caption{Our chart with tweaks to the grid lines}\label{fig:penguins-plot-gridlines-plot}
\end{figure}

And, once again, we save our plot to an object.

\hypertarget{background-formatting}{%
\subsection*{Background Formatting}\label{background-formatting}}
\addcontentsline{toc}{subsection}{Background Formatting}

The previous iteration of our plot still had a gray background. The \texttt{bbc\_style()} function removes this with the following code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot\_grid\_lines }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{panel.background =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

The plot without the gray background is seen in Figure \ref{fig:penguins-plot-no-bg}.

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/penguins-plot-no-bg-1} \caption{Our chart with the gray background removed}\label{fig:penguins-plot-no-bg}
\end{figure}

There we go! We've recreated the Penguin plot using the \texttt{bbc\_style()} function.

\hypertarget{small-multiples-formatting}{%
\subsection*{Small Multiples Formatting}\label{small-multiples-formatting}}
\addcontentsline{toc}{subsection}{Small Multiples Formatting}

However, you may recall that the function contains a bit more code, to modify strip.background and strip.text. These elements become relevant in small multiples charts like the one discussed in Chapter 2. Let's turn our penguin chart into a small multiples chart to see these components of the BBC's theme. I've used the code from the bbc\_style() function, minus the sections that deal with small multiples, to make Figure \ref{fig:penguin-facetted-plot}.

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/penguin-facetted-plot-1} \caption{Small multiples chart with no changes to the strip text formatting}\label{fig:penguin-facetted-plot}
\end{figure}

When we use the \texttt{facet\_wrap()} function, to make a small multiples chart, we are left with one chart per island. But note that, by default, the text above each chart is noticeably smaller than the rest of the chart. And the gray background behind the text stands out when we have removed the gray background from other parts of the chart. The consistency we've worked toward is now gone, with small text that is out of proportion to the other text in the chart and a gray background that sticks out like a sore thumb in a chart with an all white background.

I've saved the code used to make Figure \ref{fig:penguin-facetted-plot} as an object, \texttt{penguins\_plot\_weight.} We now use this object in order to show how to change the text that shows up above each small multiples chart (called the \emph{strip} in ggplot):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_plot\_weight }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{strip.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"white"}\NormalTok{),}
    \AttributeTok{strip.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{17}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{0}\NormalTok{, }\AttributeTok{face =} \StringTok{"bold"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We remove the background (or, more accurately, color it white). Then we make the text larger, bold, and left aligned using \texttt{hjust\ =\ 0}. I did have to make the text size slightly smaller to fit in the book and added code to make it bold. You can see the result in Figure @ref(fig: penguins-plot-facetted-bbc-plot).

\begin{figure}
\includegraphics[width=1\linewidth]{custom-theme_files/figure-latex/penguins-plot-facetted-bbc-plot-1} \caption{Small multiples chart in the BBC style}\label{fig:penguins-plot-facetted-bbc-plot}
\end{figure}

If you take a look at any chart on the BBC site, you'll see how similar it is to our chart. All of the tweaks in the \texttt{bbc\_style()} function (text formatting, legends, axes, grid lines, and backgrounds) that we used to make our example show up in charts seen by millions on the BBC website.

\hypertarget{what-about-colors}{%
\subsection*{What About Colors?}\label{what-about-colors}}
\addcontentsline{toc}{subsection}{What About Colors?}

You might be thinking: wait, what about the color of the bars? Doesn't the theme change those? It's a common point of confusion. If we read the documentation for the \texttt{theme()} function, though, it becomes clearer why this is the case:

\begin{quote}
Themes are a powerful way to customize the non-data components of your plots: i.e.~titles, labels, fonts, background, gridlines, and legends.
\end{quote}

Color (or, technically, in the case of the bar charts we have made in this chapter, fill) is used in plots as an aesthetic property to show something about data. In our small multiples chart, for instance, fill is mapped to the island (Biscoe is salmon, Dream is green, and Torgersen is blue). As we saw in Chapter \ref{data-viz-chapter}, we can change fill using the various \texttt{scale\_fill\_} functions. It is because fill is tied to the data rather than being about the overall look-and-feel that ggplot themes do not, on their own, change this component of plots.

\hypertarget{in-conclusion-code-is-the-catalyst-for-culture-change}{%
\section*{In Conclusion: Code is the Catalyst for Culture Change}\label{in-conclusion-code-is-the-catalyst-for-culture-change}}
\addcontentsline{toc}{section}{In Conclusion: Code is the Catalyst for Culture Change}

When Stylianou and Guibourg started developing a custom theme for the BBC, they had one question: would they be able to create graphs in R that could go directly onto the BBC website? And, wouldn't you know, they succeeded! The \texttt{bbplot} package allowed them to make plots with a consistent look-and-feel that followed BBC standards and, most importantly, did not need help from a designer.

You can see many of the principles of high-quality data visualization discussed in Chapter \ref{data-viz-chapter} in this custom theme. In particular, the removal of extraneous elements (axis titles and grid lines, for instance) helps keep the focus on the data itself. And because applying the theme requires users to add only a single line to their ggplot code, it became simple to get others on board. Users had only to append \texttt{bbc\_style()} to their code to produce a BBC-style plot.

Over time, others at the BBC noticed the data journalism team's production-ready graphs and wanted to make their own. The team members set up R trainings for their colleagues and developed a ``cookbook'' (found at \url{https://bbc.github.io/rcookbook/}) that showed how to make various types of charts. Soon, the quality and quantity of BBC's data visualization exploded. Stylianou told me, ``I don't think there's been a day where someone at the BBC hasn't used the package to produce a graphic.''

Now that you've seen how custom ggplot themes work, I hope you might be inspired to make one of your own. As you've seen, custom themes are a set of small tweaks that you can apply to plots to give them a consistent look-and-feel. Developing a custom theme can take your data visualization from meh to wow. And, once you've written the code, it only takes one line of code to apply your custom theme. If a custom theme can transform the data visualization work of the BBC, imagine what it can do for you.

\hypertarget{maps-chapter}{%
\chapter{Creating Maps}\label{maps-chapter}}

When I first started learning R, I considered it a tool for working with numbers, not shapes, so I was surprised when I saw people using it to make maps. Abdoul Madjid, a developer, has been creating maps with R for several years. Recently, he used one to visualize rates of COVID-19 in the United States in 2021.

You might think you need specialized mapmaking software like ArcGIS to make maps, but this tool is expensive, and while Excel has added support for map-making in recent years, its features are limited (for example, you can't use it to make maps based on street addresses). Even QGIS, an open source tool similar to ArcGIS, still requires learning new skills.

Using R for map-making has benefits. It lets you perform all of your data manipulation tasks with one tool and apply the principles of high-quality data visualization discussed in Chapter \ref{data-viz-chapter}. For example, Madjid used R to obtain his data, analyze it, and make his COVID-19 map, which you can see in Figure \ref{fig:madjid-covid-map}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-map} \caption{Abdoul Madjid's map of COVID in the United States in 2021}\label{fig:madjid-covid-map}
\end{figure}

In this chapter, we'll explore principles of working with geospatial data, then walk through Madjid's code to understand how he created this high-quality map. We'll also discuss where to find geospatial data and how to use it to make your own maps.

\hypertarget{the-briefest-of-primers-on-geospatial-data}{%
\section*{The Briefest of Primers on Geospatial Data}\label{the-briefest-of-primers-on-geospatial-data}}
\addcontentsline{toc}{section}{The Briefest of Primers on Geospatial Data}

You don't need to be a GIS expert to make maps. But you do need to understand a few things about how geospatial data works, starting with its two main types: vector and raster. \emph{Vector} data uses points, lines, and polygons to represent the world. \emph{Raster} data, which often comes from digital photographs, ties each pixel in an image to a specific geographic location. Vector data tends to be easier to work with, and we'll be using it exclusively in this chapter.

In the past, working with geospatial data meant mastering competing standards, each of which required learning a different approach. Today, though, most people use the \emph{simple features} model for working with vector geospatial data (often abbreviated as \emph{sf}), which is way easier to understand. For example, take a look at some simple features geospatial data that represents the US state of Wyoming:

You can see that the data has two columns, one for the state name (NAME) and another called geometry. This data looks like the data frames you're used to encountering, aside from two major differences: There's a bunch of metadata above the data frame, and our simple features data contains geographical data in a variable called \texttt{geometry.} The metadata begins with the text ``Simple feature collection with 1 feature and 1 field'' (because the \texttt{geometry} column must be present in order for a data frame to be geospatial data it is not counted as a field). The feature referenced here is the row, and the field is the \texttt{NAME} variable, which contains non-spatial data (the \texttt{geometry} column will be discussed below). This line, and the lines that follow, are metadata about the geospatial data in the \texttt{wyoming} object. Let's look at each part of this simple features data.

\hypertarget{geometry-type}{%
\subsection*{Geometry Type}\label{geometry-type}}
\addcontentsline{toc}{subsection}{Geometry Type}

The geometry type represents the shape of the geospatial data we're working with. These types are typically written in all caps. In this case, the relatively simple \texttt{POLYGON} type represents a single polygon. We can use ggplot to display this data by calling \texttt{geom\_sf()}, a special geom designed to work with simple features data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wyoming }\OtherTok{\textless{}{-}} \FunctionTok{read\_sf}\NormalTok{(}\StringTok{"https://data.rwithoutstatistics.com/wyoming.geojson"}\NormalTok{)}

\NormalTok{wyoming }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:wyoming-map-plot} shows the resulting map of Wyoming. It may not look like much, but, hey, I wasn't the one who chose to make Wyoming a nearly perfect rectangle!

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/wyoming-map-plot-1} \caption{A map of Wyoming}\label{fig:wyoming-map-plot}
\end{figure}

\texttt{POLYGON} is one of several geometry types that \texttt{sf} data can be used to represent.

Other geometry types used in simple feature data include \texttt{POINT}, to display elements such as a pin on a map that represents a single location. Figure \ref{fig:ev-stations-map} is a map showing the location of a single electric vehicle charging station in Wyoming.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/ev-stations-map-1} \caption{A map of a single electric vehicle charging station in Wyoming}\label{fig:ev-stations-map}
\end{figure}

The \texttt{LINESTRING} geometry type is for set of points that can be connected with lines, often used to represent roads. The \texttt{LINESTRING} in Figure \ref{fig:wy-roads-map} shows a section of US Highway 30 that runs through Wyoming.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/wy-roads-map-1} \caption{A map of a section of U.S. Highway 30 running through Wyoming}\label{fig:wy-roads-map}
\end{figure}

Each of these geometry types has a \texttt{MULTI} variation (\texttt{MULTIPOINT}, \texttt{MULTILINESTRING}, and \texttt{MULTIPOLYGON}) that combines multiple instances of the type in one row of data. For example, the data used to make Figure \ref{fig:wyoming-ev-stations-map}, which shows all electric vehicle charging stations in Wyoming, is \texttt{MULTIPOINT}.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/wyoming-ev-stations-map-1} \caption{A map of all electric vehicle charging stations in Wyoming}\label{fig:wyoming-ev-stations-map}
\end{figure}

Likewise, we can use MULTILINESTRING data to show not just one road, but all major roads in Wyoming, as in Figure \ref{fig:wyoming-roads-map}.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/wyoming-roads-map-1} \caption{A map of all major roads in Wyoming}\label{fig:wyoming-roads-map}
\end{figure}

Lastly, we could use MULTIPOLYGON data to, for example, depict a state made up of multiple polygons. To see what I mean, take a look at a map of Wyoming's counties. We can import this data with the following code:

The following simple features data represents the 23 counties in the state:

\begin{verbatim}
#> Simple feature collection with 23 features and 1 field
#> Geometry type: MULTIPOLYGON
#> Dimension:     XY
#> Bounding box:  xmin: -111.0546 ymin: 40.99477 xmax: -104.0522 ymax: 45.00582
#> Geodetic CRS:  WGS 84
#> # A tibble: 23 x 2
#>    NAME                                             geometry
#>    <chr>                                  <MULTIPOLYGON [°]>
#>  1 Lincoln     (((-110.5417 42.28652, -110.5417 42.28638, -~
#>  2 Fremont     (((-109.3258 42.86878, -109.3258 42.86894, -~
#>  3 Uinta       (((-110.5849 41.57916, -110.5837 41.57916, -~
#>  4 Big Horn    (((-107.5034 44.64004, -107.5029 44.64047, -~
#>  5 Hot Springs (((-108.1563 43.47063, -108.1563 43.45961, -~
#>  6 Washakie    (((-107.6841 44.1664, -107.684 44.1664, -107~
#>  7 Converse    (((-105.9232 43.49501, -105.9152 43.49503, -~
#>  8 Sweetwater  (((-109.5651 40.99839, -109.5652 40.99839, -~
#>  9 Crook       (((-104.4611 44.18075, -104.4612 44.18075, -~
#> 10 Carbon      (((-106.3227 41.38265, -106.3227 41.38245, -~
#> # ... with 13 more rows
\end{verbatim}

We can see that the geometry type of this data is \texttt{MULTIPOLYGON}. In addition, the repeated \texttt{MULTIPOLYGON} text in the geometry column indicates that each row contains a shape of type \texttt{MULTIPOLYGON}. Figure \ref{fig:wyoming-counties-map} is a map made with this data.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/wyoming-counties-map-1} \caption{A map of Wyoming counties}\label{fig:wyoming-counties-map}
\end{figure}

You can easily see the multiple polygons that make up the map.

\hypertarget{the-dimensions}{%
\subsection*{The Dimensions}\label{the-dimensions}}
\addcontentsline{toc}{subsection}{The Dimensions}

Next, the geospatial data frame contains the data's \emph{dimensions}, or the type of geospatial data we're working with. In the Wyoming example, it looks like this: \texttt{Dimension:\ XY}, meaning the data is two-dimensional, as in the case of all the geospatial data used in this chapter. There are two other dimensions (\texttt{Z} and \texttt{M}) that you'll see much more rarely. I'll leave them for you to investigate further.

\hypertarget{bounding-box}{%
\subsection*{Bounding Box}\label{bounding-box}}
\addcontentsline{toc}{subsection}{Bounding Box}

The penultimate element in the metadata is the bounding box. A \emph{bounding box} represents the smallest area in which we can fit all of our geospatial data. For our \texttt{wyoming} object, it looks like this:

\texttt{Bounding\ box:\ \ xmin:\ -111.0569\ ymin:\ 40.99475\ xmax:\ -104.0522\ ymax:\ 45.0059}

The \texttt{ymin} value of 40.99475 and \texttt{ymax} value of 45.0059 represent the lowest and highest latitude, respectively, that the state's polygon can fit into. The x values do the same for the longitude. Bounding boxes are calculated automatically, and you don't typically have to worry about altering them.

\hypertarget{the-geodetic-crs}{%
\subsection*{The Geodetic CRS}\label{the-geodetic-crs}}
\addcontentsline{toc}{subsection}{The Geodetic CRS}

The last piece of metadata specifies the \emph{coordinate reference system} used to project our data when we plot it. The problem with representing any geospatial data is that we're displaying information about the three-dimensional Earth on a two-dimensional map. Doing so requires us to choose a coordinate reference system that determines what type of correspondence, or \emph{projection}, to use when making our map.

The data for the Wyoming counties map includes the line \texttt{Geodetic\ CRS:\ WGS\ 84}, indicating the use of a coordinate reference system known as \emph{WGS84}. To see a different projection, check out the same map using what's known as the \emph{Albers equal-area conic convenience projection}. While Wyoming looked perfectly horizontal in Figure \ref{fig:wyoming-counties-map}, the version in Figure \ref{fig:wyoming-counties-map-wgs84} appears to be tilted.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/wyoming-counties-map-wgs84-1} \caption{A map of Wyoming counties using the WGS84 projection}\label{fig:wyoming-counties-map-wgs84}
\end{figure}

If you're curious about how to change projections when making maps of your own, fear not. You'll see how to do this when we look at Abdoul Madjid's map. And if you want to know how to choose appropriate projections for your maps, check out the conclusion of the chapter.

\hypertarget{the-geometry-column}{%
\subsection*{\texorpdfstring{The \texttt{geometry} Column}{The geometry Column}}\label{the-geometry-column}}
\addcontentsline{toc}{subsection}{The \texttt{geometry} Column}

In addition to the metadata, our simple features data differs from traditional data frames in another respect: its \texttt{geometry} column. As you probably guessed from the name, it holds the data needed to make our maps.

To understand how this works, consider the connect-the-dots drawings you probably completed as a kid. As you added lines to connect one point to the next, the subject of your drawing became clear. The geometry column is similar. It has a set of numbers, each of which corresponds to a point. If you're using \texttt{LINESTRING/MULTILINESTRING} or \texttt{POLYGON/MULTIPOLYGON} simple features data, ggplot uses the numbers in the geometry column to draw each point and then adds lines to connect the points. If you're using \texttt{POINT/MULTIPOINT} data, it draws the points but doesn't connect them.

Once again, you never have to worry about these details or look in any depth at the \texttt{geometry} column.

\hypertarget{recreating-the-covid-map}{%
\section*{Recreating the COVID Map}\label{recreating-the-covid-map}}
\addcontentsline{toc}{section}{Recreating the COVID Map}

Now that you understand the basics of geospatial data, let's walk through the code Madjid used to make his COVID-19 map., which makes use of the geometry types, dimensions, bounding boxes, projections, and the \texttt{geometry} column we just explored. (I've made some small modifications to the code to make the final map fit on the page.) Let's begin by loading few packages:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(albersusa)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(zoo)}
\FunctionTok{library}\NormalTok{(colorspace)}
\end{Highlighting}
\end{Shaded}

We'll use \texttt{tidyverse} to import data, manipulate it, and plot it (with ggplot). The \texttt{albersusa} package will give us access to geospatial data, and the \texttt{sf} package will enable us to change its coordinate reference system to use an appropriate projection. The \texttt{zoo} package has functions for calculating rolling averages, and the \texttt{colorspace} package gives us a color scale that highlights the data well.

\hypertarget{importing-the-data}{%
\subsection*{Importing the Data}\label{importing-the-data}}
\addcontentsline{toc}{subsection}{Importing the Data}

Next, let's import the data we need. We require three pieces of data: COVID rates by state over time, state populations, and geospatial information. Madjid imported each of these pieces of data separately and then merged them, and we'll do the same.

First, we import COVID data. This data comes directly from \emph{The New York Times}, which publishes daily case rates by state as a CSV file on its GitHub account. I've dropped the \texttt{fips} variable; Federal Information Processing Standards (FIPS) are numeric codes used to represent states, but we can reference states by their names instead:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{covid\_data }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"https://data.rwithoutstatistics.com/covid{-}us{-}states.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{fips)}
\end{Highlighting}
\end{Shaded}

If you take a look at this data, you can see the arrival of the first COVID cases in the United States in January 2020.

\begin{verbatim}
#> # A tibble: 61,102 x 4
#>    date       state      cases deaths
#>    <date>     <chr>      <dbl>  <dbl>
#>  1 2020-01-21 Washington     1      0
#>  2 2020-01-22 Washington     1      0
#>  3 2020-01-23 Washington     1      0
#>  4 2020-01-24 Illinois       1      0
#>  5 2020-01-24 Washington     1      0
#>  6 2020-01-25 California     1      0
#>  7 2020-01-25 Illinois       1      0
#>  8 2020-01-25 Washington     1      0
#>  9 2020-01-26 Arizona        1      0
#> 10 2020-01-26 California     2      0
#> # ... with 61,092 more rows
\end{verbatim}

Madjid's map shows per capita rates (rates per 100,000 people) rather than absolute rates (the rates without consideration for a state's population). So, to recreate his maps, we need to obtain data on each state's population. Madjid downloaded this data as a CSV:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{usa\_states }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"https://data.rwithoutstatistics.com/population{-}by{-}state.csv"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(State, Pop)}
\end{Highlighting}
\end{Shaded}

We import this data, keep the \texttt{State} and \texttt{Pop} (population) variables, and save it as an object called \texttt{usa\_states.} Let's see what \texttt{usa\_states} looks like:

\begin{verbatim}
#> # A tibble: 52 x 2
#>    State               Pop
#>    <chr>             <dbl>
#>  1 California     39613493
#>  2 Texas          29730311
#>  3 Florida        21944577
#>  4 New York       19299981
#>  5 Pennsylvania   12804123
#>  6 Illinois       12569321
#>  7 Ohio           11714618
#>  8 Georgia        10830007
#>  9 North Carolina 10701022
#> 10 Michigan        9992427
#> # ... with 42 more rows
\end{verbatim}

Finally, we'll bring in our geospatial data and save it as an object called usa\_states\_geom:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{usa\_states\_geom }\OtherTok{\textless{}{-}} \FunctionTok{usa\_sf}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(name) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{st\_transform}\NormalTok{(us\_laea\_proj)}
\end{Highlighting}
\end{Shaded}

The \texttt{usa\_sf()} function from the \texttt{albersusa} package gives us simple features data for all US states (and, conveniently, places Alaska and Hawaii in locations, and at a scale, that make them easy to see). This data includes multiple variables, but we need only the state names, so we keep the name variable only.

We then used the \texttt{st\_transform()} function from the \texttt{sf} package to change the coordinate reference system. The one used here comes from the \texttt{us\_laea\_proj} object, from the \texttt{albersusa} package. Remember the \emph{Albers equal-area conic convenience projection} we used to change the appearance of our Wyoming counties map? This is the same projection.

\hypertarget{calculating-daily-covid-cases}{%
\subsection*{Calculating Daily COVID Cases}\label{calculating-daily-covid-cases}}
\addcontentsline{toc}{subsection}{Calculating Daily COVID Cases}

Next, we need to calculate the number of daily COVID cases. We have to do this because the \texttt{covid\_data} data frame gives us cumulative cases by state, but not the number of cases per day:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{covid\_cases }\OtherTok{\textless{}{-}}\NormalTok{ covid\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(state) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{pd\_cases =} \FunctionTok{lag}\NormalTok{(cases)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{replace\_na}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{pd\_cases =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{daily\_cases =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{      cases }\SpecialCharTok{\textgreater{}}\NormalTok{ pd\_cases }\SpecialCharTok{\textasciitilde{}}\NormalTok{ cases }\SpecialCharTok{{-}}\NormalTok{ pd\_cases,}
      \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \DecValTok{0}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(state, date)}
\end{Highlighting}
\end{Shaded}

We use the \texttt{group\_by()} function to calculate totals for each state, then create a new variable called \texttt{pd\_cases}, which represents the number of cases in the previous day (we can use the \texttt{lag()} function to assign data to this variable). Some days do not have cases counts for the previous day, so in these cases, we set the value to 0 using the \texttt{replace\_na()} function. Finally, we create a new variable called \texttt{daily\_cases.} To set the value of this variable, we use the \texttt{case\_when()} function to set up a condition: if the \texttt{cases} variable (which holds the cases on that day) is greater than the \texttt{pd\_cases} variable (which holds cases from one day prior), then \texttt{daily\_cases} is equal to cases minus \texttt{pd\_cases}; otherwise, we set \texttt{daily\_cases} to be equal to 0. Because we grouped the data by state at the beginning, we must now remove this grouping using the \texttt{ungroup()} function before arranging our data by state and date. Now take a look at the \texttt{covid\_cases} data frame we created:

\begin{verbatim}
#> # A tibble: 61,102 x 6
#>    date       state   cases deaths pd_cases daily_cases
#>    <date>     <chr>   <dbl>  <dbl>    <dbl>       <dbl>
#>  1 2020-03-13 Alabama     6      0        0           6
#>  2 2020-03-14 Alabama    12      0        6           6
#>  3 2020-03-15 Alabama    23      0       12          11
#>  4 2020-03-16 Alabama    29      0       23           6
#>  5 2020-03-17 Alabama    39      0       29          10
#>  6 2020-03-18 Alabama    51      0       39          12
#>  7 2020-03-19 Alabama    78      0       51          27
#>  8 2020-03-20 Alabama   106      0       78          28
#>  9 2020-03-21 Alabama   131      0      106          25
#> 10 2020-03-22 Alabama   157      0      131          26
#> # ... with 61,092 more rows
\end{verbatim}

In the next step, we'll make use of the daily\_cases variable.

\hypertarget{calculating-incidence-rates}{%
\subsection*{Calculating Incidence Rates}\label{calculating-incidence-rates}}
\addcontentsline{toc}{subsection}{Calculating Incidence Rates}

We're not quite done calculating values. The data that Madjid used to make his map didn't include daily case counts. Instead, it contained a five-day rolling average of cases per 100,000 people. A \emph{rolling average} is the average case rate in a certain time period. Quirks of reporting (for example, not reporting on weekends but instead rolling Saturday and Sunday cases into Monday) can make the value for any single day less reliable. Using a rolling average smooths things out. Here is the code to generate this data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{covid\_cases }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{roll\_cases =} \FunctionTok{rollmean}\NormalTok{(}
\NormalTok{    daily\_cases,}
    \AttributeTok{k =} \DecValTok{5}\NormalTok{,}
    \AttributeTok{fill =} \ConstantTok{NA}
\NormalTok{  ))}
\end{Highlighting}
\end{Shaded}

We create a new data frame called \texttt{covid\_cases\_rm} (where \texttt{rm} stands for rolling mean). The first step in its creation is to use the \texttt{rollmean()} function from the zoo package to create a \texttt{roll\_cases} variable, which holds the average number of cases in the five-day period surrounding a single date. The \texttt{k} argument is the number of days for which we want to calculate the rolling average (five, in our case), and the \texttt{fill} argument determines what happens in cases like the first day, where we can't calculate a five-day rolling mean because there are no days prior to this day (Madjid set these values to be NA).

After calculating \texttt{roll\_cases}, we need to calculate per capita case rates. To do this, we needed population data, so we join the population data from the \texttt{usa\_states} data frame with the \texttt{covid\_cases} data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{left\_join}\NormalTok{(usa\_states,}
          \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"state"} \OtherTok{=} \StringTok{"State"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{drop\_na}\NormalTok{(Pop)}
\end{Highlighting}
\end{Shaded}

We then drop rows with missing population data (the \texttt{Pop} variable). In practice, this means getting rid of several US territories (American Samoa, Guam, Northern Marianas Islands, and Virgin Islands).
Next, we created a per capita case rate variable called \texttt{incidence\_rate} by multiplying the \texttt{roll\_cases} variable by 100,000 and then dividing it by the population of each state:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{incidence\_rate =} \DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ roll\_cases }\SpecialCharTok{/}\NormalTok{ Pop) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{incidence\_rate =} \FunctionTok{cut}\NormalTok{(incidence\_rate,}
                              \AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{5}\NormalTok{), }\ConstantTok{Inf}\NormalTok{),}
                              \AttributeTok{include.lowest =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
           \FunctionTok{factor}\NormalTok{(}\AttributeTok{labels =} \FunctionTok{paste0}\NormalTok{(}\StringTok{"\textgreater{}"}\NormalTok{, }\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{5}\NormalTok{))))}
\end{Highlighting}
\end{Shaded}

Rather than keeping raw values (for example, on June 29, 2021, Florida had a rate of 57.77737 cases per 100,000 people), we use the \texttt{cut()} function to convert the values into categories: values of \texttt{\textgreater{}0} (greater than zero), \texttt{\textgreater{}5} (greater than five), and so on, up to a maximum value of \texttt{\textgreater{}50} (greater than 50).

The last step is to filter the data so it includes only 2021 data (the only year depicted in Madjid's map) and select only the variables (\texttt{state}, \texttt{date}, and \texttt{incidence\_rate}) we'll need to create our map. Here is the final \texttt{covid\_cases\_rm} data frame.

\begin{verbatim}
#> # A tibble: 18,980 x 3
#>    state   date       incidence_rate
#>    <chr>   <date>     <fct>         
#>  1 Alabama 2021-01-01 >50           
#>  2 Alabama 2021-01-02 >50           
#>  3 Alabama 2021-01-03 >50           
#>  4 Alabama 2021-01-04 >50           
#>  5 Alabama 2021-01-05 >50           
#>  6 Alabama 2021-01-06 >50           
#>  7 Alabama 2021-01-07 >50           
#>  8 Alabama 2021-01-08 >50           
#>  9 Alabama 2021-01-09 >50           
#> 10 Alabama 2021-01-10 >50           
#> # ... with 18,970 more rows
\end{verbatim}

We now have a data frame that we can combine with our geospatial data.

\hypertarget{adding-geospatial-data}{%
\subsection*{Adding Geospatial Data}\label{adding-geospatial-data}}
\addcontentsline{toc}{subsection}{Adding Geospatial Data}

We've now used two of our three data sources (COVID case data and state population data) to create the \texttt{covid\_cases\_rm} data frame we'll need to make the map. Let's now use the third data source: the geospatial data we saved as \texttt{usa\_states\_geom.} Simple features data allows us to merge regular data frames and geospatial data, another mark in its favor:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{usa\_states\_geom }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(covid\_cases\_rm, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"name"} \OtherTok{=} \StringTok{"state"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We merge our \texttt{covid\_cases\_rm} data frame into the geospatial data, matching the name variable from \texttt{usa\_states\_geom} to the state variable in \texttt{covid\_cases\_rm}. Next, we create a new variable called \texttt{fancy\_date.} As the name implies, it's a nicely formatted version of the date (for example, \emph{Jan 01} instead of \emph{2021-01-01}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{usa\_states\_geom\_covid }\OtherTok{\textless{}{-}}\NormalTok{ usa\_states\_geom }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(covid\_cases\_rm, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"name"} \OtherTok{=} \StringTok{"state"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{fancy\_date =} \FunctionTok{fct\_inorder}\NormalTok{(}\FunctionTok{format}\NormalTok{(date, }\StringTok{"\%b. \%d"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{relocate}\NormalTok{(fancy\_date, }\AttributeTok{.before =}\NormalTok{ incidence\_rate)}
\end{Highlighting}
\end{Shaded}

The \texttt{format()} function does the formatting while the \texttt{fct\_inorder()} function makes the \texttt{fancy\_date} variable sort data by date (rather than, say, alphabetically, which would put August before January). Last, we use the \texttt{relocate()} function to put the \texttt{fancy\_date} column next to the date column. We save this data frame as \texttt{usa\_states\_geom\_covid}. Take a look at it:

\begin{verbatim}
#> Simple feature collection with 18615 features and 4 fields
#> Geometry type: MULTIPOLYGON
#> Dimension:     XY
#> Bounding box:  xmin: -2100000 ymin: -2500000 xmax: 2516374 ymax: 732103.3
#> CRS:           +proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +a=6370997 +b=6370997 +units=m +no_defs
#> First 10 features:
#>       name       date fancy_date incidence_rate
#> 1  Arizona 2021-01-01    Jan. 01            >50
#> 2  Arizona 2021-01-02    Jan. 02            >50
#> 3  Arizona 2021-01-03    Jan. 03            >50
#> 4  Arizona 2021-01-04    Jan. 04            >50
#> 5  Arizona 2021-01-05    Jan. 05            >50
#> 6  Arizona 2021-01-06    Jan. 06            >50
#> 7  Arizona 2021-01-07    Jan. 07            >50
#> 8  Arizona 2021-01-08    Jan. 08            >50
#> 9  Arizona 2021-01-09    Jan. 09            >50
#> 10 Arizona 2021-01-10    Jan. 10            >50
#>                          geometry
#> 1  MULTIPOLYGON (((-1111066 -8...
#> 2  MULTIPOLYGON (((-1111066 -8...
#> 3  MULTIPOLYGON (((-1111066 -8...
#> 4  MULTIPOLYGON (((-1111066 -8...
#> 5  MULTIPOLYGON (((-1111066 -8...
#> 6  MULTIPOLYGON (((-1111066 -8...
#> 7  MULTIPOLYGON (((-1111066 -8...
#> 8  MULTIPOLYGON (((-1111066 -8...
#> 9  MULTIPOLYGON (((-1111066 -8...
#> 10 MULTIPOLYGON (((-1111066 -8...
\end{verbatim}

We can see the metadata and \texttt{geometry} columns we discussed.

\hypertarget{making-the-map}{%
\subsection*{Making the Map}\label{making-the-map}}
\addcontentsline{toc}{subsection}{Making the Map}

It took a lot of work to end up with the surprisingly simple data frame \texttt{usa\_states\_geom\_covid.} And while the data may be simple, the code Madjid used to make his map is quite complex. In this section, we walk through it in pieces.

The final map is actually multiple maps, one for each day in 2021. Combining 365 days makes for a large final product, so instead of showing the code for every single day, we'll filter the \texttt{usa\_states\_geom\_covid} to show just the first six days in January:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{usa\_states\_geom\_covid\_six\_days }\OtherTok{\textless{}{-}}\NormalTok{ usa\_states\_geom\_covid }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(date }\SpecialCharTok{\textless{}=} \FunctionTok{as.Date}\NormalTok{(}\StringTok{"2021{-}01{-}06"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We save the result as a data frame called \texttt{usa\_states\_geom\_covid\_six\_days}. Here's what this data looks like:

\begin{verbatim}
#> Simple feature collection with 306 features and 4 fields
#> Geometry type: MULTIPOLYGON
#> Dimension:     XY
#> Bounding box:  xmin: -2100000 ymin: -2500000 xmax: 2516374 ymax: 732103.3
#> CRS:           +proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +a=6370997 +b=6370997 +units=m +no_defs
#> First 10 features:
#>        name       date fancy_date incidence_rate
#> 1   Arizona 2021-01-01    Jan. 01            >50
#> 2   Arizona 2021-01-02    Jan. 02            >50
#> 3   Arizona 2021-01-03    Jan. 03            >50
#> 4   Arizona 2021-01-04    Jan. 04            >50
#> 5   Arizona 2021-01-05    Jan. 05            >50
#> 6   Arizona 2021-01-06    Jan. 06            >50
#> 7  Arkansas 2021-01-01    Jan. 01            >50
#> 8  Arkansas 2021-01-02    Jan. 02            >50
#> 9  Arkansas 2021-01-03    Jan. 03            >50
#> 10 Arkansas 2021-01-04    Jan. 04            >50
#>                          geometry
#> 1  MULTIPOLYGON (((-1111066 -8...
#> 2  MULTIPOLYGON (((-1111066 -8...
#> 3  MULTIPOLYGON (((-1111066 -8...
#> 4  MULTIPOLYGON (((-1111066 -8...
#> 5  MULTIPOLYGON (((-1111066 -8...
#> 6  MULTIPOLYGON (((-1111066 -8...
#> 7  MULTIPOLYGON (((557903.1 -1...
#> 8  MULTIPOLYGON (((557903.1 -1...
#> 9  MULTIPOLYGON (((557903.1 -1...
#> 10 MULTIPOLYGON (((557903.1 -1...
\end{verbatim}

Madjid's map is giant, as it includes all 365 days. We'll change the size of a few elements so they fit in this book.

\hypertarget{generating-the-basic-map}{%
\subsubsection*{Generating the Basic Map}\label{generating-the-basic-map}}
\addcontentsline{toc}{subsubsection}{Generating the Basic Map}

Now that we have six days of data, let's make some maps. We'll revisit the three lines of code used to make our Wyoming maps, with some adornments to improve the quality of the visualization:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{usa\_states\_geom\_covid\_six\_days }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ incidence\_rate),}
    \AttributeTok{size =}\NormalTok{ .}\DecValTok{05}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"grey55"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}
    \FunctionTok{vars}\NormalTok{(fancy\_date),}
    \AttributeTok{strip.position =} \StringTok{"bottom"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We use \texttt{geom\_sf()} to plot the geospatial data, modifying a couple arguments. We use \texttt{size\ =\ .05} to make the state borders less prominent and \texttt{color\ =\ "grey55"} to set the borders to a medium gray color. Then, to make one map for each day, we use the \texttt{facet\_wrap()} function. The \texttt{vars(fancy\_date)} code specifies that the \texttt{fancy\_date} variable should be used to do the faceting (in other words, make one map for each day) and \texttt{strip.position\ =\ "bottom"} moves the labels \emph{Jan.~01}, \emph{Jan.~02}, and so on to the bottom of the maps. You can see the resulting map in Figure \ref{fig:basic-map}.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/basic-map-1} \caption{A map showing the incidence rate of COVID for the first six days of 2021}\label{fig:basic-map}
\end{figure}

\hypertarget{applying-data-visualization-principles-to-the-map}{%
\subsubsection*{Applying Data Visualization Principles to the Map}\label{applying-data-visualization-principles-to-the-map}}
\addcontentsline{toc}{subsubsection}{Applying Data Visualization Principles to the Map}

From here on out, all of the code that Abdoul Madjid uses is to improve the appearance of the maps. Many of the tweaks you will see below will feel familiar if you've read Chapter \ref{data-viz-chapter}. And that's a great benefit of making maps with ggplot: you can apply the same data visualization principles you learned when making charts to your maps as well.

The \texttt{scale\_fill\_discrete\_sequential()} function from the \texttt{colorspace} package sets the color scale. Madjid uses the ``rocket'' palette (the same palette that that Cédric Scherer and Georgios Karamanis used in Chapter \ref{data-viz-chapter}) and changes the legend title to ``COVID-19 INCIDENCE RATE.'' Within the \texttt{guide\_legend()} function, Madjid puts adjusts the position and alignment as well as text properties of the title. He also puts the colored squares in one row, adjusts their height and width, and tweaks the text properties of the labels (the ``\textgreater0,'' ``\textgreater5,'' and so on).

Next, Madjid adds a title and caption using the \texttt{labs()} function. From there on, Madjid uses \texttt{theme\_minimal()} (again, the same theme that Scherer and Karamanis used in Chapter \ref{data-viz-chapter}) before making tweaks using the \texttt{theme()} function. These tweaks include:

\begin{itemize}
\tightlist
\item
  Setting the font and text color.
\item
  Making the title and caption bold, adjusting their size, alignment, and the margins around them.
\item
  Adjusting the size of the strip text (the \emph{Jan 01}, \emph{Jan 02}, and so on) and making it bold.
\item
  Putting the legend on top of the maps and adding a bit of spacing around it.
\item
  Removing grid lines and the longitude and latitude lines.
\item
  Adding a bit of padding around the entire visualization and making the background a light gray.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{usa\_states\_geom\_covid\_six\_days }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ incidence\_rate),}
    \AttributeTok{size =}\NormalTok{ .}\DecValTok{05}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"transparent"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}
    \FunctionTok{vars}\NormalTok{(fancy\_date),}
    \AttributeTok{strip.position =} \StringTok{"bottom"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_discrete\_sequential}\NormalTok{(}
    \AttributeTok{palette =} \StringTok{"Rocket"}\NormalTok{,}
    \AttributeTok{name =} \StringTok{"COVID{-}19 INCIDENCE RATE"}\NormalTok{,}
    \AttributeTok{guide =} \FunctionTok{guide\_legend}\NormalTok{(}
      \AttributeTok{title.position =} \StringTok{"top"}\NormalTok{,}
      \AttributeTok{title.hjust =}\NormalTok{ .}\DecValTok{5}\NormalTok{,}
      \AttributeTok{title.theme =} \FunctionTok{element\_text}\NormalTok{(}
        \AttributeTok{family =} \StringTok{"Times New Roman"}\NormalTok{,}
        \AttributeTok{size =} \FunctionTok{rel}\NormalTok{(}\DecValTok{9}\NormalTok{),}
        \AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}
          \AttributeTok{b =}\NormalTok{ .}\DecValTok{1}\NormalTok{,}
          \AttributeTok{unit =} \StringTok{"cm"}
\NormalTok{        )}
\NormalTok{      ),}
      \AttributeTok{nrow =} \DecValTok{1}\NormalTok{,}
      \AttributeTok{keyheight =} \FunctionTok{unit}\NormalTok{(.}\DecValTok{3}\NormalTok{, }\StringTok{"cm"}\NormalTok{),}
      \AttributeTok{keywidth =} \FunctionTok{unit}\NormalTok{(.}\DecValTok{3}\NormalTok{, }\StringTok{"cm"}\NormalTok{),}
      \AttributeTok{label.theme =} \FunctionTok{element\_text}\NormalTok{(}
        \AttributeTok{family =} \StringTok{"Times New Roman"}\NormalTok{,}
        \AttributeTok{size =} \FunctionTok{rel}\NormalTok{(}\DecValTok{6}\NormalTok{),}
        \AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}
          \AttributeTok{r =} \DecValTok{5}\NormalTok{,}
          \AttributeTok{unit =} \StringTok{"pt"}
\NormalTok{        )}
\NormalTok{      )}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"2021 · A pandemic year"}\NormalTok{,}
       \AttributeTok{caption =} \StringTok{"Incidence rates are calculated for 100,000 people in each state.}
\StringTok{                  Inspired from a graphic in the DIE ZEIT newspaper of November 18, 2021.}
\StringTok{                  Data from NY Times · Tidytuesday Week{-}1 2022 · Abdoul ISSA BIDA."}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{family =} \StringTok{"Times New Roman"}\NormalTok{, }
                        \AttributeTok{color =} \StringTok{"\#111111"}\NormalTok{),}
    \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{size =} \FunctionTok{rel}\NormalTok{(}\FloatTok{2.5}\NormalTok{),}
      \AttributeTok{face =} \StringTok{"bold"}\NormalTok{,}
      \AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{,}
      \AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}\AttributeTok{t =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }
                      \AttributeTok{b =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }
                      \AttributeTok{unit =} \StringTok{"cm"}\NormalTok{)}
\NormalTok{    ),}
    \AttributeTok{plot.caption =} \FunctionTok{element\_text}\NormalTok{(}
      \AttributeTok{hjust =}\NormalTok{ .}\DecValTok{5}\NormalTok{,}
      \AttributeTok{face =} \StringTok{"bold"}\NormalTok{,}
      \AttributeTok{margin =} \FunctionTok{margin}\NormalTok{(}\AttributeTok{t =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }
                      \AttributeTok{b =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }
                      \AttributeTok{unit =} \StringTok{"cm"}\NormalTok{)),}
    \AttributeTok{strip.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \FunctionTok{rel}\NormalTok{(}\FloatTok{0.75}\NormalTok{), }
                              \AttributeTok{face =} \StringTok{"bold"}\NormalTok{),}
    \AttributeTok{legend.position =} \StringTok{"top"}\NormalTok{,}
    \AttributeTok{legend.box.spacing =} \FunctionTok{unit}\NormalTok{(.}\DecValTok{25}\NormalTok{, }\StringTok{"cm"}\NormalTok{),}
    \AttributeTok{panel.grid =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.text =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{plot.margin =} \FunctionTok{margin}\NormalTok{(}\AttributeTok{t =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }
                         \AttributeTok{r =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }
                         \AttributeTok{b =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }
                         \AttributeTok{l =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }
                         \AttributeTok{unit =} \StringTok{"cm"}\NormalTok{),}
    \AttributeTok{plot.background =} \FunctionTok{element\_rect}\NormalTok{(}\AttributeTok{fill =} \StringTok{"\#e5e4e2"}\NormalTok{, }
                                   \AttributeTok{color =} \ConstantTok{NA}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

And there we have it: Figure \ref{fig:final-map-map} shows our recreation of Abdoul Madjid's COVID-19 map.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/final-map-map-1} \caption{Our recreation of Abdoul Madjid's map}\label{fig:final-map-map}
\end{figure}

\hypertarget{making-your-own-maps}{%
\section*{Making Your Own Maps}\label{making-your-own-maps}}
\addcontentsline{toc}{section}{Making Your Own Maps}

You may now be wondering: okay, great, but how do I actually make my own maps? Let's talk about where you can find geospatial data, how to choose a projection, and how to wrangle geospatial data to get it ready for mapping.

\hypertarget{importing-raw-data}{%
\subsection*{Importing Raw Data}\label{importing-raw-data}}
\addcontentsline{toc}{subsection}{Importing Raw Data}

There are two ways to access simple features geospatial data. The first is to import raw data. Geospatial data can take a number of different formats. While ESRI shapefiles (with the \emph{.shp} extension) are the most common, you might also encounter GeoJSON files (\emph{.geojson}), KML files (\emph{.kml}), and others. Chapter 8 of \emph{Geocomputation with R} by Robin Lovelace, Jakub Nowosad, and Jannes Muenchow discusses this range of formats.

The good news for us is that a single function can read pretty much any type of geospatial data: \texttt{read\_sf()} from the \texttt{sf} package. Let's show an example of how it works. Say you've downloaded geospatial data about United States state boundaries from the website \emph{geojson.xyz} in GeoJSON format, then saved it in the \emph{data} folder as \emph{states.geojson}. You can then import this data using the \texttt{read\_sf()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{us\_states }\OtherTok{\textless{}{-}} \FunctionTok{read\_sf}\NormalTok{(}\AttributeTok{dsn =} \StringTok{"data/states.geojson"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The dsn argument (which stands for data source name) tells read\_sf() where to find the file. We save the data as the object \texttt{us\_states}.

\hypertarget{accessing-geospatial-data-using-r-functions}{%
\subsection*{Accessing Geospatial Data Using R Functions}\label{accessing-geospatial-data-using-r-functions}}
\addcontentsline{toc}{subsection}{Accessing Geospatial Data Using R Functions}

You'll sometimes have to work with raw data in this way, but not always. That's because certain R packages provide functions for accessing geospatial data. Madjid used the \texttt{usa\_sf()} function from the \texttt{albersusa} package to acquire his. Another package for accessing geospatial data related to the United States, \texttt{tigris}, has a number of well-named functions for different types of data. For example, we can load the \texttt{tigris} package and run the \texttt{states()} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tigris)}

\NormalTok{states\_tigris }\OtherTok{\textless{}{-}} \FunctionTok{states}\NormalTok{(}\AttributeTok{cb =} \ConstantTok{TRUE}\NormalTok{, }
                        \AttributeTok{resolution =} \StringTok{"20m"}\NormalTok{,}
                        \AttributeTok{progress\_bar =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We use the \texttt{cb\ =\ TRUE} argument to opt us out of using the most detailed shapefile and set the resolution to a more manageable 20m. Without these changes, the shapefile we'd get would be large and slow to work with. We also set \texttt{progress\_bar\ =\ FALSE} so we won't see the messages that \texttt{tigris} shares while it loads data. We then save the result as \texttt{states\_tigris}.

The \texttt{tigris} package has functions to get geospatial data about counties, census tracts, roads, and more. Kyle Walker, developer of the package, wrote a book, \emph{Analyzing US Census Data: Methods, Maps, and Models in R}, if you'd like to learn more about how to use it.

If you're looking for data outside of the United States, fear not! The \texttt{rnaturalearth} package provides functions for importing geospatial data from across the world. For example, \texttt{ne\_countries()} can retrieve geospatial data about various countries:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rnaturalearth)}

\NormalTok{africa\_countries }\OtherTok{\textless{}{-}} \FunctionTok{ne\_countries}\NormalTok{(}\AttributeTok{returnclass =} \StringTok{"sf"}\NormalTok{,}
                                 \AttributeTok{continent =} \StringTok{"Africa"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This code uses two arguments: \texttt{returnclass\ =\ "sf"} to get data in simple features format, and \texttt{continent\ =\ "Africa"} to get only countries on the African continent. If we save the result to an object called \texttt{africa\_countries}, we can plot the data on a map:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa\_countries }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:africa-map} shows the resulting map.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/africa-map-1} \caption{A map of Africa made with data from the rnaturalearth package}\label{fig:africa-map}
\end{figure}

If you need geospatial data, start by looking for a package like \texttt{albersusa}, \texttt{tigris}, or \texttt{rnaturalearth.} If you can't find one, fall back on using \texttt{read\_sf()} from the \texttt{sf} package.

\hypertarget{using-appropriate-projections}{%
\subsection*{Using Appropriate Projections}\label{using-appropriate-projections}}
\addcontentsline{toc}{subsection}{Using Appropriate Projections}

Once you have access to geospatial data, you need to decide which projection to use. If you're looking for a simple answer to this question, you'll be disappointed. As Robin Lovelace, Jakub Nowosad, and Jannes Muenchow put it in their book \emph{Geocomputation with R}, ``the question of \emph{which} CRS {[}to use{]} is tricky, and there is rarely a `right' answer.''

If you feel overwhelmed by the task of choosing a projection, the \texttt{crsuggest} package, also by Kyle Walker, can give you ideas. Its \texttt{suggest\_top\_crs()} function returns a coordinate reference system that is well-suited for your data. Let's load \texttt{crsuggest} and try it out on our \texttt{africa\_countries} data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(crsuggest)}

\NormalTok{africa\_countries }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{suggest\_top\_crs}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

The \texttt{suggest\_top\_crs()} function returns the projection number 28232. We can now use this value in combination with the \texttt{st\_transform()} function in order to change the projection before we plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa\_countries }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{st\_transform}\NormalTok{(}\DecValTok{28232}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

When run, this code generates the map in Figure \ref{fig:africa-map-different-projection}.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/africa-map-different-projection-1} \caption{A map of Africa made with projection number 28232}\label{fig:africa-map-different-projection}
\end{figure}

As you can see, we've mapped Africa with a different projection.

\hypertarget{bring-your-existing-r-skills-to-geospatial-data}{%
\subsection*{Bring Your Existing R Skills to Geospatial Data}\label{bring-your-existing-r-skills-to-geospatial-data}}
\addcontentsline{toc}{subsection}{Bring Your Existing R Skills to Geospatial Data}

The ability to merge traditional data frames with geospatial data is a huge benefit of working with simple features data. Remember that for his COVID map, Madjid analyzed traditional data frames before merging them with geospatial data. But because simple features data acts just like traditional data frames, we can just as easily apply the data-wrangling and analysis functions from \texttt{tidyverse} directly to a simple features object. To demonstrate this, let's return to the \texttt{africa\_countries} simple features data, selecting two variables (\texttt{name} and \texttt{pop\_est}) to see the name and population of the countries:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa\_countries }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(name, pop\_est)}
\end{Highlighting}
\end{Shaded}

The output looks like the following:

\begin{verbatim}
#> Simple feature collection with 51 features and 2 fields
#> Geometry type: MULTIPOLYGON
#> Dimension:     XY
#> Bounding box:  xmin: -17.62504 ymin: -34.81917 xmax: 51.13387 ymax: 37.34999
#> CRS:           +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
#> First 10 features:
#>                    name  pop_est
#> 1                Angola 12799293
#> 11              Burundi  8988091
#> 13                Benin  8791832
#> 14         Burkina Faso 15746232
#> 25             Botswana  1990876
#> 26 Central African Rep.  4511488
#> 31        Côte d'Ivoire 20617068
#> 32             Cameroon 18879301
#> 33      Dem. Rep. Congo 68692542
#> 34                Congo  4012809
#>                          geometry
#> 1  MULTIPOLYGON (((16.32653 -5...
#> 11 MULTIPOLYGON (((29.34 -4.49...
#> 13 MULTIPOLYGON (((2.691702 6....
#> 14 MULTIPOLYGON (((-2.827496 9...
#> 25 MULTIPOLYGON (((25.64916 -1...
#> 26 MULTIPOLYGON (((15.27946 7....
#> 31 MULTIPOLYGON (((-2.856125 4...
#> 32 MULTIPOLYGON (((13.07582 2....
#> 33 MULTIPOLYGON (((30.83386 3....
#> 34 MULTIPOLYGON (((12.99552 -4...
\end{verbatim}

Say we want to make a map showing which African countries have populations larger than 20 million. To do so, we'd need to first calculate this value for each country. Let's do this using the \texttt{mutate()} and \texttt{if\_else()} functions, which will return \texttt{TRUE} if a country's population is over 20 million and \texttt{FALSE} otherwise, then store the result in a variable called \texttt{population\_above\_20\_million}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa\_countries }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(name, pop\_est) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{population\_above\_20\_million =} \FunctionTok{if\_else}\NormalTok{(pop\_est }\SpecialCharTok{\textgreater{}} \DecValTok{20000000}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We can then take this code and pipe it into ggplot, setting the \texttt{fill} aesthetic property to be equal to \texttt{population\_above\_20\_million}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa\_countries }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(name, pop\_est) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{population\_above\_20\_million =} \FunctionTok{if\_else}\NormalTok{(pop\_est }\SpecialCharTok{\textgreater{}} \DecValTok{20000000}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ population\_above\_20\_million)) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This code generates the map shown in Figure \ref{fig:africa-map-20m}.

\begin{figure}
\includegraphics[width=1\linewidth]{maps_files/figure-latex/africa-map-20m-1} \caption{A map of Africa that highlights countries with populations above 20 million people}\label{fig:africa-map-20m}
\end{figure}

This is a simple example of the data wrangling and analysis you can perform on simple features data. The larger lesson is this: any skill you've developed for working with data in R will serve you well when working with geospatial data.

\hypertarget{in-conclusion-r-is-a-map-making-swiss-army-knife}{%
\section*{In Conclusion: R is a Map-Making Swiss Army Knife}\label{in-conclusion-r-is-a-map-making-swiss-army-knife}}
\addcontentsline{toc}{section}{In Conclusion: R is a Map-Making Swiss Army Knife}

In this short romp through the world of map-making in R, we discussed the basics of simple features geospatial data, reviewed how Abdoul Madjid applied this knowledge to make his map, discussed how to get your own geospatial data, and covered how to project it appropriately to make your own maps.

R may very well be the best tool for making maps. It's way more flexible than Excel, way less expensive than ArcGIS, and uses syntax you already know. It also lets you use the skills you've developed for working with traditional data frames and the ggplot code that makes your visualizations look great. After all, Madjid isn't a GIS expert, but he combined a basic understanding of geospatial data, fundamental R skills, and knowledge of data-visualization principles to make a beautiful map. Now it's your turn to do the same.

\hypertarget{tables-chapter}{%
\chapter{Making High-Quality Tables}\label{tables-chapter}}

In his book \emph{Fundamentals of Data Visualization}, Claus Wilke writes that ``tables are an important tool for visualizing data.'' This statement might seem might odd. Tables are often seen as the opposite of data visualization: plots are (or should be) highly-designed tools of communication; tables are where we dump numbers for the few nerds who care to read them. But Wilke sees things differently. Tables should not be data dumps devoid of design. He writes: ``because of their apparent simplicity, they may not always receive the attention they need.''

Tables should be treated as data visualization because \emph{that is exactly what they are}. As the term data visualization has become codified, it has become a synonym for graphs. But think about what the phrase data visualization really means. Don't overthink it. It simply means to visualize data. And while bars, lines, and points in graphs are visualizations, so too are numbers in a table. When we make tables, we visualize our data.

And since we're visualizing data, we should care about design. Need proof that good design matters when it comes to making tables? Look at tables made by reputable news organizations. Data dumps these are not. News organizations, whose job is to communicate clearly and effectively, pay a lot of attention to table design.

We saw in Chapter \ref{data-viz-chapter} that a few simple but significant tweaks can drastically improve the quality of our graphs. In this chapter, we'll see that a little bit of work can go a long way toward improving our tables.

The good news for you is that R is a great tool for making high-quality tables. If you are writing reports in R Markdown (which you can learn about in \ref{rmarkdown-chapter}), you can write code that will generate a table when you export your document. Working with the same tool to generate tables alongside your text and data visualization means you don't have to copy and paste your data, running the risk of human error.

Generating tables in Microsoft Word, the tool that many use to make tables, has other potential pitfalls. Claus Wilke found that his version of Word had 105 built-in table styles. Of those, around 80 percent violated some key principles of table design. Wilke writes:

\begin{quote}
So if you pick a Microsoft Word table layout at random, you have an 80\% chance of picking one that has issues. And if you pick the default, you will end up with a poorly formatted table every time.
\end{quote}

In R, there are a number of packages to make a wide range of tables. And within these packages, there are a number of functions designed to make sure your tables follow important design principles.

The rest of this chapter will examine what these design principles are and show how to apply them in your tables made in R. We'll begin by with a brief trip into the world of table design. After examining the principles that Claus Wilke and other experts recommend, we'll learn how to apply these principles. For this chapter, I spoke with Tom Mock of Posit (the company that makes RStudio), who has become something of an R table connoisseur. His 2020 blog post ``10+ Guidelines for Better Tables in R'' takes table design principles and shows how to implement them using the \texttt{gt} package. We'll walk through examples of Tom's code to show how small tweaks can make a big difference in improving your tables.

\hypertarget{table-design-principles}{%
\section*{Table Design Principles}\label{table-design-principles}}
\addcontentsline{toc}{section}{Table Design Principles}

Advice on data visualization has become ubiquitous in the last few years. Books, articles, blog posts, and more talk about how to make your graphs communicate effectively. Table design advice is less common, but it is out there. In addition to Claus Wilke, others including Jon Schwabish and Stephen Few have written about table design. All three of these experts come to discussing tables after having written about making effective graphs. The principles they discuss, not surprisingly, will sound similar to data visualization advice. The principles of effective communication apply no matter the form in which data is ultimately presented.

The principles below are adapted primarily from a conversation I had with Tom Mock, which focuses on his tables blog post. That blog post shows how to implement in R the ten table design principles that Jon Schwabish discusses in his article ``Ten Guidelines for Better Tables.'' Schwabish cites Stephen Few's work on table design. As you can see, the world of table design is closely connected. Rather than trying to and show every single principle that Schwabish discusses and Mock implements in R, I've selected what I think are six of the most important.

In this chapter, I use the \texttt{gt} package. This is one of the most popular table-making packages and, as we'll see below, it uses good design principles by default. The code below is a lightly adapted version of the code in Mock's blog post.

\hypertarget{principle-one-minimize-clutter}{%
\subsection*{Principle One: Minimize Clutter}\label{principle-one-minimize-clutter}}
\addcontentsline{toc}{subsection}{Principle One: Minimize Clutter}

As with data visualization, one of the most important principles of table design is to minimize clutter. One of the most important ways we can do this is by removing unnecessary elements. One of the most common unnecessary elements that clutter tables is gridlines. To show you how we can make more effective tables by removing gridlines, let's first load the packages we need. We're relying on the \texttt{tidyverse} package for general data manipulation functions, \texttt{gapminder} for the data we'll use, and \texttt{gt} to make the tables.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(gapminder)}
\FunctionTok{library}\NormalTok{(gt)}
\FunctionTok{library}\NormalTok{(gtExtras)}
\end{Highlighting}
\end{Shaded}

As we saw in Chapter \ref{data-viz-chapter}, the \texttt{gapminder} package provides data on country-level demographic statistics. To make a data frame we'll use for our table, let's use just a few countries (the first four in alphabetical order: Afghanistan, Albania, Algeria, and Angola) and a few years (1952, 1972, and 1992). The \texttt{gapminder} data has many years but we only need a few to demonstrate table-making principles.

I've created a data frame called \texttt{gdp}. Let's see what it looks like.

\begin{verbatim}
#> # A tibble: 4 x 4
#>   Country     `1952` `1972` `1992`
#>   <chr>        <dbl>  <dbl>  <dbl>
#> 1 Afghanistan   779.   740.   649.
#> 2 Albania      1601.  3313.  2497.
#> 3 Algeria      2449.  4183.  5023.
#> 4 Angola       3521.  5473.  2628.
\end{verbatim}

Now that we've created the data frame we can work with, it's time to talk about reducing clutter by getting rid of gridlines. Often, you see tables that look like this:

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05001} \caption{Table with gridlines everywhere}\label{fig:unnamed-chunk-6}
\end{figure}

Having gridlines around every single cell in our table is unnecessary and creates visual clutter that distracts from the goal of communicating clearly. A table with minimal or even no gridlines is a much more effective communication tool.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05002} \caption{Table with only horizontal gridlines}\label{fig:table-horizontal-gridlines}
\end{figure}

You know how I mentioned before that \texttt{gt} uses good table design principles by default? This is a great example of it. The second table, with minimal gridlines, requires just two lines. We pipe our \texttt{gdp} data into the \texttt{gt()} function, which creates a table.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gdp }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

To make the example with gridlines everywhere, we would have to add additional code. The code that follows \texttt{gt()} here adds gridlines.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gdp }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}
    \AttributeTok{style =} \FunctionTok{cell\_borders}\NormalTok{(}
      \AttributeTok{side =} \StringTok{"all"}\NormalTok{,}
      \AttributeTok{color =} \StringTok{"black"}\NormalTok{,}
      \AttributeTok{weight =} \FunctionTok{px}\NormalTok{(}\DecValTok{1}\NormalTok{),}
      \AttributeTok{style =} \StringTok{"solid"}
\NormalTok{    ),}
    \AttributeTok{locations =} \FunctionTok{list}\NormalTok{(}
      \FunctionTok{cells\_body}\NormalTok{(}
        \FunctionTok{everything}\NormalTok{()}
\NormalTok{      ),}
      \FunctionTok{cells\_column\_labels}\NormalTok{(}
        \FunctionTok{everything}\NormalTok{()}
\NormalTok{      )}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{opt\_table\_lines}\NormalTok{(}\AttributeTok{extent =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Since I don't recommend doing this, I won't walk through the code. The important thing to remember is that you get good defaults using \texttt{gt()}. Take advantage of them!

If we wanted to remove additional gridlines, we could use the following code. The \texttt{tab\_style()} function uses a two-step approach:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify the style we want to modify (in this case the borders).
\item
  Tell the function where to apply these styles.
\end{enumerate}

Here, we tell \texttt{tab\_style()} that we want to modify the borders using the \texttt{cell\_borders()} function, making our borders transparent. Then, we say that we want this to apply to the \texttt{cells\_body()} location (other options include \texttt{cells\_column\_labels()} for the row with country, 1952, 1972, and 1992).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gdp }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}
    \AttributeTok{style =} \FunctionTok{cell\_borders}\NormalTok{(}\AttributeTok{color =} \StringTok{"transparent"}\NormalTok{),}
    \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Doing this gives us a table with no gridlines at all in the body.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05003} \caption{Table with gridlines only on the header row and bottom}\label{fig:unnamed-chunk-11}
\end{figure}

I'll then save this table as an object called \texttt{table\_no\_gridlines} so that we can add onto it below.

\hypertarget{principle-two-differentiate-the-header-from-the-body}{%
\subsection*{Principle Two: Differentiate the Header from the Body}\label{principle-two-differentiate-the-header-from-the-body}}
\addcontentsline{toc}{subsection}{Principle Two: Differentiate the Header from the Body}

While reducing clutter is an important goal, going too far can have negative consequences. A table with no gridlines at all can make it hard to differentiate between the header row and the table body.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05004} \caption{Table with all gridlines removed}\label{fig:unnamed-chunk-14}
\end{figure}

We saw how to use appropriate gridlines above. We can make our header row bold to make it stand out even more. We start with the \texttt{table\_no\_gridlines} object (our saved table from above). Then, we apply our formatting with the \texttt{tab\_style()} function two-step, first saying we want to alter the text (using the \texttt{cell\_text()} function) by setting the weight to bold and then saying we want this to happen only to the header row (using the \texttt{cells\_column\_labels()} function).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table\_no\_gridlines }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}
    \AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
    \AttributeTok{locations =} \FunctionTok{cells\_column\_labels}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We can see what our table with headers bolded looks like below.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05005} \caption{Table with header row bolded}\label{fig:unnamed-chunk-17}
\end{figure}

Let's save this table as \texttt{table\_bold\_header} in order to reuse it below and add additional formatting on top of what's already there.

\hypertarget{principle-three-align-appropriately}{%
\subsection*{Principle Three: Align Appropriately}\label{principle-three-align-appropriately}}
\addcontentsline{toc}{subsection}{Principle Three: Align Appropriately}

A third principle of high-quality table design is appropriate alignment. Specifically, numbers in tables should be right-aligned. Tom Mock explains why:

\begin{quote}
Left-alignment or center-alignment of numbers impairs the ability to clearly compare numbers and decimal places. Right-alignment lets you align decimal places and numbers for easy parsing.
\end{quote}

We can see this in action. In the table below, we've left aligned 1952, center aligned 1972, and right aligned 1992. You can see how much easier it is to compare the values in 1992 than in the other two columns. In both 1952 and 1972, it is much more difficult to compare the numeric values because the numbers in the same columns (the tens place, for example) are not in the same vertical position. In 1992, however, the number in the tens place in Afghanistan (4) aligns with the number in the tens place in Albania (9) and all other countries. This vertical alignment makes it easier to scan the table.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05006} \caption{Table with year columns aligned left, center, and right}\label{fig:unnamed-chunk-20}
\end{figure}

As with other tables, we've actually had to override the defaults to get the \texttt{gt} package to misalign the columns (code shown below). By default, \texttt{gt} will right align numeric values. So, just don't change anything and you'll be golden!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table\_bold\_header }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{cols\_align}\NormalTok{(}\AttributeTok{align =} \StringTok{"left"}\NormalTok{,}
             \AttributeTok{columns =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{cols\_align}\NormalTok{(}\AttributeTok{align =} \StringTok{"center"}\NormalTok{,}
             \AttributeTok{columns =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{cols\_align}\NormalTok{(}\AttributeTok{align =} \StringTok{"right"}\NormalTok{,}
             \AttributeTok{columns =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Right alignment is best practice for numeric columns, but for text columns, we want to use left alignment. As Jon Scwabish points out, it's much easier to read longer text cells when they are left aligned. This is even easier to see if we add a country with a long name to our table. I've added Bosnia and Herzegovina and saved this as a data frame called \texttt{gdp\_with\_bosnia}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gdp\_with\_bosnia}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 4}
\CommentTok{\#\textgreater{}   Country                \textasciigrave{}1952\textasciigrave{} \textasciigrave{}1972\textasciigrave{} \textasciigrave{}1992\textasciigrave{}}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}                   \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Afghanistan              779.   740.   649.}
\CommentTok{\#\textgreater{} 2 Albania                 1601.  3313.  2497.}
\CommentTok{\#\textgreater{} 3 Algeria                 2449.  4183.  5023.}
\CommentTok{\#\textgreater{} 4 Angola                  3521.  5473.  2628.}
\CommentTok{\#\textgreater{} 5 Bosnia and Herzegovina   974.  2860.  2547.}
\end{Highlighting}
\end{Shaded}

Let's then take the \texttt{gdp\_with\_bosnia} data frame and create a table with the country column center aligned. In this table, it is hard to scan the country names and that center-aligned column just looks a bit weird.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05007} \caption{Table with country column center aligned}\label{fig:unnamed-chunk-25}
\end{figure}

This is another example where we've had to change the \texttt{gt} defaults to mess things up. The \texttt{gt} package has good default alignment practices for other column types as well. In addition to right aligning numeric columns by default, it will also left align character columns. So, if we don't touch anything, \texttt{gt} will give us the alignment we're looking for.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05008} \caption{Table with country column left aligned}\label{fig:unnamed-chunk-27}
\end{figure}

If you ever do want to override the default alignments, you can use the \texttt{cols\_align()} function. Within this function, we use the \texttt{columns} argument to tell \texttt{gt} which columns to align and the \texttt{align} argument to select our alignment. That table above with the country names center aligned? Here's how I made it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gdp\_with\_bosnia }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}
    \AttributeTok{style =} \FunctionTok{cell\_borders}\NormalTok{(}\AttributeTok{color =} \StringTok{"transparent"}\NormalTok{),}
    \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{()}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}
    \AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
    \AttributeTok{locations =} \FunctionTok{cells\_column\_labels}\NormalTok{()}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{cols\_align}\NormalTok{(}\AttributeTok{columns =} \StringTok{"Country"}\NormalTok{,}
             \AttributeTok{align =} \StringTok{"center"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{principle-four-use-the-right-level-of-precision}{%
\subsection*{Principle Four: Use the Right Level of Precision}\label{principle-four-use-the-right-level-of-precision}}
\addcontentsline{toc}{subsection}{Principle Four: Use the Right Level of Precision}

In all of the tables we've made so far, we've used the data exactly as it came to us. In all of the numeric columns, we have data to four decimal places. This is almost certainly too many. Having more decimal places than necessary makes our table harder to read. There is always a balance between what Jon Schwabish describes as ``necessary precision and a clean, spare table.'' I've also heard it described that, if adding additional decimal places would change some action, keep them; otherwise, take them. out My general experience is that people tend to leave too many decimal places in, assuming that accuracy to a very high degree is more important than it is (and, in the process, they reduce the legibility of their tables).

Looking at our GDP table, we can use the \texttt{fmt\_currency()} function to format our numeric values. The \texttt{gt} package has a whole series of functions for formatting values in tables. All of these functions start with \texttt{fmt\_}. In the code below, we set \texttt{fmt\_currency()} to be applied to the 1952, 1972, and 1992 columns. I then use \texttt{decimals} argument to tell \texttt{fmt\_currency()} to format the values with zero decimal places (the difference between a GDP of \$799.4453 and \$779 is unlikely to lead to different decisions so I'm comfortable with sacrificing precision for legibility).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table\_bold\_header }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{fmt\_currency}\NormalTok{(}
    \AttributeTok{columns =} \FunctionTok{c}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{),}
    \AttributeTok{decimals =} \DecValTok{0}
\NormalTok{  ) }
\end{Highlighting}
\end{Shaded}

What we end up with is values formatted as dollars, with a thousands-place comma automatically added by \texttt{fmt\_currency()} to make the values even easier to read.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05009} \caption{Table with numbers rounded to whole numbers and dollar sign added}\label{fig:unnamed-chunk-31}
\end{figure}

Let's now save our table for reuse below.

\hypertarget{principle-five-use-color-intentionally}{%
\subsection*{Principle Five: Use Color Intentionally}\label{principle-five-use-color-intentionally}}
\addcontentsline{toc}{subsection}{Principle Five: Use Color Intentionally}

Up to this point, our table has not had any color. We're now going to add some, using color to highlight outliers. Especially for those readers who want to scan your table, highlighting outliers with color can help significantly. Let's make the highest value in any single year a different color. To do this, we again use the \texttt{tab\_style()} function. Within this function, I'm using the \texttt{cell\_text()} function to change both the color of text to orange and make it bold. I'm then using the \texttt{locations} argument to say that we want to adjust cells in the body of the table. Within the \texttt{cells\_body()} function, we have to specify both the columns we want to apply our change to and the rows. If we just look at 1952, we see that we set the columns equal to that year. The rows are set to a more complicated formula. The text rows = \texttt{1952} == max(\texttt{1952}) means that the text transformation will occur in rows where the value is equal to the maximum value in that year.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table\_whole\_numbers }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}\AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"orange"}\NormalTok{,}
                              \AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
            \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{(}
              \AttributeTok{columns =} \StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{,}
              \AttributeTok{rows =} \StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \FunctionTok{max}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{            )) }
\end{Highlighting}
\end{Shaded}

We then repeat this same code for 1972 and 1992, with the result shown below.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05010} \caption{Table with color added to show the highest value in each year}\label{fig:unnamed-chunk-35}
\end{figure}

As always, we save this table to avoid having to repeat all of the formatting code we've created up to this point.

\hypertarget{principle-six-add-data-visualization-where-appropriate}{%
\subsection*{Principle Six: Add Data Visualization Where Appropriate}\label{principle-six-add-data-visualization-where-appropriate}}
\addcontentsline{toc}{subsection}{Principle Six: Add Data Visualization Where Appropriate}

Adding color to highlight outliers is one way to help guide the reader's attention. Another way is to incorporate graphs into tables. Tom Mock has developed an add-on package for \texttt{gt} called \texttt{gtExtras} that makes it possible to do just this. In our table that we've made we might want to show the trend of GDP by country. To do that, we'll add a new column that shows this trend using a sparkline (essentially, a simple line chart). The \texttt{gt\_plt\_sparkline()} function that we'll use to do this requires us to have a single column with all of the values needed to make the sparkline. We'll create a variable called \texttt{Trend} using \texttt{group\_by()} and \texttt{mutate()}. This variable will be a list of the values for each country (so, for Afghanistan, it would be 779.4453145, 739.9811058, and 649.3413952). We'll save this as an object called \texttt{gdp\_with\_trend}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gdp\_with\_trend }\OtherTok{\textless{}{-}}\NormalTok{ gdp }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(Country) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Trend =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ungroup}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

From there, we create our table, same as before. But at the end of our code, we add the \texttt{gt\_plt\_sparkline()} function. Within this function, we specify which column to use to create the sparkline (\texttt{Trend}). We set \texttt{label\ =\ FALSE} to remove text labels that \texttt{gt\_plt\_sparkline()} adds by default. And we add \texttt{palette\ =\ c("black",\ "transparent",\ "transparent",\ "transparent",\ "transparent")} to make the sparkline black and all other elements of it transparent (by default, the function will make different parts of the sparkline different colors).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gdp\_with\_trend }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}
    \AttributeTok{style =} \FunctionTok{cell\_borders}\NormalTok{(}\AttributeTok{color =} \StringTok{"transparent"}\NormalTok{),}
    \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{()}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tab\_style}\NormalTok{(}
    \AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
    \AttributeTok{locations =} \FunctionTok{cells\_column\_labels}\NormalTok{()}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{fmt\_currency}\NormalTok{(}
    \AttributeTok{columns =} \FunctionTok{c}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{),}
    \AttributeTok{decimals =} \DecValTok{0}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}\AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"orange"}\NormalTok{,}
                              \AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
            \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{(}
              \AttributeTok{columns =} \StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{,}
              \AttributeTok{rows =} \StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \FunctionTok{max}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{            )) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}\AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"orange"}\NormalTok{,}
                              \AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
            \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{(}
              \AttributeTok{columns =} \StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{,}
              \AttributeTok{rows =} \StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \FunctionTok{max}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{            )) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}\AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"orange"}\NormalTok{,}
                              \AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
            \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{(}
              \AttributeTok{columns =} \StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{,}
              \AttributeTok{rows =} \StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \FunctionTok{max}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{            )) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt\_plt\_sparkline}\NormalTok{(}\AttributeTok{column =}\NormalTok{ Trend,}
                   \AttributeTok{label =} \ConstantTok{FALSE}\NormalTok{,}
                   \AttributeTok{palette =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"transparent"}\NormalTok{, }\StringTok{"transparent"}\NormalTok{, }\StringTok{"transparent"}\NormalTok{, }\StringTok{"transparent"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

This stripped-down sparkline now allows the reader to see the trend for each country at a glance.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05011} \caption{Table with sparkline added to show trend over time}\label{fig:unnamed-chunk-40}
\end{figure}

\hypertarget{conclusion}{%
\section*{Conclusion}\label{conclusion}}
\addcontentsline{toc}{section}{Conclusion}

Many of the tweaks we made to create an effective table are quite subtle. Things like removing excess gridlines, bolding header text, right aligning numeric values, and adjusting the level of precision can often go unnoticed. But skip them and your table will be far less effective. What we ended up with is not flashy, but it does communicate clearly, which is the main goal of tables.

We used the \texttt{gt} package to make a high-quality table. One benefit of using this package is that we were able to use the \texttt{gt\_plt\_sparkline()} function from the \texttt{gtExtras} package to easily add a sparkline to our table. \texttt{gtExtras} does way more than this, though. This package has a set of ``theme'' functions to allow you to make your tables look like those made by FiveThirtyEight, the \emph{New York Times}, the \emph{Guardian}, and other news outlets. I've removed the formatting we created and instead used the \texttt{gt\_theme\_538()} function to make our tables look like they came from that organization.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gdp }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(Country) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Trend =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}\AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"orange"}\NormalTok{,}
                              \AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
            \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{(}
              \AttributeTok{columns =} \StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{,}
              \AttributeTok{rows =} \StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \FunctionTok{max}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{            )) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}\AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"orange"}\NormalTok{,}
                              \AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
            \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{(}
              \AttributeTok{columns =} \StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{,}
              \AttributeTok{rows =} \StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \FunctionTok{max}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{            )) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tab\_style}\NormalTok{(}\AttributeTok{style =} \FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"orange"}\NormalTok{,}
                              \AttributeTok{weight =} \StringTok{"bold"}\NormalTok{),}
            \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{(}
              \AttributeTok{columns =} \StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{,}
              \AttributeTok{rows =} \StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}} \SpecialCharTok{==} \FunctionTok{max}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{)}
\NormalTok{            )) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{fmt\_currency}\NormalTok{(}
    \AttributeTok{columns =} \FunctionTok{c}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{1952}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1972}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{1992}\StringTok{\textasciigrave{}}\NormalTok{),}
    \AttributeTok{decimals =} \DecValTok{0}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt\_plt\_sparkline}\NormalTok{(}\AttributeTok{column =}\NormalTok{ Trend,}
                   \AttributeTok{label =} \ConstantTok{FALSE}\NormalTok{,}
                   \AttributeTok{palette =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"transparent"}\NormalTok{, }\StringTok{"transparent"}\NormalTok{, }\StringTok{"transparent"}\NormalTok{, }\StringTok{"transparent"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{gt\_theme\_538}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Take a look at tables on the FiveThirtyEight website and you'll see the similarities to this table.

\begin{figure}
\includegraphics[width=1\linewidth]{nostarch/temp/F05012} \caption{Table redone in FiveThirtyEight style}\label{fig:unnamed-chunk-43}
\end{figure}

Add-on packages like \texttt{gtExtras} are common in the table-making landscape. If you are working with the \texttt{reactable} package to make interactive tables, for example, you can also use the \texttt{reactablefmtr} to add interactive sparklines, themes, and more. The functionality that you get from these packages is enough to never make you go back to making tables in Word!

No matter which package you use to make tables, it's essential to treat them as worthy of as much thought as data visualization (because, let me remind you, tables \emph{are} data visualization). Good tables are well designed; they are not data dumps. And fortunately for us, R is well-suited to making well designed tables. The \texttt{gt} package, as we've repeatedly seen, has good defaults built in. Oftentimes, you don't need to change much to end up with high-quality tables.

And it's not just that we have good packages to make tables. R is a great tool for making tables because it's the tool you're already using to create your reports (especially if you're using R Markdown, a tool we discuss in \ref{rmarkdown-chapter}). What better than using just a few lines of code to make publication-ready tables?

\hypertarget{part-communicate}{%
\part*{Communicate}\label{part-communicate}}
\addcontentsline{toc}{part}{Communicate}

\hypertarget{rmarkdown-chapter}{%
\chapter{Communicating with R Markdown}\label{rmarkdown-chapter}}

Imagine this: It's January, and you've collected surveys about customer satisfaction with your new product. Now you're ready to analyze the data and write up your results. Your workflow looks something like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Download your data from Google Sheets and import it into a statistical analysis tool like SPSS.
\item
  Use SPSS to clean and analyze your data.
\item
  Export summaries of your data as Excel spreadsheets.
\item
  Use Excel to make some charts.
\item
  Write your report in Word, copying in your charts from Excel along the way.
\end{enumerate}

Sound familiar? If so, you're not alone. Many people use this workflow for data analysis. But what happens when, in February, new surveys roll in, and you have to redo your report? Yup, back through steps one through five. You might think this multi-tool process works for one-time project, but let's be honest: few projects are really one-time. For example, you might realize you forgot to include a few surveys in your original analysis or catch a mistake.

R Markdown combines data analysis, data visualization, and other R code with narrative text to create a document that can be exported to many formats, including Word, PDF, and HTML, so that you can share them with non-R users. When you use a single tool, your workflow becomes way more efficient. Need to recreate that January report in February to see if customers are liking your product more this month? Just rerun your code and you've got a new report, complete with the newest data. Need to fix an error in your analysis? Adjust your code, rerun it, and your corrected report is ready to go.
In this chapter, we'll break down the pieces of R Markdown documents, then talk about some potential pitfalls and best practices.

\hypertarget{how-r-markdown-works}{%
\section*{How R Markdown Works}\label{how-r-markdown-works}}
\addcontentsline{toc}{section}{How R Markdown Works}

To create an R Markdown document while working in RStudio, go to File \textgreater{} New File \textgreater{} R Markdown (it is possible to make R Markdown documents with other editors, but the process looks a bit different). Choose a title, author, and date, as well as your default output format (HTML, PDF, or Word). All of these values can be changed later. Press OK, and RStudio will create an R Markdown document with some placeholder content, as seen in Figure \ref{fig:default-rmd-content}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/default-rmd-content} \caption{The placeholder content in a new R Markdown document}\label{fig:default-rmd-content}
\end{figure}

My first step is always to delete the content and replace it with my own. Let's create a report about penguins using data from the \texttt{palmerpenguins} package. I've broken it into pieces by year, and we'll use just the 2007 data. Here is the content I'll add to my R Markdown document.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\AnnotationTok{title:}\CommentTok{ "Penguins Report"}
\AnnotationTok{author:}\CommentTok{ "David"}
\AnnotationTok{date:}\CommentTok{ "2024{-}01{-}12"}
\AnnotationTok{output:}\CommentTok{ word\_document}
\CommentTok{{-}{-}{-}}
  
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r setup, include = FALSE\}}
\InformationTok{knitr::opts\_chunk$set(include = TRUE, }
\InformationTok{                      echo = FALSE,}
\InformationTok{                      message = FALSE,}
\InformationTok{                      warning = FALSE)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{library(tidyverse)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{penguins \textless{}{-} read\_csv("https://raw.githubusercontent.com/rfortherestofus/r{-}without{-}statistics/main/data/penguins{-}2007.csv")}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\FunctionTok{\# Introduction}

\NormalTok{We are writing a report about the **Palmer Penguins**. These penguins are *really* amazing. There are three species:}

\SpecialStringTok{{-} }\NormalTok{Adelie}
\SpecialStringTok{{-} }\NormalTok{Gentoo}
\SpecialStringTok{{-} }\NormalTok{Chinstrap}

\FunctionTok{\#\# Bill Length}

\NormalTok{We can make a histogram to see the distribution of bill lengths.}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{penguins \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = bill\_length\_mm)) +}
\InformationTok{  geom\_histogram() +}
\InformationTok{  theme\_minimal()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{average\_bill\_length \textless{}{-} penguins \%\textgreater{}\% }
\InformationTok{  summarize(avg\_bill\_length = mean(bill\_length\_mm,}
\InformationTok{                                   na.rm = TRUE)) \%\textgreater{}\% }
\InformationTok{  pull(avg\_bill\_length)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\NormalTok{The chart shows the distribution of bill lengths. The average bill length is }\InformationTok{\textasciigrave{}r average\_bill\_length\textasciigrave{}}\NormalTok{ millimeters.}
\end{Highlighting}
\end{Shaded}

This document has several pieces, each of which we will discuss below. First, though, let's skip straight to the finish line by doing what's called knitting our document (also known as rendering or, in plain English, exporting). The Knit button at the top of RStudio converts the R Markdown document into whatever format we selected upon creating it (Figure \ref{fig:knit-button}).

\begin{figure}
\includegraphics[width=1\linewidth]{assets/knit-button} \caption{The knit button in RStudio}\label{fig:knit-button}
\end{figure}

We've set the output format to be Word (see the \texttt{output\_format:\ word\_document\ line}), so you should now have a Word document. Some features were not visible in R Markdown but should appear in Word: the histogram, for example. This is because the R Markdown document doesn't directly include this plot. Rather, it includes the code needed to produce the plot when knitted.
It may seem convoluted to constantly knit R Markdown documents to Word, but this workflow allows us to update our reports at any point with new code or data. This ability is known as \emph{reproducibility}, and it is central to the value of R Markdown.

\hypertarget{document-structure}{%
\section*{Document Structure}\label{document-structure}}
\addcontentsline{toc}{section}{Document Structure}

All R Markdown documents have three main pieces: one YAML section, multiple R code chunks, and sections of Markdown text. Figure \ref{fig:rmarkdown-pieces} shows these parts of an R Markdown document.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/rmarkdown-pieces} \caption{All of the pieces of an R Markdown document}\label{fig:rmarkdown-pieces}
\end{figure}

Let's take these pieces one at a time.

\hypertarget{the-yaml-metadata}{%
\subsection*{The YAML Metadata}\label{the-yaml-metadata}}
\addcontentsline{toc}{subsection}{The YAML Metadata}

The YAML section is the very beginning of an R Markdown document. (The name YAML comes from the recursive acronym \emph{YAML ain't markup language}, whose meaning isn't important for our purposes.) Three dashes indicate its beginning and end, and the text inside of it contains metadata about the R Markdown document. Here is my YAML:

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{{-}{-}{-}}
\FunctionTok{title}\KeywordTok{:}\AttributeTok{ }\StringTok{"Penguins Report"}
\FunctionTok{author}\KeywordTok{:}\AttributeTok{ }\StringTok{"David Keyes"}
\FunctionTok{date}\KeywordTok{:}\AttributeTok{ }\StringTok{"2024{-}01{-}12"}
\FunctionTok{output}\KeywordTok{:}\AttributeTok{ word\_document}
\PreprocessorTok{{-}{-}{-}}
\end{Highlighting}
\end{Shaded}

As you can see, it provides the title, author, date, and output format. The title, author, and date will go on the top of the knitted report while the output determines what format that knitted report takes. All elements of the YAML are given in \texttt{key:\ value} syntax where \texttt{key} is the piece of metadata (for example, title) followed by its \texttt{value}.

\hypertarget{the-code-chunks}{%
\subsection*{The Code Chunks}\label{the-code-chunks}}
\addcontentsline{toc}{subsection}{The Code Chunks}

R Markdown documents have a different structure from the R script files you might be familiar with (those with the \emph{.R} extension). R script files treat all content as code unless you comment out a line by putting a pound sign (\texttt{\#}) in front of it. In the following code, the first line is a comment while the second line is code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\NormalTok{\# Import our data}
\NormalTok{data \textless{}{-} read\_csv("data.csv")}
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

In R Markdown, the situation is reversed. Everything after the YAML is treated as text unless we specify otherwise by creating what are known as \emph{code chunks}. These start with three back ticks (```), followed by the lowercase letter \texttt{r} surrounded by curly brackets ( \texttt{\{\}} ). Another three back ticks indicate the end of the code chunk:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\NormalTok{library(tidyverse)}
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

If you're working in RStudio, code chunks should have a light gray background.

Anything in the code chunk is treated as R code when we knit. For example, this code chunk will produce a histogram in the final Word document.

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{penguins \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = bill\_length\_mm)) +}
\InformationTok{  geom\_histogram() +}
\InformationTok{  theme\_minimal()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

The histogram made from this code can be seen in Figure \ref{fig:simple-histogram}.

\begin{figure}
\includegraphics[width=1\linewidth]{rmarkdown_files/figure-latex/simple-histogram-1} \caption{A simple histogram}\label{fig:simple-histogram}
\end{figure}

\hypertarget{code-chunk-options}{%
\subsubsection*{Code Chunk Options}\label{code-chunk-options}}
\addcontentsline{toc}{subsubsection}{Code Chunk Options}

A special code chunk at the top of each R Markdown document, known as the \emph{setup code chunk}, gives instructions for what should happen when knitting a document. It contains the following code chunk options:

\begin{itemize}
\item
  \texttt{echo}: Do you want to show the code itself in our knitted document?
\item
  \texttt{include}: Do you want to show the output of the code chunk?
\item
  \texttt{message}: Do you want to include any messages that code generates? For example, this message shows up when you run \texttt{library(tidyverse)}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{── Attaching core tidyverse packages ───── tidyverse 1.3.2.9000 ──}
\NormalTok{✔ dplyr     1.0.10     ✔ readr     2.1.3 }
\NormalTok{✔ forcats   0.5.2      ✔ stringr   1.5.0 }
\NormalTok{✔ ggplot2   3.4.0      ✔ tibble    3.1.8 }
\NormalTok{✔ lubridate 1.9.0      ✔ tidyr     1.2.1 }
\NormalTok{✔ purrr     1.0.1      }
\NormalTok{── Conflicts───── tidyverse\_conflicts() ──}
\NormalTok{✖ dplyr::filter() masks stats::filter()}
\NormalTok{✖ dplyr::lag()    masks stats::lag()}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \texttt{warning}: Do you want to include any messages that the code might generate? For example, here is the message you get when creating a histogram using \texttt{geom\_histogram()}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\textasciigrave{}stat\_bin()\textasciigrave{} using \textasciigrave{}bins = 30\textasciigrave{}. Pick better value with \textasciigrave{}binwidth\textasciigrave{}.}
\end{Highlighting}
\end{Shaded}

In cases where you're using R Markdown to generate a report for a non-R user, you likely want to hide the code, messages, and warnings but show the output (which would include any visualizations you generate). To do this, create a \texttt{setup} code chunk that looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r setup, include = FALSE\}}
\InformationTok{knitr::opts\_chunk$set(include = TRUE, }
\InformationTok{                      echo = FALSE,}
\InformationTok{                      message = FALSE,}
\InformationTok{                      warning = FALSE)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

The setup code chunk is a bit of a brain twister. The \texttt{include\ =\ FALSE} option on the first line applies to the setup code chunk itself. It tells R Markdown to not include the output of the setup code chunk on knitting. The options within \texttt{knitr::opts\_chunk\$set()} apply to all future code chunks. apply to all subsequent code chunks. However, you can also override these global code chunk options on individual chunks. If I wanted my Word document to show both the plot itself and the code used to make it, I could set \texttt{echo\ =\ TRUE} for that code chunk only:

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r echo = TRUE\}}
\InformationTok{penguins \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = bill\_length\_mm)) +}
\InformationTok{  geom\_histogram() +}
\InformationTok{  theme\_minimal()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

Because include is already set to TRUE within knitr::opts\_chunk\$set() in the setup code chunk, I don't need to specify it again.

\hypertarget{markdown-text}{%
\subsection*{Markdown Text}\label{markdown-text}}
\addcontentsline{toc}{subsection}{Markdown Text}

Markdown is a way to style plain text. If you were writing directly in Word, you could just press the B button to make text bold, for example, but R doesn't have such a button. If you want your knitted Word document to include bold text, you need to use Markdown indicate this in the document.

Markdown text sections (which have a white background in R Studio) will be converted into formatted text in the Word document after knitting. Figure \ref{fig:markdown-text-to-word} highlights the equivalent sections in our R Markdown and Word documents.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/markdown-text-to-word} \caption{Markdown text in R Markdown and its equivalent in a knitted Word document}\label{fig:markdown-text-to-word}
\end{figure}

As you can see, the text \texttt{\#\ Introduction} in R Markdown gets converted to a first-level heading, while \texttt{\#\#\ Bill\ Length} becomes a second-level heading. By adding hashes, you can create up to six levels of headings. In RStudio, headers are easy to find because they show up in blue.

Text without anything before it becomes body text in Word. To create italic text, add single asterisks around it (*like this*). To make text bold, use double asterisks (**Palmer Penguins**).

You can make bulleted lists by placing a dash at the beginning of a line and adding your text after it:

\begin{Shaded}
\begin{Highlighting}[]
\SpecialStringTok{{-} }\NormalTok{Adelie}
\SpecialStringTok{{-} }\NormalTok{Gentoo}
\SpecialStringTok{{-} }\NormalTok{Chinstrap}
\end{Highlighting}
\end{Shaded}

To make ordered lists, replace the dashes with numbers. You can either number each line consecutively or, as I've done below, just repeat 1. In the knitted document, the proper numbers will automatically generate.

\begin{Shaded}
\begin{Highlighting}[]
\SpecialStringTok{1. }\NormalTok{Adelie}
\SpecialStringTok{1. }\NormalTok{Gentoo}
\SpecialStringTok{1. }\NormalTok{Chinstrap}
\end{Highlighting}
\end{Shaded}

Formatting text in Markdown might seem more complicated than doing so in Word. But if we want to switch from a multi-tool workflow to a reproducible R Markdown-based workflow, we need to remove all manual actions from the process so we can easily repeat it in the future.

\hypertarget{inline-r-code}{%
\subsection*{Inline R Code}\label{inline-r-code}}
\addcontentsline{toc}{subsection}{Inline R Code}

R Markdown documents can also include little bits of code within Markdown text. To see how this inline code works, take a look at the following sentence of the R Markdown document:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{The average bill length is }\InformationTok{\textasciigrave{}r average\_bill\_length\textasciigrave{}}\NormalTok{ millimeters.}
\end{Highlighting}
\end{Shaded}

Inline R code begins with a backtick and the lowercase letter r and ends with another backtick. Here, it tells R to print the value of the variable \texttt{average\_bill\_length}, which we've defined as follows in the code chunk above the inline code:

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{average\_bill\_length \textless{}{-} penguins \%\textgreater{}\% }
\InformationTok{  summarize(avg\_bill\_length = mean(bill\_length\_mm,}
\InformationTok{                                   na.rm = TRUE)) \%\textgreater{}\% }
\InformationTok{  pull(avg\_bill\_length)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

This code calculates the average bill length and saves it as average\_bill\_length. Having created this variable, I can then use it in my inline R code. As a result, the Word document includes the sentence ``The average bill length is 43.9219298.''
One benefit of using inline R code is that you avoid having to copy and paste values, which is error-prone. Inline R code also makes it possible to automatically calculate values on the fly whenever we re-knit the R Markdown document with new data. To show you how this works, let's make a new report using data from 2008. To do this, I need to change only one line, the one that reads the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"https://raw.githubusercontent.com/rfortherestofus/r{-}without{-}statistics/main/data/penguins{-}2008.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now that I've switched \emph{penguins-2007.csv} to \emph{penguins-2008.csv}, I can re-knit my report and get a new Word document, complete with updated results. Figure \ref{fig:penguins-report-2008} shows our new knitted Word document.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/penguins-report-2008} \caption{The knitted Word document with 2008 data}\label{fig:penguins-report-2008}
\end{figure}

The histogram is based on 2008 data, as is the average bill length of 43.5412281. These update automatically because every time I hit knit, the code is rerun, regenerating plots and recalculating values. As long as the data has the same structure, updating a report requires just a click of the knit button.

\hypertarget{running-code-chunks-interactively}{%
\subsection*{Running Code Chunks Interactively}\label{running-code-chunks-interactively}}
\addcontentsline{toc}{subsection}{Running Code Chunks Interactively}

You can run the code within an R Markdown document in two ways. The first is by knitting the entire document. The second way is to run code chunks manually (also known as interactively) by hitting the little green play button at the top-right of a code chunk. The down arrow next to it will run all code until that point. We can see these buttons in Figure \ref{fig:code-chunk-buttons-annotated}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/code-chunk-buttons-annotated} \caption{The buttons on code chunks in RStudio}\label{fig:code-chunk-buttons-annotated}
\end{figure}

You can also use the Cmd key on Mac and the Ctrl key on Windows, followed by Enter, to run pieces of code, just like in an R script file. Running code interactively is a good way to test that portions of code work before you knit the entire document.
The one downside to running code interactively is that you can sometimes make mistakes that make your R Markdown document fail to knit. That is because, in order to knit, an R Markdown document must contain all the code it uses. If you are working interactively and, say, load data in a separate file, you will be unable to knit your R Markdown document. When working in R Markdown, always keep all code within a single document.

The code must also be in the right order. An R Markdown document that looks like this, for example, will give you an error if you try to knit it:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\AnnotationTok{title:}\CommentTok{ "Penguins Report"}
\AnnotationTok{author:}\CommentTok{ "David Keyes"}
\AnnotationTok{date:}\CommentTok{ "2024{-}01{-}12"}
\AnnotationTok{output:}\CommentTok{ word\_document}
\CommentTok{{-}{-}{-}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r setup, include=FALSE\}}
\InformationTok{knitr::opts\_chunk$set(include = TRUE, }
\InformationTok{                      echo = FALSE,}
\InformationTok{                      message = FALSE,}
\InformationTok{                      warning = FALSE)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{penguins \textless{}{-} read\_csv("https://raw.githubusercontent.com/rfortherestofus/r{-}without{-}statistics/main/data/penguins{-}2008.csv")}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{penguins \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = bill\_length\_mm)) +}
\InformationTok{  geom\_histogram() +}
\InformationTok{  theme\_minimal()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{library(tidyverse)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

This happens because you are attempting to use tidyverse functions (read\_csv(), as well as various ggplot functions) before you load the tidyverse package. Figure \ref{fig:rmarkdown-order-annotated} highlights the problem.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/rmarkdown-order-annotated} \caption{An R Markdown document with code chunks in the wrong order}\label{fig:rmarkdown-order-annotated}
\end{figure}

Alison Hill, one of the most prolific R Markdown educators, tells her students to ``knit early and often.'' This practice makes it easier to isolate issues that make knitting fail. Hill describes her typical R Markdown workflow as spending 75 percent of her time working on a new document and 25 percent of her time knitting to check that the R Markdown document works.

\hypertarget{quarto}{%
\section*{Quarto}\label{quarto}}
\addcontentsline{toc}{section}{Quarto}

In 2022, a new publishing tool similar to R Markdown was released. Known as Quarto, this tool takes what R Markdown has done for R and extends it to other languages, including Python, Julia, and Observable JS. As I write this book, Quarto is starting to gain more traction. Luckily, the concepts you've learned about in this chapter apply to Quarto as well. Quarto documents have a YAML section, code chunks, and Markdown text. You can export Quarto documents to HTML, PDF, and Word documents. There are some minor differences in syntax between R Markdown and Quarto documents, but if you know how to use R Markdown, you should easily pick up Quarto as well. The documentation at \emph{\url{https://quarto.org/}} is a great place to read more about all of the Quarto features and learn how to get started using it.

\hypertarget{in-conclusion-r-markdown-opens-up-all-sorts-of-possibilities}{%
\section*{In Conclusion: R Markdown Opens up All Sorts of Possibilities}\label{in-conclusion-r-markdown-opens-up-all-sorts-of-possibilities}}
\addcontentsline{toc}{section}{In Conclusion: R Markdown Opens up All Sorts of Possibilities}

We started this chapter with the example of a report that needs to be regenerated monthly. Using R Markdown, we can reproduce this report every month without changing our code. Even if we lost the final Word document, we could quickly recreate it. Or, as Jenny Bryan and Jim Hester, as part of their rstats.wtf workshop, put it in Figure \ref{fig:if-you-liked-it}:

\begin{figure}
\includegraphics[width=1\linewidth]{assets/if-you-liked-it-you-should-have-saved-the-source-for-it} \caption{A meme explaining why you should save your source and not care about knitted documents}\label{fig:if-you-liked-it}
\end{figure}

Best of all, working with R Markdown makes it possible to do things in seconds that would have previously taken hours. In a world where making a single report requires three tools and five steps, you may not want to work on it. As a research scientist who used R Markdown regularly, Alison Hill says it enabled her to work on reports before she had received all of the data. She could write code that worked with partial data and rerun it with the final data at any time.

In this chapter, we've just scratched the surface of what R Markdown can do. The next chapter will show how to use it to instantly generate hundreds of reports. Magic indeed!

\hypertarget{parameterized-reports-chapter}{%
\chapter{Generate Multiple Reports at Once with Parameterized Reporting}\label{parameterized-reports-chapter}}

In mid-2020, staff at the Urban Institute were tasked with developing State Fiscal Briefs. The Urban Institute, a Washington D.C.-based think tank, regularly produces economic and social policy research and the State Fiscal Briefs were designed to provide an overview of the fiscal situation of all U.S. states as well as the District of Columbia. At a time when COVID-19 had brought much economic activity to a halt, these reports would show just how bad their fiscal situation had become.

For Urban Institute staff, the main challenge was how to produce these reports. Each one would have extensive text and multiple charts so creating the reports by hand was not feasible. They needed a way to automate the process. Fortunately, the Urban Institute has a strong cadre of R users. Three of them -- Safia Sayed, Livia Mucciolo, and Aaron Williams -- worked together to create the State Fiscal Briefs using parameterized reporting, a technique that uses R Markdown to make multiple reports simultaneously. Parameterized reporting allowed them to make 51 beautiful reports that could be embedded on the Urban Institute website. A snippet of three of these reports is shown in Figure \ref{fig:state-fiscal-briefs}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/state-fiscal-briefs} \caption{A portion of three of the State Fiscal Briefs}\label{fig:state-fiscal-briefs}
\end{figure}

In this chapter, I'll begin by explaining what parameterized reporting is. We'll then work through a simplified version of the type of code that the Urban Institute used in order to demonstrate parameterized reporting in action. We'll conclude with some reflections on the value of parameterized reporting. Throughout the chapter, you'll hear insights about parameterized reporting from my interview with the Urban Institute staff members Sayed, Mucciolo, and Williams.

\hypertarget{how-parameterized-reporting-works}{%
\section*{How Parameterized Reporting Works}\label{how-parameterized-reporting-works}}
\addcontentsline{toc}{section}{How Parameterized Reporting Works}

If you've ever had to make multiple reports at the same time, you know what a drag it can be. Especially if you're using the multi-tool workflow described in Chapter \ref{rmarkdown-chapter} (analysis in SPSS, data visualization in Excel, report writing in Word), it can take a long time to make just one report. Take that amount of work and multiply it by 10, 20, 50 or, in the case of the team at the Urban Institute, 51 and it can start to feel overwhelming. Parameterized reporting is the solution to this problem.

The workflow for making parameterized reports looks like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make a report template in R Markdown
\item
  Add a parameter (for example, state) in the YAML of your R Markdown document
\item
  Use that parameter to generate a report for one state to make sure you can knit your document
\item
  Create a separate R script file with a function to knit your report for one state
\item
  Run this function for all states
\end{enumerate}

This five-step workflow can generate dozens, hundreds, even thousands of reports at once.

\hypertarget{creating-an-r-markdown-document-with-parameters}{%
\subsection*{Creating an R Markdown Document with Parameters}\label{creating-an-r-markdown-document-with-parameters}}
\addcontentsline{toc}{subsection}{Creating an R Markdown Document with Parameters}

It might sound a bit complicated so let's show it in action. I've taken the code that the Urban Institute staff used to make their State Fiscal Briefs and simplified it significantly. And, instead of focusing on fiscal data, I've used data you may be more familiar with: COVID-19 rates (the data is from mid-2022). We can see the R Markdown document below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\CommentTok{  title: "Urban Institute COVID Report"}
\AnnotationTok{output:}\CommentTok{ html\_document}
\AnnotationTok{params:}
\CommentTok{  state: "Alabama"}
\CommentTok{{-}{-}{-}}
  
  \InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r setup, include=FALSE\}}
\InformationTok{knitr::opts\_chunk$set(}
\InformationTok{  echo = FALSE,}
\InformationTok{  warning = FALSE,}
\InformationTok{  message = FALSE}
\InformationTok{)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{library(tidyverse)}
\InformationTok{library(urbnthemes)}
\InformationTok{library(here)}
\InformationTok{library(scales)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\FunctionTok{\# \textasciigrave{}r params$state\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{cases \textless{}{-} tibble(state.name) \%\textgreater{}\%}
\InformationTok{  rbind(state.name = "District of Columbia") \%\textgreater{}\%}
\InformationTok{  left\_join(}
\InformationTok{    read\_csv("united\_states\_covid19\_cases\_deaths\_and\_testing\_by\_state.csv",}
\InformationTok{      skip = 2}
\InformationTok{    ),}
\InformationTok{    by = c("state.name" = "State/Territory")}
\InformationTok{  ) \%\textgreater{}\%}
\InformationTok{  select(}
\InformationTok{    total\_cases = \textasciigrave{}Total Cases\textasciigrave{}, state.name,}
\InformationTok{    cases\_per\_100000 = \textasciigrave{}Case Rate per 100000\textasciigrave{}}
\InformationTok{  ) \%\textgreater{}\%}
\InformationTok{  mutate(cases\_per\_100000 = parse\_number(cases\_per\_100000)) \%\textgreater{}\%}
\InformationTok{  mutate(case\_rank = rank({-}cases\_per\_100000, ties.method = "min"))}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{state\_text \textless{}{-} if\_else(params$state == "District of Columbia", str\_glue("the District of Columbia"), str\_glue("state of \{params$state\}"))}

\InformationTok{state\_cases\_per\_100000 \textless{}{-} cases \%\textgreater{}\%}
\InformationTok{  filter(state.name == params$state) \%\textgreater{}\%}
\InformationTok{  pull(cases\_per\_100000) \%\textgreater{}\%}
\InformationTok{  comma()}

\InformationTok{state\_cases\_rank \textless{}{-} cases \%\textgreater{}\%}
\InformationTok{  filter(state.name == params$state) \%\textgreater{}\%}
\InformationTok{  pull(case\_rank)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\NormalTok{In }\InformationTok{\textasciigrave{}r state\_text\textasciigrave{}}\NormalTok{, there were }\InformationTok{\textasciigrave{}r state\_cases\_per\_100000\textasciigrave{}}\NormalTok{ cases per 100,000 people in the last seven days. This puts }\InformationTok{\textasciigrave{}r params$state\textasciigrave{}}\NormalTok{ at number }\InformationTok{\textasciigrave{}r state\_cases\_rank\textasciigrave{}}\NormalTok{ of 50 states and the District of Columbia. }

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r fig.height = 8\}}
\InformationTok{set\_urbn\_defaults(style = "print")}

\InformationTok{cases \%\textgreater{}\%}
\InformationTok{  mutate(highlight\_state = if\_else(state.name == params$state, "Y", "N")) \%\textgreater{}\%}
\InformationTok{  mutate(state.name = fct\_reorder(state.name, cases\_per\_100000)) \%\textgreater{}\%}
\InformationTok{  ggplot(aes(}
\InformationTok{    x = cases\_per\_100000,}
\InformationTok{    y = state.name,}
\InformationTok{    fill = highlight\_state}
\InformationTok{  )) +}
\InformationTok{  geom\_col() +}
\InformationTok{  scale\_x\_continuous(labels = comma\_format()) +}
\InformationTok{  theme(legend.position = "none") +}
\InformationTok{  labs(}
\InformationTok{    y = NULL,}
\InformationTok{    x = "Cases per 100,000"}
\InformationTok{  )}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

If we knit this document, we end up with a simple HTML document, seen in Figure \ref{fig:alabama-covid-report}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/alabama-covid-report} \caption{A screenshot of the Alabama COVID report}\label{fig:alabama-covid-report}
\end{figure}

All of the text and charts in our report come the \texttt{cases} data frame. Let's take a look at that so we can keep it in mind throughout the chapter.

\begin{verbatim}
#> # A tibble: 51 x 4
#>    total_cases state.name  cases_per_100000 case_rank
#>    <chr>       <chr>                  <dbl>     <int>
#>  1 1302945     Alabama                26573        18
#>  2 246345      Alaska                 33675         2
#>  3 2025435     Arizona                27827        10
#>  4 837154      Arkansas               27740        12
#>  5 9274208     California             23472        35
#>  6 1388702     Colorado               24115        33
#>  7 766172      Connecticut            21490        42
#>  8 264376      Delaware               27150        13
#>  9 5965411     Florida                27775        11
#> 10 2521664     Georgia                23750        34
#> # ... with 41 more rows
\end{verbatim}

Returning to the R Markdown document, the combination of YAML, R code chunks, and markdown text should look familiar if you've read chapter \ref{rmarkdown-chapter}. There's even some inline R code. The one piece that you haven't seen is the two lines in the YAML that look like this:

\begin{Shaded}
\begin{Highlighting}[]
\AnnotationTok{params:}
\AnnotationTok{state:}\CommentTok{ "Alabama"}
\end{Highlighting}
\end{Shaded}

These lines allow us to define a variable, in this case \texttt{state}. We can then use this variable throughout the rest of our R Markdown document using this syntax: \texttt{params\$variable\_name} (replacing \texttt{variable\_name} with \texttt{state} or any name you set in the YAML). Take a look at this line:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\# \textasciigrave{}r params$state\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

Where we see \texttt{params\$state} in our inline R code, this is converted to Alabama when we knit (it also becomes a Heading 1 because the line starts with a hash). You can see the result in Figure \ref{fig:alabama-covid-report-header}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/alabama-covid-report-header} \caption{A screenshot of the Alabama COVID report}\label{fig:alabama-covid-report-header}
\end{figure}

This variable created using \texttt{params} in our YAML is the parameter that gives parameterized reporting its name. This use of our parameter to dynamically generate text using inline R code also shows up later on. Take a look at this code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{In }\InformationTok{\textasciigrave{}r state\_text\textasciigrave{}}\NormalTok{, there were }\InformationTok{\textasciigrave{}r state\_cases\_per\_100000\textasciigrave{}}\NormalTok{ cases per 100,000 people in the last seven days. This puts }\InformationTok{\textasciigrave{}r params$state\textasciigrave{}}\NormalTok{ at number }\InformationTok{\textasciigrave{}r state\_cases\_rank\textasciigrave{}}\NormalTok{ of 50 states and the District of Columbia. }
\end{Highlighting}
\end{Shaded}

When we knit our document, we see the following text:

\begin{quote}
In state of Alabama, there were 26,573 cases per 100,000 people in the last seven days. This puts Alabama at number 18 of 50 states and the District of Columbia.
\end{quote}

This text is automatically generated. The inline R code \texttt{\textasciigrave{}r\ state\_text\textasciigrave{}} prints the value of the variable \texttt{state\_text}. And \texttt{state\_text} is determined by this \texttt{if\_else()} statement:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{state\_text }\OtherTok{\textless{}{-}} \FunctionTok{if\_else}\NormalTok{(params}\SpecialCharTok{$}\NormalTok{state }\SpecialCharTok{==} \StringTok{"District of Columbia"}\NormalTok{, }\FunctionTok{str\_glue}\NormalTok{(}\StringTok{"the District of Columbia"}\NormalTok{), }\FunctionTok{str\_glue}\NormalTok{(}\StringTok{"state of \{params$state\}"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

This line of code says that, if \texttt{params\$states} is District of Columbia, then make \texttt{state\_text} equal to ``the District of Columbia.'' If \texttt{params\$state} does not equal District of Columbia, then \texttt{state\_text} gets the value ``state of Alabama'' (or whatever the state name is). This allows us to put \texttt{state\_text} in a sentence and have it work no matter whether our state parameter is a state or the District of Columbia.

The values of the \texttt{state\_cases\_per\_100000} and \texttt{state\_cases\_rank} variables are also calcualted dynamically using our \texttt{state} parameter. This section of code shows how we filter the \texttt{cases} data frame (which has data for all states) to keep just the data for the state in \texttt{params\$state}. We then use the \texttt{pull()} function to get a single value and do a bit of formatting with the \texttt{comma()} function from the \texttt{scales} package to make \texttt{state\_cases\_per\_100000} show up as 26,573 (rather than 26573) before putting these variables into our inline R code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{state\_cases\_per\_100000 }\OtherTok{\textless{}{-}}\NormalTok{ cases }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{filter}\NormalTok{(state.name }\SpecialCharTok{==}\NormalTok{ params}\SpecialCharTok{$}\NormalTok{state) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{pull}\NormalTok{(cases\_per\_100000) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{comma}\NormalTok{()}

\NormalTok{state\_cases\_rank }\OtherTok{\textless{}{-}}\NormalTok{ cases }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{filter}\NormalTok{(state.name }\SpecialCharTok{==}\NormalTok{ params}\SpecialCharTok{$}\NormalTok{state) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{pull}\NormalTok{(case\_rank)}
\end{Highlighting}
\end{Shaded}

Writing sentences using inline R code that dynamically updates based on the value of our parameter allows us to create a report for any state with numbers specific to that state.

We can see them our parameter used in other places as well. Take a look at this section from the last code chunk. This creates a variable called \texttt{highlight\_state}. Working in the \texttt{cases} data frame, we check if the \texttt{state.name} is equal to \texttt{params\$state}. If it is, \texttt{highlight\_state} gets the value ``Y''. If not, it gets ``N.''

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cases }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{mutate}\NormalTok{(}\AttributeTok{highlight\_state =} \FunctionTok{if\_else}\NormalTok{(state.name }\SpecialCharTok{==}\NormalTok{ params}\SpecialCharTok{$}\NormalTok{state, }\StringTok{"Y"}\NormalTok{, }\StringTok{"N"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We can see what the relevant columns in our data look like after these two lines:

\begin{verbatim}
#> # A tibble: 51 x 2
#>    state.name  highlight_state
#>    <chr>       <chr>          
#>  1 Alabama     Y              
#>  2 Alaska      N              
#>  3 Arizona     N              
#>  4 Arkansas    N              
#>  5 California  N              
#>  6 Colorado    N              
#>  7 Connecticut N              
#>  8 Delaware    N              
#>  9 Florida     N              
#> 10 Georgia     N              
#> # ... with 41 more rows
\end{verbatim}

Later down, our ggplot code uses the \texttt{highlight\_state} variable for the \texttt{fill} aesthetic. What this means is that, when we create our bar chart, the state that is in our variable \texttt{params\$state} (Alabama) is highlighted in yellow while all of the other states are blue. If you're eagle-eyed, you may have noticed a reference to the \texttt{urbnthemes} package and the line of code that says \texttt{set\_urbn\_defaults(style\ =\ "print")}. This package provides a custom ggplot theme for all graphs and the \texttt{set\_urbn\_defaults(style\ =\ "print")} line applies that theme (in a slightly different way than we saw in Chapter \ref{custom-theme-chapter}, but with the same result). The Urban Institute-styled chart with Alabama highlighted is seen in Figure \ref{fig:alabama-covid-chart} below.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/alabama-covid-chart} \caption{A bar chart showing Alabama highlighted}\label{fig:alabama-covid-chart}
\end{figure}

We've now seen how setting a parameter in the YAML gives us the ability to dynamically generate text and charts in our knitted report. But we've only generated one report so far. How can we now create all 51 reports? Your first thought might be to manually update the YAML. You could go in, change Alabama to Alaska, and knit again in order to get a report for that state. You could then do this same thing for all states. But it would be tedious, and we're trying to avoid that. Let's automate it instead.

\hypertarget{creating-an-r-script-file-to-render-multiple-reports}{%
\subsection*{Creating an R Script File to Render Multiple Reports}\label{creating-an-r-script-file-to-render-multiple-reports}}
\addcontentsline{toc}{subsection}{Creating an R Script File to Render Multiple Reports}

At this point, we're going to move out of R Markdown and into an R script file (I tend to call mine \texttt{render.R}). The first thing to know is that, while you've seen how to knit an R Markdown document using the Knit button, you can do the same thing with code. There is a package called \texttt{rmarkdown} and a function within it called \texttt{render()}. If I load the \texttt{rmarkdown} package and then use the \texttt{render()} function, as in the code below, the resulting HTML document will be generated.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rmarkdown)}
\FunctionTok{render}\NormalTok{(}\AttributeTok{input =} \StringTok{"urban{-}covid{-}budget{-}report.Rmd"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Using this code, our HTML document will be called \texttt{urban-covid-budget-report.html} (the same name as the R Markdown document, but replacing the .Rmd with .html). We can change its name by using the \texttt{output\_file} argument in the \texttt{render()} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{render}\NormalTok{(}
\AttributeTok{input =} \StringTok{"urban{-}covid{-}budget{-}report.Rmd"}\NormalTok{,}
\AttributeTok{output\_file =} \StringTok{"Alabama.html"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can also tell the \texttt{render()} function to use parameters we give it (parameters we provide here override those in the R Markdown document itself). This code would tell R to use Alaska for our \texttt{state} parameter and save the resulting HTML file as Alaska.html.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{render}\NormalTok{(}
\AttributeTok{input =} \StringTok{"urban{-}covid{-}budget{-}report.Rmd"}\NormalTok{,}
\AttributeTok{output\_file =} \StringTok{"Alaska.html"}\NormalTok{,}
\AttributeTok{parms =} \FunctionTok{list}\NormalTok{(}\AttributeTok{state =} \StringTok{"Alaska"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This approach works, but to get all 51 reports, we'd still have to manually change the state name in our YAML and update the \texttt{render()} function each time before we run it. Things really get interesting when we write code that generates all reports for us automatically. We do this in three steps.

\hypertarget{step-1-create-a-vector-of-all-states}{%
\subsubsection*{Step 1: Create a Vector of All States}\label{step-1-create-a-vector-of-all-states}}
\addcontentsline{toc}{subsubsection}{Step 1: Create a Vector of All States}

First, we create a vector (in colloquial terms, a list of items) of all state names and the District of Columbia. The team at the Urban Institute does this by using the built-in dataset \texttt{state.name}, which has all 50 state names in a vector. They turn it into a \texttt{tibble} (for our purposes, the same thing as a data frame) and then use the \texttt{rbind()} function to add on the District of Columbia. Finally, they use the \texttt{pull()} function to get one single column and save this as \texttt{state}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{state }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(state.name) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{rbind}\NormalTok{(}\StringTok{"District of Columbia"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{pull}\NormalTok{(state.name)}
\end{Highlighting}
\end{Shaded}

We can see what \texttt{state} looks like below.

\begin{verbatim}
#>  [1] "Alabama"              "Alaska"              
#>  [3] "Arizona"              "Arkansas"            
#>  [5] "California"           "Colorado"            
#>  [7] "Connecticut"          "Delaware"            
#>  [9] "Florida"              "Georgia"             
#> [11] "Hawaii"               "Idaho"               
#> [13] "Illinois"             "Indiana"             
#> [15] "Iowa"                 "Kansas"              
#> [17] "Kentucky"             "Louisiana"           
#> [19] "Maine"                "Maryland"            
#> [21] "Massachusetts"        "Michigan"            
#> [23] "Minnesota"            "Mississippi"         
#> [25] "Missouri"             "Montana"             
#> [27] "Nebraska"             "Nevada"              
#> [29] "New Hampshire"        "New Jersey"          
#> [31] "New Mexico"           "New York"            
#> [33] "North Carolina"       "North Dakota"        
#> [35] "Ohio"                 "Oklahoma"            
#> [37] "Oregon"               "Pennsylvania"        
#> [39] "Rhode Island"         "South Carolina"      
#> [41] "South Dakota"         "Tennessee"           
#> [43] "Texas"                "Utah"                
#> [45] "Vermont"              "Virginia"            
#> [47] "Washington"           "West Virginia"       
#> [49] "Wisconsin"            "Wyoming"             
#> [51] "District of Columbia"
\end{verbatim}

\hypertarget{step-2-create-a-tibble-with-data-to-render-all-reports}{%
\subsubsection*{Step 2: Create a Tibble with Data to Render All Reports}\label{step-2-create-a-tibble-with-data-to-render-all-reports}}
\addcontentsline{toc}{subsubsection}{Step 2: Create a Tibble with Data to Render All Reports}

The second step is to create a tibble with information needed to render all 51 reports. We do this by creating an object called \texttt{reports}. This object has multiple arguments that we can pass to the \texttt{render()} function. Above, we used \texttt{render()} with the \texttt{input} and \texttt{output\_file} arguments, but you can also pass the \texttt{params} argument to give it parameters to use when knitting. The code below generates a tibble with 51 rows and three variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reports }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
\AttributeTok{input =} \StringTok{"urban{-}covid{-}budget{-}report.Rmd"}\NormalTok{,}
\AttributeTok{output\_file =} \FunctionTok{str\_glue}\NormalTok{(}\StringTok{"\{state\}.html"}\NormalTok{),}
\AttributeTok{params =} \FunctionTok{map}\NormalTok{(state, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{list}\NormalTok{(}\AttributeTok{state =}\NormalTok{ .))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In all rows, the \texttt{input} variable is set to \texttt{urban-covid-budget-report.Rmd}. The value of \texttt{output\_file} is set with \texttt{str\_glue()} to be equal to the name of the state, followed by ``.html'' (for example, \texttt{Alabama.html}). The \texttt{params} variable is the most complicated. It is what's known as a named list. This data structure is what is needed to use parameters in our R Markdown document, where, for example, we set \texttt{state} to be equal to Alabama. We create the \texttt{params} variable with the \texttt{map()} function from the \texttt{purrr} package, which creates our named list, telling R to set the value of each row as \texttt{state\ =\ "Alabama"} and so on for all states.

\begin{verbatim}
#> # A tibble: 51 x 3
#>    input                         output_file    params      
#>    <chr>                         <glue>         <list>      
#>  1 urban-covid-budget-report.Rmd Alabama.html   <named list>
#>  2 urban-covid-budget-report.Rmd Alaska.html    <named list>
#>  3 urban-covid-budget-report.Rmd Arizona.html   <named list>
#>  4 urban-covid-budget-report.Rmd Arkansas.html  <named list>
#>  5 urban-covid-budget-report.Rmd California.ht~ <named list>
#>  6 urban-covid-budget-report.Rmd Colorado.html  <named list>
#>  7 urban-covid-budget-report.Rmd Connecticut.h~ <named list>
#>  8 urban-covid-budget-report.Rmd Delaware.html  <named list>
#>  9 urban-covid-budget-report.Rmd Florida.html   <named list>
#> 10 urban-covid-budget-report.Rmd Georgia.html   <named list>
#> # ... with 41 more rows
\end{verbatim}

If we look at the \texttt{reports} tibble, we can see these variables. The \texttt{params} variable just shows up as \texttt{\textless{}named\ list\textgreater{}}, but if we open it in the viewer (you can do so by clicking the name \texttt{reports} in your Environment tab in RStudio), we can see the output more clearly. Figure \ref{fig:params-named-list} shows this.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/params-named-list} \caption{The named list column shown in the RStudio viewer}\label{fig:params-named-list}
\end{figure}

\hypertarget{step-3-render-all-of-the-reports}{%
\subsubsection*{Step 3: Render All of the Reports}\label{step-3-render-all-of-the-reports}}
\addcontentsline{toc}{subsubsection}{Step 3: Render All of the Reports}

Once we've created the \texttt{reports} tibble, we're ready for our third and final step: rendering all of our reports. The code that generates all of the reports is only one line. We use the \texttt{pwalk()} function from the \texttt{purrr} package. This function has two arguments: 1) a data frame or tibble (\texttt{reports} in our case), and 2) a function to run on each row of this tibble (\texttt{render} though note that you do not include open and close parentheses typically seen with functions).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pwalk}\NormalTok{(reports, render)}
\end{Highlighting}
\end{Shaded}

When we run this code, it runs the \texttt{render()} function for each row in \texttt{reports}, each time passing in the values for \texttt{input}, \texttt{output\_file}, and \texttt{params}. It is the equivalent of typing out code like this that runs the \texttt{render()} function for each of the 51 states:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{render}\NormalTok{(}
\AttributeTok{input =} \StringTok{"urban{-}covid{-}budget{-}report.Rmd"}\NormalTok{,}
\AttributeTok{output\_file =} \StringTok{"Alabama.html"}\NormalTok{,}
\AttributeTok{params =} \FunctionTok{list}\NormalTok{(}\AttributeTok{state =} \StringTok{"Alabama"}\NormalTok{)}
\NormalTok{)}

\FunctionTok{render}\NormalTok{(}
\AttributeTok{input =} \StringTok{"urban{-}covid{-}budget{-}report.Rmd"}\NormalTok{,}
\AttributeTok{output\_file =} \StringTok{"Alaska.html"}\NormalTok{,}
\AttributeTok{params =} \FunctionTok{list}\NormalTok{(}\AttributeTok{state =} \StringTok{"Alaska"}\NormalTok{)}
\NormalTok{)}

\FunctionTok{render}\NormalTok{(}
\AttributeTok{input =} \StringTok{"urban{-}covid{-}budget{-}report.Rmd"}\NormalTok{,}
\AttributeTok{output\_file =} \StringTok{"Arizona.html"}\NormalTok{,}
\AttributeTok{params =} \FunctionTok{list}\NormalTok{(}\AttributeTok{state =} \StringTok{"Arizona"}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# And so on for all states}
\end{Highlighting}
\end{Shaded}

Putting all three steps together, here's what my full R script file looks like:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load packages}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(rmarkdown)}

\CommentTok{\# Create a vector of all states and the District of Columbia}
\NormalTok{state }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(state.name) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{rbind}\NormalTok{(}\StringTok{"District of Columbia"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{pull}\NormalTok{(state.name)}

\CommentTok{\# Create a tibble with information on the:}
\CommentTok{\# input R Markdown document}
\CommentTok{\# output HTML file}
\CommentTok{\# parameters needed to knit the document}
\NormalTok{reports }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
\AttributeTok{input =} \StringTok{"urban{-}covid{-}budget{-}report.Rmd"}\NormalTok{,}
\AttributeTok{output\_file =} \FunctionTok{str\_glue}\NormalTok{(}\StringTok{"\{state\}.html"}\NormalTok{),}
\AttributeTok{params =} \FunctionTok{map}\NormalTok{(state, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{list}\NormalTok{(}\AttributeTok{state =}\NormalTok{ .))}
\NormalTok{)}

\CommentTok{\# Generate all of our reports}
\FunctionTok{pwalk}\NormalTok{(reports, render)}
\end{Highlighting}
\end{Shaded}

Being able to tell R to run the Alabama row to generate its report, then the Alaska row, then the Arizona row, and then all other states is a huge time-saver. If I run the \texttt{pwalk(reports,\ render)} code, I will quickly see 51 HTML documents appear. And each one will be a report for that state, complete with a customized graph and accompanying text.

\hypertarget{best-practices-for-working-with-parameterized-reporting}{%
\section*{Best Practices for Working with Parameterized Reporting}\label{best-practices-for-working-with-parameterized-reporting}}
\addcontentsline{toc}{section}{Best Practices for Working with Parameterized Reporting}

Working with parameterized reporting is incredibly powerful. It can also present some challenges. I asked the team at the Urban Institute for their thoughts on best practices for parameterized reporting. Their feedback focused on one topic: considering outliers.

The first example they gave is one we have already seen: Washington D.C. In a project making state-level reports, Washington D.C. is an outlier because it is not technically a state. Having done extensive parameterized reporting, the Urban Institute team knew that they would need to alter the language in the text so that it didn't talk about Washington D.C. as a state. As we saw above, a quick \texttt{if\_else()} statement made it possible to avoid referring to Washington D.C. as a state in the inline R code.

Another best practice that the Urban Institute team recommends is to manually generate and review reports with the shortest and longest text length of the parameter you're working with (in the State Fiscal Briefs, this would be Iowa and District of Columbia). Making and reviewing these reports manually allows you to see places where the length of the text may cause unexpected results. Titles in charts can be cut off, page breaks in PDF or Word documents may be messed up by text that runs onto multiple lines, and so on. A few minutes of manual review early on can make the automated process of generating multiple reports much smoother in the end.

\hypertarget{in-conclusion-parameterized-reporting-makes-new-reporting-options-possible}{%
\section*{In Conclusion: Parameterized Reporting Makes New Reporting Options Possible}\label{in-conclusion-parameterized-reporting-makes-new-reporting-options-possible}}
\addcontentsline{toc}{section}{In Conclusion: Parameterized Reporting Makes New Reporting Options Possible}

In this chapter, we've worked through the example of the State Fiscal Briefs that the Urban Institute team made using parameterized reporting. Automating the production of 51 reports was a huge time-saver, though at this scale, it still would be feasible to make these reports by hand. But near the end of our interview, Aaron Williams gave me an example of another project the Urban Institute team works on. This project involves making county-level reports. With over 3,000 counties in the United States, making these reports by hand is not realistic. With parameterized reporting, though, it is the same exact process to make 3,000 reports as it is to make 51. Parameterized reporting makes new reporting options possible.

Parameterized reporting also makes your work more accurate. If the Urban Institute were to make these reports using, say, SPSS, Excel, and Word, there would be a ton of copying and pasting between programs. Humans are fallible, and mistakes occur no matter how hard we try to avoid them. Computers, on the other hand, do not make copy-paste errors. Letting computers handle the tedious work of making multiple reports significantly reduces the chance of error. As Safia Sayed told me, ``using R Markdown made it not only quicker, but much more accurate, and we were able to pull in more information because of that and make more interesting calculations and observations.''

In Chapter \ref{rmarkdown-chapter}, I talked about reproducibility as being able to update a monthly report. Parameterized reporting is another example of reproducibility. Not only can we reproduce reports across time, we can also reproduce them across all states (or any other parameter). It's just another example of how R doesn't simply replace other tools, but makes things you had previously considered impossible suddenly feel possible.

As with many things with R, when you're starting out it can feel like a heavy lift to produce reports using parameterized reporting. Initially, it is. You have to make sure that your code works not just for, say, one state, but for all 51. There can be challenges with outliers. You have to master the syntax to knit your reports from an R script file. But once you have your R Markdown document and accompanying R script file for rendering, it is straightforward to produce multiple reports at once. It may be more work in the beginning, but it is far, far less work in the end.

\hypertarget{presentations-chapter}{%
\chapter{Create Beautiful Presentations with R Markdown}\label{presentations-chapter}}

Remember how we talked in Chapter \ref{rmarkdown-chapter} about the multi-tool workflow from SPSS to Excel to Word? That leaves out one of the most common tools in many people's workflow: PowerPoint. Reporting happens in presentations as often as it does in Word-based reports.

In Chapter \ref{rmarkdown-chapter}, we talked about the R Markdown-based workflow having the benefit of keeping everything in one tool. You may be wondering at this point if creating presentations will require us to add another tool, like PowerPoint. Do you need to do your analysis, data visualization, and table making in R and then copy everything to PowerPoint by hand? No! R has robust presentation-making capabilities.

In this chapter, we'll learn how to make presentations in R using the \texttt{xaringan} package. This package, which uses R Markdown to make presentations, is one of several you can use to make slides, but it is the most widely used. To learn more about the capabilities of \texttt{xaringan}, I spoke with Silvia Canelón, a data analyst in the Urban Health Lab at the University of Pennsylvania. Canelón has done extensive teaching on the \texttt{xaringan} package and has thought deeply about its benefits. As you'll hear in this chapter, these benefits include, but also go well beyond, making good-looking slides.

\hypertarget{how-xaringan-works}{%
\section*{\texorpdfstring{How \texttt{xaringan} Works}{How xaringan Works}}\label{how-xaringan-works}}
\addcontentsline{toc}{section}{How \texttt{xaringan} Works}

To get started with \texttt{xaringan}, you need to first install the package using the standard approach: \texttt{install.packages("xaringan")}. Once it is installed, you can go to File \textgreater{} New File \textgreater{} R Markdown. You're probably thinking that you want to go to the Presentation tab. Doing so will give you several options for making slides, as you can see in Figure \ref{fig:new-rmarkdown-presentation}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/new-rmarkdown-presentation} \caption{The options presented to create a new presentation}\label{fig:new-rmarkdown-presentation}
\end{figure}

These are other formats you can use to make slides (and yes, you can knit an R Markdown document to PowerPoint). However, if you want to make a presentation with \texttt{xaringan} (and, as I will explain below, I think it's the best option), you should go to the From Template tab. From there, scroll down until you find the template called Ninja Presentation. Select that, hit OK, and you'll get a blank R Markdown document. Figure \ref{fig:new-xaringan-document} shows you what to look for.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/new-xaringan-document} \caption{The options presented to create a new presentation}\label{fig:new-xaringan-document}
\end{figure}

Just as when we created a regular R Markdown document, creating a new \texttt{xaringan} presentation will give us some default content. I'm going to delete that and add my own contents which you can see below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\AnnotationTok{title:}\CommentTok{ "Penguins Report"}
\AnnotationTok{author:}\CommentTok{ "David Keyes"}
\AnnotationTok{date:}\CommentTok{ "2024{-}01{-}12"}
\AnnotationTok{output:}\CommentTok{ xaringan::moon\_reader}
\CommentTok{{-}{-}{-}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r setup, include=FALSE\}}
\InformationTok{knitr::opts\_chunk$set(include = TRUE, }
\InformationTok{                      echo = FALSE,}
\InformationTok{                      message = FALSE,}
\InformationTok{                      warning = FALSE)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{library(tidyverse)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{penguins \textless{}{-} read\_csv("https://raw.githubusercontent.com/rfortherestofus/r{-}without{-}statistics/main/data/penguins{-}2008.csv")}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\FunctionTok{\# Introduction}

\NormalTok{We are writing a report about the **Palmer Penguins**. These penguins are *really* amazing. There are three species:}

\SpecialStringTok{{-} }\NormalTok{Adelie}
\SpecialStringTok{{-} }\NormalTok{Gentoo}
\SpecialStringTok{{-} }\NormalTok{Chinstrap}

\FunctionTok{\#\# Bill Length}

\NormalTok{We can make a histogram to see the distribution of bill lengths.}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{penguins \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = bill\_length\_mm)) +}
\InformationTok{  geom\_histogram() +}
\InformationTok{  theme\_minimal()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{average\_bill\_length \textless{}{-} penguins \%\textgreater{}\% }
\InformationTok{  summarize(avg\_bill\_length = mean(bill\_length\_mm,}
\InformationTok{                                   na.rm = TRUE)) \%\textgreater{}\% }
\InformationTok{  pull(avg\_bill\_length)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\NormalTok{The chart shows the distribution of bill lengths. The average bill length is }\InformationTok{\textasciigrave{}r average\_bill\_length\textasciigrave{}}\NormalTok{ millimeters.}
\end{Highlighting}
\end{Shaded}

This code should look familiar because it is exactly the same as the R Markdown document we created in Chapter \ref{rmarkdown-chapter} with one line changed in the YAML. Instead of \texttt{output:\ word\_document} we now have \texttt{output:\ xaringan::moon\_reader}. With this change, we will now get slides rather than a Word document. Let's try hitting the Knit button to see what it looks like. When I hit Knit, I get an HTML file with the same name as R Markdown document (in my case, \texttt{xaringan-example.Rmd} and \texttt{xaringan-example.html}). If I open up the HTML document, I see Figure \ref{fig:penguins-report-slide-1}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/penguins-report-slide-1} \caption{The first slide of my presentation}\label{fig:penguins-report-slide-1}
\end{figure}

This is the first thing to know about \texttt{xaringan}: the slides it produces are HTML files. It may seem odd to get slides as HTML files, but it offers several advantages over formats like PowerPoint, as we'll see below.

If we scroll to the next slide with the right arrow key, we'll see content that looks familiar. Figure \ref{fig:penguins-report-slide-2} shows this slide, which has the same text and a cut-off version of the histogram we made in Chapter \ref{rmarkdown-chapter}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/penguins-report-slide-2} \caption{The second slide of my presentation}\label{fig:penguins-report-slide-2}
\end{figure}

At this point, we've learned two things about how \texttt{xaringan} works:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{The overall syntax for making slides with \texttt{xaringan} is nearly identical to that used to make reports with R Markdown.} We copied in the content of our R Markdown document, changed one line, and we see the same output, just in slide format. The YAML, markdown text, and code chunks work exactly the same.
\item
  \textbf{We need to make a few tweaks to make our content fit on our slides.} When we're working in an R Markdown document that will be knitted to Word, its length doesn't matter because reports can be one page or 100 pages. Working with \texttt{xaringan}, however, we need to think about how much content will fit on one slide. Our cut-off histogram shows us what happens without doing this. Let's fix it.
\end{enumerate}

\hypertarget{breaking-content-across-slides}{%
\subsection*{Breaking Content Across Slides}\label{breaking-content-across-slides}}
\addcontentsline{toc}{subsection}{Breaking Content Across Slides}

Let's make our histogram fully visible by putting it on its own slide. To make a new slide, we add three dashes at any point in our R Markdown document. I've copied the relevant portion of the document and added these dashes.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}

\CommentTok{\#\# Bill Length}

\CommentTok{We can make a histogram to see the distribution of bill lengths.}

\CommentTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\CommentTok{penguins \%\textgreater{}\% }
\CommentTok{  ggplot(aes(x = bill\_length\_mm)) +}
\CommentTok{  geom\_histogram() +}
\CommentTok{  theme\_minimal()}
\CommentTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

If I knit again, what was one slide is now broken into two: an Introduction slide and a Bill Length slide. We can see both in Figure \ref{fig:penguins-report-2-pages}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/penguins-report-2-pages} \caption{The presentation broken into two slides}\label{fig:penguins-report-2-pages}
\end{figure}

If I look closely, I can see that the bottom of histogram is ever so slightly cut off. I can fix this by adjusting its size. We do this using the code chunk option \texttt{fig.height} to make our figure four inches tall.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}

\CommentTok{\#\# Bill Length}

\CommentTok{We can make a histogram to see the distribution of bill lengths.}

\CommentTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r fig.height = 4\}}
\CommentTok{penguins \%\textgreater{}\%}
\CommentTok{  ggplot(aes(x = bill\_length\_mm)) +}
\CommentTok{  geom\_histogram() +}
\CommentTok{  theme\_minimal()}
\CommentTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

Doing this makes the histogram fit on the slide and also reveals the text that was hidden below.

\hypertarget{incrementally-revealing-content}{%
\subsection*{Incrementally Revealing Content}\label{incrementally-revealing-content}}
\addcontentsline{toc}{subsection}{Incrementally Revealing Content}

When presenting, it's often useful to only show a portion of the content on each slide at a time. Let's say, for example, we know that when we're presenting the first slide, we want to talk a bit about each penguin species. Rather than have all three species visible when we open this slide, it would be nice to have the names come up one at a time. We can do this using what \texttt{xaringan} calls incremental reveal.

To use this feature, we put two dashes between any content we want to incrementally reveal. This code, for example, will let us show Adelie on the screen, then Adelie and Gentoo, then Adelie, Gentoo, and Chinstrap.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\# Introduction}

\NormalTok{We are writing a report about the **Palmer Penguins**. These penguins are *really* amazing. There are three species:}

\SpecialStringTok{{-} }\NormalTok{Adelie}

\NormalTok{{-}{-}}

\SpecialStringTok{{-} }\NormalTok{Gentoo}

\NormalTok{{-}{-}}

\SpecialStringTok{{-} }\NormalTok{Chinstrap}
\end{Highlighting}
\end{Shaded}

When presenting your slides, you'll use the right arrow to incrementally reveal the species. We can see what this looks like in Figure \ref{fig:incremental-reveal}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/incremental-reveal} \caption{One slide shown with incremental reveal}\label{fig:incremental-reveal}
\end{figure}

\hypertarget{aligning-content}{%
\subsection*{Aligning Content}\label{aligning-content}}
\addcontentsline{toc}{subsection}{Aligning Content}

When designing your presentation, you'll also likely want to control the alignment of content. We do this by adding what are known as content classes. You can surround any content with the classes \texttt{.left{[}{]}}, \texttt{right{[}{]}}, and \texttt{center{[}{]}} to align them. For example, on our slide that creates a histogram and associated text, we could put \texttt{.center{[}{]}} around the code chunk that makes the histogram:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Bill Length}

\NormalTok{We can make a histogram to see the distribution of bill lengths.}

\NormalTok{.center[}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r fig.height = 4\}}
\InformationTok{penguins \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = bill\_length\_mm)) +}
\InformationTok{  geom\_histogram() +}
\InformationTok{  theme\_minimal()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\NormalTok{]}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{average\_bill\_length \textless{}{-} penguins \%\textgreater{}\% }
\InformationTok{  summarize(avg\_bill\_length = mean(bill\_length\_mm,}
\InformationTok{                                   na.rm = TRUE)) \%\textgreater{}\% }
\InformationTok{  pull(avg\_bill\_length)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\NormalTok{The chart shows the distribution of bill lengths. The average bill length is }\InformationTok{\textasciigrave{}r average\_bill\_length\textasciigrave{}}\NormalTok{ millimeters.}
\end{Highlighting}
\end{Shaded}

Doing this would center the chart on our slide, as we can see in Figure \ref{fig:center-chart}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/center-chart} \caption{A slide with the chart centered}\label{fig:center-chart}
\end{figure}

There are also built-in options to make two-column layouts. Adding \texttt{pull-left{[}{]}} and \texttt{pull-right{[}{]}} in this way will make two equally spaced columns.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Bill Length}

\NormalTok{We can make a histogram to see the distribution of bill lengths.}

\NormalTok{.pull{-}left[}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r fig.height = 4\}}
\InformationTok{penguins \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = bill\_length\_mm)) +}
\InformationTok{  geom\_histogram() +}
\InformationTok{  theme\_minimal()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\NormalTok{]}

\NormalTok{.pull{-}right[}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{average\_bill\_length \textless{}{-} penguins \%\textgreater{}\% }
\InformationTok{  summarize(avg\_bill\_length = mean(bill\_length\_mm,}
\InformationTok{                                   na.rm = TRUE)) \%\textgreater{}\% }
\InformationTok{  pull(avg\_bill\_length)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\NormalTok{The chart shows the distribution of bill lengths. The average bill length is }\InformationTok{\textasciigrave{}r average\_bill\_length\textasciigrave{}}\NormalTok{ millimeters.}
\NormalTok{]}
\end{Highlighting}
\end{Shaded}

We can see what this looks like in Figure \ref{fig:slide-two-columns} below.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/slide-two-columns} \caption{A slide with two columns}\label{fig:slide-two-columns}
\end{figure}

You can also use the content classes \texttt{.left-column{[}{]}} and \texttt{.right-column{[}{]}} to make a layout with a narrow left column and wide right column. The code below puts the text on the left and the histogram on the right.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Bill Length}

\NormalTok{We can make a histogram to see the distribution of bill lengths.}

\NormalTok{.right{-}column[}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r fig.height = 4\}}
\InformationTok{penguins \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = bill\_length\_mm)) +}
\InformationTok{  geom\_histogram() +}
\InformationTok{  theme\_minimal()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\NormalTok{]}

\NormalTok{.left{-}column[}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{average\_bill\_length \textless{}{-} penguins \%\textgreater{}\% }
\InformationTok{  summarize(avg\_bill\_length = mean(bill\_length\_mm,}
\InformationTok{                                   na.rm = TRUE)) \%\textgreater{}\% }
\InformationTok{  pull(avg\_bill\_length)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\NormalTok{The chart shows the distribution of bill lengths. The average bill length is }\InformationTok{\textasciigrave{}r average\_bill\_length\textasciigrave{}}\NormalTok{ millimeters.}
\NormalTok{]}
\end{Highlighting}
\end{Shaded}

We can see the slide output in Figure \ref{fig:slide-two-columns-v2}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/slide-two-columns-v2} \caption{A slide with a smaller left column and a larger right column}\label{fig:slide-two-columns-v2}
\end{figure}

In addition to aligning particular pieces of content on slides, we can also everything using the \texttt{.left}, \texttt{right}, and \texttt{center} classes. To do this, you specify the class right after the three dashes that indicate a new slide and before any content.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}

\AnnotationTok{class:}\CommentTok{ center}

\CommentTok{\#\# Bill Length}

\CommentTok{We can make a histogram to see the distribution of bill lengths.}

\CommentTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r fig.height = 4\}}
\CommentTok{penguins \%\textgreater{}\% }
\CommentTok{  ggplot(aes(x = bill\_length\_mm)) +}
\CommentTok{  geom\_histogram() +}
\CommentTok{  theme\_minimal()}
\CommentTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\CommentTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\CommentTok{average\_bill\_length \textless{}{-} penguins \%\textgreater{}\% }
\CommentTok{  summarize(avg\_bill\_length = mean(bill\_length\_mm,}
\CommentTok{                                   na.rm = TRUE)) \%\textgreater{}\% }
\CommentTok{  pull(avg\_bill\_length)}
\CommentTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\CommentTok{The chart shows the distribution of bill lengths. The average bill length is \textasciigrave{}r average\_bill\_length\textasciigrave{} millimeters.}
\end{Highlighting}
\end{Shaded}

Doing this would give us a fully-centered slide, as seen in Figure \ref{fig:slide-centered} below.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/slide-centered} \caption{A fully centered slide}\label{fig:slide-centered}
\end{figure}

You can also use the class \texttt{.middle} to vertically center the slide, as we'll see in the next section.

\hypertarget{adding-background-images-to-slides}{%
\subsection*{Adding Background Images to Slides}\label{adding-background-images-to-slides}}
\addcontentsline{toc}{subsection}{Adding Background Images to Slides}

The same syntax that we just used to center our entire slide can also enable us to add a background image. Below I've created a new slide, added the classes \texttt{center} and \texttt{middle} to horizontally and vertically align the content, and added a background image, surrounding the path to the image with \texttt{url()}.

\begin{Shaded}
\begin{Highlighting}[]
\AnnotationTok{class:}\CommentTok{ center, middle}
\AnnotationTok{background{-}image:}\CommentTok{ url("penguins.jpg")}

\FunctionTok{\#\# Penguins}
\end{Highlighting}
\end{Shaded}

Doing this gives me a slide with a picture of penguins in the background with the text Penguins in front of it. Figure \ref{fig:xaringan-background-image} shows the output.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/xaringan-background-image} \caption{A slide that uses a background image}\label{fig:xaringan-background-image}
\end{figure}

\hypertarget{customizing-our-slides-further}{%
\subsection*{Customizing our Slides Further}\label{customizing-our-slides-further}}
\addcontentsline{toc}{subsection}{Customizing our Slides Further}

One issue with the slide we just made is that it's hard to read the word ``Penguins.'' It would probably be best if we could make the text bigger and a different color. To do this, we need to use some CSS, the language used to style HTML documents (remember, when we knit our \texttt{xaringan} presentation, we end up with an HTML document). If you're thinking, ``I'm reading this book to learn R, not CSS,'' don't worry. You just have to know a bit of CSS to make tweaks to your slides.

To add custom CSS, I'm going to create a code chunk. To tell R Markdown that this code chunk contains CSS, not R, I put the text ``css'' in between the curly brackets. I can then add CSS like this to tell R Markdown to make the h2 (the second-level header) 150px and white. I have to add the \texttt{.remark-slide-content} before the h2 in order to make sure we target the specific element in our presentation (remark comes from remark.js, a JavaScript library to make presentations that \texttt{xaringan} uses under the hood).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{css\}}
\FunctionTok{.remark{-}slide{-}content}\NormalTok{ h2 \{}
  \KeywordTok{font{-}size}\NormalTok{: }\DecValTok{150}\DataTypeTok{px}\OperatorTok{;}
  \KeywordTok{color}\NormalTok{: }\ConstantTok{white}\OperatorTok{;}
\NormalTok{\}}
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

We can see our slide in Figure \ref{fig:penguins-report}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/penguins-report} \caption{The title slide with changes to the font to make the text more visible}\label{fig:penguins-report}
\end{figure}

If I wanted to change the font, I could do so with some additional CSS. The first line of this code will make a font called Inter available to use in our slides (we do this because not everyone has this font installed on their computers). The two lines I added will make the h2 use the Inter font and make it bold.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{css\}}
\ImportTok{@import} \FunctionTok{url(}\StringTok{\textquotesingle{}https://fonts.googleapis.com/css2?family=Inter:wght@400;700\&display=swap\textquotesingle{}}\FunctionTok{)}\OperatorTok{;}

\FunctionTok{.remark{-}slide{-}content}\NormalTok{ h2 \{}
  \KeywordTok{font{-}size}\NormalTok{: }\DecValTok{150}\DataTypeTok{px}\OperatorTok{;}
  \KeywordTok{color}\NormalTok{: }\ConstantTok{white}\OperatorTok{;}
    \KeywordTok{font{-}family}\NormalTok{: Inter}\OperatorTok{;}
  \KeywordTok{font{-}weight}\NormalTok{: }\DecValTok{bold}\OperatorTok{;}
\NormalTok{\}}
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

The slide with bold Inter font is visible in Figure \ref{fig:penguins-report-inter}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/penguins-report-inter} \caption{The title slide with changes to the font to make the text more visible}\label{fig:penguins-report-inter}
\end{figure}

Because \texttt{xaringan} slides are built as HTML documents, the sky is the limit in terms of customizing them with CSS. Of course, you have to know the ins and outs of CSS, and if you're reading this book, you're probably more into R than CSS.Fortunately, there are two ways you can customize your slides without knowing CSS.

The first way is to use pre-built themes. R users have made \texttt{xaringan} themes that you can apply to your slides to change the overall look-and-feel. If you run this code, you will get a list of all of these themes.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(xaringan}\SpecialCharTok{:::}\FunctionTok{list\_css}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Doing this will show the following output:

\begin{verbatim}
#>  [1] "chocolate-fonts"  "chocolate"       
#>  [3] "default-fonts"    "default"         
#>  [5] "duke-blue"        "fc-fonts"        
#>  [7] "fc"               "glasgow_template"
#>  [9] "hygge-duke"       "hygge"           
#> [11] "ki-fonts"         "ki"              
#> [13] "kunoichi"         "lucy-fonts"      
#> [15] "lucy"             "metropolis-fonts"
#> [17] "metropolis"       "middlebury-fonts"
#> [19] "middlebury"       "nhsr-fonts"      
#> [21] "nhsr"             "ninjutsu"        
#> [23] "rladies-fonts"    "rladies"         
#> [25] "robot-fonts"      "robot"           
#> [27] "rutgers-fonts"    "rutgers"         
#> [29] "shinobi"          "tamu-fonts"      
#> [31] "tamu"             "uio-fonts"       
#> [33] "uio"              "uo-fonts"        
#> [35] "uo"               "uol-fonts"       
#> [37] "uol"              "useR-fonts"      
#> [39] "useR"             "uwm-fonts"       
#> [41] "uwm"              "wic-fonts"       
#> [43] "wic"
\end{verbatim}

You can then choose a theme you'd like to use. To use the theme, you adjust your YAML as follows. This code tells \texttt{xaringan} to use the default CSS as well as customizations made in the \texttt{metropolis} and \texttt{metropolis-fonts} CSS files (these come bundled with \texttt{xaringan} so you don't need to do anything beyond installing the package to access them).

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{{-}{-}{-}}
\FunctionTok{title}\KeywordTok{:}\AttributeTok{ }\StringTok{"Penguins Report"}
\FunctionTok{author}\KeywordTok{:}\AttributeTok{ }\StringTok{"David Keyes"}
\FunctionTok{date}\KeywordTok{:}\AttributeTok{ }\StringTok{"2024{-}01{-}12"}
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon\_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{css}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{default}\KeywordTok{,}\AttributeTok{ metropolis}\KeywordTok{,}\AttributeTok{ metropolis{-}fonts}\KeywordTok{]}
\PreprocessorTok{{-}{-}{-}}
\end{Highlighting}
\end{Shaded}

You can see how this theme changes the look-and-feel of our slides in Figure \ref{fig:xaringan-metropolis} below.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/xaringan-metropolis} \caption{A slide using the metropolis theme}\label{fig:xaringan-metropolis}
\end{figure}

If writing custom CSS is the totally flexible but more challenging option to tweaking your \texttt{xaringan} slides, using a custom theme is way simpler but a lot less flexible. A nice middle ground is to use the \texttt{xaringanthemer} package by Garrick Aden-Buie. This package has several built-in themes and also allows you to easily create your own custom \texttt{xaringan} theme. After installing the \texttt{xaringanthemer} package, you adjust the css line in your YAML to use the \texttt{xaringan-themer.css} file.

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{{-}{-}{-}}
\FunctionTok{title}\KeywordTok{:}\AttributeTok{ }\StringTok{"Penguins Report"}
\FunctionTok{author}\KeywordTok{:}\AttributeTok{ }\StringTok{"David Keyes"}
\FunctionTok{date}\KeywordTok{:}\AttributeTok{ }\StringTok{"2024{-}01{-}12"}
\FunctionTok{output}\KeywordTok{:}
\AttributeTok{  xaringan:}\FunctionTok{:moon\_reader}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{css}\KeywordTok{:}\AttributeTok{ xaringan{-}themer.css}
\PreprocessorTok{{-}{-}{-}}
\end{Highlighting}
\end{Shaded}

With this in place, you can now customize your slides by using the \texttt{style\_xaringan()} function. This function has over 60 arguments, allowing you to tweak nearly any part of your \texttt{xaringan} slides. To make the same changes that we made above with custom CSS, I'll use just a few of the arguments. One particularly nice thing about the \texttt{xaringanthemer} package is that you can use any font available on Google Fonts by simply adding its name to \texttt{header\_font\_family} or any other similar argument (no need to run the line above that made the Inter font available to us). To make the same changes that I made with custom CSS above, I would add a code chunk at the top of my document that looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{library(xaringanthemer)}

\InformationTok{style\_xaringan(}
\InformationTok{  header\_h2\_font\_size = "150px",}
\InformationTok{  header\_color = "white",}
\InformationTok{  header\_font\_weight = "bold",}
\InformationTok{  header\_font\_family = "Inter"}
\InformationTok{)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

I could show you what my slide with the penguin image background looks like, but trust me, it's exactly identical to the slide we made previously with custom CSS.

\hypertarget{in-conclusion-the-advantages-of-xaringan}{%
\section*{\texorpdfstring{In Conclusion: The Advantages of \texttt{xaringan}}{In Conclusion: The Advantages of xaringan}}\label{in-conclusion-the-advantages-of-xaringan}}
\addcontentsline{toc}{section}{In Conclusion: The Advantages of \texttt{xaringan}}

Now that we've discussed how to use \texttt{xaringan}, let's talk a bit about why you might consider switching to it for your presentations. In my conversation with Silvia Canelón, she brought up three main reasons.

First, if you're already working in R and R Markdown, being able to produce slides in the same tool is a game changer. Say you've written a report that you've knitted to a Word document. You can now reuse your code from that R Markdown document and use it to make figures, tables, and more in your \texttt{xaringan} slides.

Second, because \texttt{xaringan} creates slides as HTML documents, you can post them online (we'll discuss ways to do this in Chapter \ref{websites-chapter}). No need to email or print out your slides for your viewers. Just share the link to your slides and you're done.

The third benefit of using \texttt{xaringan} is accessibility. As Canelón put it to me, ``when {[}people{]} have the HTML version of the slides, they have some control over what it looks like.'' People with limited vision are able to access HTML documents in ways that are accessible to them. They can, for example, increase the text size or use screen readers. Making presentations with \texttt{xaringan} isn't just a cool trick. It also means more people can engage with your slides.

\hypertarget{websites-chapter}{%
\chapter{Make Websites to Share Results Online}\label{websites-chapter}}

In summer 2020, Matt Herman moved with his family from Brooklyn to Westchester County, New York. It was the first summer of the COVID pandemic, and Herman was shocked to see that the high-quality data put out by the City of New York was not replicated in Westchester County. At a time before vaccines were available, daily choices depended on access to good data. Not having data made simple decisions, like whether to take children to the park, feel impossible.

Matt Herman was not just any person with an interest in COVID data. He was also, at the time, the Deputy Director of the ChildStat Data Unit in the Office of Research and Analytics at the New York City Administration for Children's Services. This handful of a title meant that he was skilled at working with data. And with these skills, Herman realized that he could create a COVID Westchester County COVID data resource that he and others needed. The data was out there; it just needed someone to make it accessible.

What Herman ended up creating was the Westchester COVID-19 Tracking website. Built entirely in R, this website had charts, maps, tables, and text that summarized the latest COVID data for Westchester County. Although the website is no longer consistently updated, it is still available at \url{https://westchester-covid.mattherman.info/} (a screenshot is in Figure \ref{fig:westchester-website-screenshot}), and it shows what is possible with R.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/westchester-website} \caption{A screenshot of the Westchester COVID-19 website}\label{fig:westchester-website-screenshot}
\end{figure}

The code that Herman wrote to make the website is a set of R Markdown files, strung together with the \texttt{distill} package. You may not think of R as a tool for making websites, but it can make them quite well -- and \texttt{distill} makes it straightforward. If you already use R to work with your data, creating a website is a great way to share your results.

In this chapter, I'll explain the basics of how \texttt{distill} works by creating a simple website with it (the Westchester COVID-19 website that Matt Herman created is quite complicated so I'll use examples from it, but won't walk through it line by line). Within this website, we'll show how to create things like different page layouts, navigation menus, interactive graphics, and more. We'll then discuss different strategies to host your website. We'll conclude with some reflections on why the \texttt{distill} package to make websites is a great option for R users looking to get their results online.

\hypertarget{creating-a-website-with-the-distill-package}{%
\section*{\texorpdfstring{Creating a Website With the \texttt{distill} Package}{Creating a Website With the distill Package}}\label{creating-a-website-with-the-distill-package}}
\addcontentsline{toc}{section}{Creating a Website With the \texttt{distill} Package}

There are a few different ways to make websites using R Markdown. There is the \texttt{blogdown} package, which uses the Hugo static site generator under the surface. It is flexible but finicky (updates to Hugo themes are notorious for breaking \texttt{blogdown} websites). For those looking for a simple option, the \texttt{distill} package is the way to go. It's what Matt Herman and many others have used to quickly and attractively get R Markdown-based websites up and running.

To understand how \texttt{distill} works, think back to when we have knitted our R Markdown documents to HTML (for example, in chapter \ref{rmarkdown-chapter}). These have all been one-offs, with a single R Markdown document generating a single HTML file. A website, on the other hand, is a collection of HTML files. The \texttt{distill} package is what enables us to use multiple R Markdown documents to create multiple HTML files, and have them all connected with a navigation menu and more.

To create a \texttt{distill} website, you'll first need to install the package using \texttt{install.packages("distill")}. Once you've done that, the easiest way to start a \texttt{distill} website project is to go to File \textgreater{} New Project \textgreater{} New Directory. Once you get the menu visible in Figure \ref{fig:new-distill-website}, scroll down and select Distill Website.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/new-distill-website} \caption{Menu to create a new distill website}\label{fig:new-distill-website}
\end{figure}

Once you do that, you'll see the menu in Figure \ref{fig:create-distill-website}. Here, in addition to specifying the directory and subdirectory where your project will live on your computer, you'll also want to give your website a title. You can also select Configure for GitHub Pages if you'd like. GitHub Pages is an easy way to get your website online, and I'll show how it works below. I'm going to create a new website called COVID Website and select the option to configure it for GitHub Pages.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/create-distill-website} \caption{Giving your distill website a name}\label{fig:create-distill-website}
\end{figure}

Let's now take a look at the files in our project. In addition to the \texttt{covid-website.Rproj} file that indicates that we're working in an RStudio project, we've got two R Markdown documents (\texttt{about.Rmd} and \texttt{index.Rmd}), a \texttt{\_site.yml} file, and a \texttt{docs} folder. The \texttt{docs} folder is where the rendered HTML files that make up our website will go, and we'll talk about them later. Let's begin by looking at the two R Markdown documents and the \texttt{\_site.yml} file.

\hypertarget{working-with-r-markdown-documents-in-distill}{%
\section*{\texorpdfstring{Working with R Markdown Documents in \texttt{distill}}{Working with R Markdown Documents in distill}}\label{working-with-r-markdown-documents-in-distill}}
\addcontentsline{toc}{section}{Working with R Markdown Documents in \texttt{distill}}

If we open up the \texttt{index.Rmd} file, we see the following code.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\AnnotationTok{title:}\CommentTok{ "COVID Website"}
\AnnotationTok{description:}\CommentTok{ |}
\CommentTok{  Welcome to the website. I hope you enjoy it!}
\AnnotationTok{site:}\CommentTok{ distill::distill\_website}
\CommentTok{{-}{-}{-}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r setup, include=FALSE\}}
\InformationTok{knitr::opts\_chunk$set(echo = FALSE)}

\InformationTok{\# Learn more about creating websites with Distill at:}
\InformationTok{\# https://rstudio.github.io/distill/website.html}

\InformationTok{\# Learn more about publishing to GitHub Pages at:}
\InformationTok{\# https://rstudio.github.io/distill/publish\_website.html\#github{-}pages}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

For the most part, this looks like a standard R Markdown document. In the YAML, we can see a couple differences with other R Markdown documents we've worked with: the \texttt{description} parameter and the line that says \texttt{site:\ distill::distill\_website}. The \texttt{description} specifies text that will go below the title of each page, as seen in Figure \ref{fig:website-description}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/website-description} \caption{The default website description}\label{fig:website-description}
\end{figure}

The \texttt{site:\ distill::distill\_website} specifies that the R Markdown document is the root page of a \texttt{distill} website. This means that when we knit, R Markdown knows to create a website, rather than an individual HTML file.

On top of these two new parameters, we also are missing one parameter that we've seen in other R Markdown documents. This is the \texttt{output} parameter, which we've used to specify the output format of our R Markdown document on knitting. The reason we don't have this \texttt{output} parameter in our R Markdown documents is that we specify the output for the entire website in our \texttt{\_site.yml} file.

\hypertarget{setting-options-for-our-website-with-_site.yml}{%
\section*{\texorpdfstring{Setting Options for Our Website with \texttt{\_site.yml}}{Setting Options for Our Website with \_site.yml}}\label{setting-options-for-our-website-with-_site.yml}}
\addcontentsline{toc}{section}{Setting Options for Our Website with \texttt{\_site.yml}}

The promise of \texttt{distill} is that it we can make several R Markdown documents and combine them into a website. To do this, we need a place to tell R which R Markdown documents make up the website, what the knitted files should look like, what the website should be called, and more. This all happens in the \texttt{\_site.yml} file. If we open up the \texttt{\_site.yml} file, we see the following code.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{name}\KeywordTok{:}\AttributeTok{ }\StringTok{"covid{-}website"}
\FunctionTok{title}\KeywordTok{:}\AttributeTok{ }\StringTok{"COVID Website"}
\FunctionTok{description}\KeywordTok{: }\CharTok{|}
\NormalTok{  COVID Website}
\FunctionTok{output\_dir}\KeywordTok{:}\AttributeTok{ }\StringTok{"docs"}
\FunctionTok{navbar}\KeywordTok{:}
\AttributeTok{  }\FunctionTok{right}\KeywordTok{:}
\AttributeTok{    }\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{text}\KeywordTok{:}\AttributeTok{ }\StringTok{"Home"}
\AttributeTok{      }\FunctionTok{href}\KeywordTok{:}\AttributeTok{ index.html}
\AttributeTok{    }\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{text}\KeywordTok{:}\AttributeTok{ }\StringTok{"About"}
\AttributeTok{      }\FunctionTok{href}\KeywordTok{:}\AttributeTok{ about.html}
\FunctionTok{output}\KeywordTok{:}\AttributeTok{ distill::distill\_article}
\end{Highlighting}
\end{Shaded}

Let's go backwards through this file, starting with the \texttt{output:\ distill::distill\_article} line. This line specifies that all R Markdown documents should be rendered using the \texttt{distill\_article} format. This format, which we'll discuss more below, allows for things such as layouts of different widths, asides (parenthetical items that live in a sidebar next to the main content), easily customizable CSS, and more.

Next, let's look at the \texttt{navbar} section. This, as you might guess from the name, is where we define the top navigation bar on our website. Our navigation bar is placed on the right side (swapping \texttt{right} for \texttt{left} would switch its position) with two pages: Home and About. Figure \ref{fig:navbar} below highlights the navigation bar created from our code.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/navbar} \caption{The website navigation bar}\label{fig:navbar}
\end{figure}

Breaking down the \texttt{navbar} code, the \texttt{text} parameter determines what shows up in the menu. For example, if I wanted to change ``About'' to ``About this Website'', I would change this portion of the \texttt{\_site.yml} to this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{navbar}\KeywordTok{:}
\AttributeTok{  }\FunctionTok{right}\KeywordTok{:}
\AttributeTok{    }\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{text}\KeywordTok{:}\AttributeTok{ }\StringTok{"Home"}
\AttributeTok{      }\FunctionTok{href}\KeywordTok{:}\AttributeTok{ index.html}
\AttributeTok{    }\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{text}\KeywordTok{:}\AttributeTok{ }\StringTok{"About this Website"}
\AttributeTok{      }\FunctionTok{href}\KeywordTok{:}\AttributeTok{ about.html}
\end{Highlighting}
\end{Shaded}

The \texttt{href} parameter determines where the text in the navigation bar links to. You'll probably have noticed that the HTML files linked to have the same names as our R Markdown documents. This is because of the behavior we saw in Chapter \ref{rmarkdown-chapter}, where the names of HTML files are the same as the R Markdown documents used to create them, swapping out \texttt{.Rmd} for \texttt{.html} (so, for example, \texttt{index.Rmd} becomes \texttt{index.html}).

Moving up in the \texttt{\_site.yml} file, the \texttt{output\_dir} parameter determines where the rendered HTML files live when we generate our website. The \texttt{docs} directory is listed here because we selected the Configure for GitHub Pages option when creating our website (more on this below). However, you can change the output directory to any folder you choose. The \texttt{description} parameter provides a short description of the website that will show up in search results. Finally, we have the \texttt{title} and \texttt{name}. The \texttt{title} parameter creates the title for the entire website and shows up in the top left of the navigation bar by the default. The \texttt{name} parameter determines the URL for your website (if you don't change anything, it will be the name of the directory where your \texttt{distill} project lives).

\hypertarget{building-our-site}{%
\section*{Building our Site}\label{building-our-site}}
\addcontentsline{toc}{section}{Building our Site}

So far, we've looked at our R Markdown documents and the \texttt{\_site.yml} file. We haven't, however, created our website. There are three ways to do this.

The first option is to use the Build Website button, which can be found in the Build tab of the top right pane on RStudio, seen in Figure \ref{fig:build-website} below.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/build-website} \caption{The build website button}\label{fig:build-website}
\end{figure}

The second option to build your website is to use the function \texttt{rmarkdown::render\_site()}. You can run this in the console or in an R script file. The third option, applicable if you're working in RStudio, is to use the keyboard shortcut command/control (Mac/Windows) + shift + B.

All three options will render all of the R Markdown documents and add the top navigation bar to them, with the options specified in the \texttt{\_site.yml} file. To find the rendered files, look in the output directory you specified (for us, that was \texttt{docs}). Open up any HTML file and you'll find your website, which should look like Figure \ref{fig:covid-website-default-content}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-website-default-content} \caption{The COVID website with default content}\label{fig:covid-website-default-content}
\end{figure}

\hypertarget{custom-css}{%
\section*{Custom CSS}\label{custom-css}}
\addcontentsline{toc}{section}{Custom CSS}

Websites made with \texttt{distill} tend to look similar (it's the tradeoff of working with a simple approach). But you can change how your website looks using some custom CSS. The \texttt{distill} package even provides a function to simplify the process.

To get started, the easiest approach is to run the \texttt{create\_theme()} function from \texttt{distill}. Doing so will create a file called \texttt{theme.css}, which we can see below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/* base variables */}

\CommentTok{/* Edit the CSS properties in this file to create a custom}
\CommentTok{   Distill theme. Only edit values in the right column}
\CommentTok{   for each row; values shown are the CSS defaults.}
\CommentTok{   To return any property to the default,}
\CommentTok{   you may set its value to: unset}
\CommentTok{   All rows must end with a semi{-}colon.                      */}

\CommentTok{/* Optional: embed custom fonts here with \textasciigrave{}@import\textasciigrave{}          */}
\CommentTok{/* This must remain at the top of this file.                 */}

\NormalTok{html \{}
  \CommentTok{/*{-}{-} Main font sizes {-}{-}*/}
  \VariableTok{{-}{-}title{-}size}\NormalTok{:      }\DecValTok{50}\DataTypeTok{px}\OperatorTok{;}
  \VariableTok{{-}{-}body{-}size}\NormalTok{:       }\DecValTok{1.06}\DataTypeTok{rem}\OperatorTok{;}
  \VariableTok{{-}{-}code{-}size}\NormalTok{:       }\DecValTok{14}\DataTypeTok{px}\OperatorTok{;}
  \VariableTok{{-}{-}aside{-}size}\NormalTok{:      }\DecValTok{12}\DataTypeTok{px}\OperatorTok{;}
  \VariableTok{{-}{-}fig{-}cap{-}size}\NormalTok{:    }\DecValTok{13}\DataTypeTok{px}\OperatorTok{;}
  \CommentTok{/*{-}{-} Main font colors {-}{-}*/}
  \VariableTok{{-}{-}title{-}color}\NormalTok{:     }\ConstantTok{\#000000}\OperatorTok{;}
  \VariableTok{{-}{-}header{-}color}\NormalTok{:    }\FunctionTok{rgba(}\DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0.8}\FunctionTok{)}\OperatorTok{;}
  \VariableTok{{-}{-}body{-}color}\NormalTok{:      }\FunctionTok{rgba(}\DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0.8}\FunctionTok{)}\OperatorTok{;}
  \VariableTok{{-}{-}aside{-}color}\NormalTok{:     }\FunctionTok{rgba(}\DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0.6}\FunctionTok{)}\OperatorTok{;}
  \VariableTok{{-}{-}fig{-}cap{-}color}\NormalTok{:   }\FunctionTok{rgba(}\DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0.6}\FunctionTok{)}\OperatorTok{;}
  \CommentTok{/*{-}{-} Specify custom fonts \textasciitilde{}\textasciitilde{}\textasciitilde{} must be imported above   {-}{-}*/}
  \VariableTok{{-}{-}heading{-}font}\NormalTok{:    }\DecValTok{sans{-}serif}\OperatorTok{;}
  \VariableTok{{-}{-}mono{-}font}\NormalTok{:       }\DecValTok{monospace}\OperatorTok{;}
  \VariableTok{{-}{-}body{-}font}\NormalTok{:       }\DecValTok{sans{-}serif}\OperatorTok{;}
  \VariableTok{{-}{-}navbar{-}font}\NormalTok{:     }\DecValTok{sans{-}serif}\OperatorTok{;}  \CommentTok{/* websites + blogs only */}
\NormalTok{\}}

\CommentTok{/*{-}{-} ARTICLE METADATA {-}{-}*/}
\NormalTok{d{-}byline \{}
  \VariableTok{{-}{-}heading{-}size}\NormalTok{:    }\DecValTok{0.6}\DataTypeTok{rem}\OperatorTok{;}
  \VariableTok{{-}{-}heading{-}color}\NormalTok{:   }\FunctionTok{rgba(}\DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0.5}\FunctionTok{)}\OperatorTok{;}
  \VariableTok{{-}{-}body{-}size}\NormalTok{:       }\DecValTok{0.8}\DataTypeTok{rem}\OperatorTok{;}
  \VariableTok{{-}{-}body{-}color}\NormalTok{:      }\FunctionTok{rgba(}\DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0.8}\FunctionTok{)}\OperatorTok{;}
\NormalTok{\}}

\CommentTok{/*{-}{-} ARTICLE TABLE OF CONTENTS {-}{-}*/}
\FunctionTok{.d{-}contents}\NormalTok{ \{}
  \VariableTok{{-}{-}heading{-}size}\NormalTok{:    }\DecValTok{18}\DataTypeTok{px}\OperatorTok{;}
  \VariableTok{{-}{-}contents{-}size}\NormalTok{:   }\DecValTok{13}\DataTypeTok{px}\OperatorTok{;}
\NormalTok{\}}

\CommentTok{/*{-}{-} ARTICLE APPENDIX {-}{-}*/}
\NormalTok{d{-}appendix \{}
  \VariableTok{{-}{-}heading{-}size}\NormalTok{:    }\DecValTok{15}\DataTypeTok{px}\OperatorTok{;}
  \VariableTok{{-}{-}heading{-}color}\NormalTok{:   }\FunctionTok{rgba(}\DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0.65}\FunctionTok{)}\OperatorTok{;}
  \VariableTok{{-}{-}text{-}size}\NormalTok{:       }\DecValTok{0.8}\DataTypeTok{em}\OperatorTok{;}
  \VariableTok{{-}{-}text{-}color}\NormalTok{:      }\FunctionTok{rgba(}\DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{0.5}\FunctionTok{)}\OperatorTok{;}
\NormalTok{\}}

\CommentTok{/*{-}{-} WEBSITE HEADER + FOOTER {-}{-}*/}
\CommentTok{/* These properties only apply to Distill sites and blogs  */}

\FunctionTok{.distill{-}site{-}header}\NormalTok{ \{}
  \VariableTok{{-}{-}title{-}size}\NormalTok{:       }\DecValTok{18}\DataTypeTok{px}\OperatorTok{;}
  \VariableTok{{-}{-}text{-}color}\NormalTok{:       }\FunctionTok{rgba(}\DecValTok{255}\OperatorTok{,} \DecValTok{255}\OperatorTok{,} \DecValTok{255}\OperatorTok{,} \DecValTok{0.8}\FunctionTok{)}\OperatorTok{;}
  \VariableTok{{-}{-}text{-}size}\NormalTok{:        }\DecValTok{15}\DataTypeTok{px}\OperatorTok{;}
  \VariableTok{{-}{-}hover{-}color}\NormalTok{:      }\ConstantTok{white}\OperatorTok{;}
  \VariableTok{{-}{-}bkgd{-}color}\NormalTok{:       }\ConstantTok{\#0F2E3D}\OperatorTok{;}
\NormalTok{\}}

\FunctionTok{.distill{-}site{-}footer}\NormalTok{ \{}
  \VariableTok{{-}{-}text{-}color}\NormalTok{:       }\FunctionTok{rgba(}\DecValTok{255}\OperatorTok{,} \DecValTok{255}\OperatorTok{,} \DecValTok{255}\OperatorTok{,} \DecValTok{0.8}\FunctionTok{)}\OperatorTok{;}
  \VariableTok{{-}{-}text{-}size}\NormalTok{:        }\DecValTok{15}\DataTypeTok{px}\OperatorTok{;}
  \VariableTok{{-}{-}hover{-}color}\NormalTok{:      }\ConstantTok{white}\OperatorTok{;}
  \VariableTok{{-}{-}bkgd{-}color}\NormalTok{:       }\ConstantTok{\#0F2E3D}\OperatorTok{;}
\NormalTok{\}}

\CommentTok{/*{-}{-} Additional custom styles {-}{-}*/}
\CommentTok{/* Add any additional CSS rules below                      */}
\end{Highlighting}
\end{Shaded}

Within that file, there are a set of what are known as CSS variables. Most of them have names that clearly show their purpose. Our \texttt{theme.css} file contains the default values for our CSS variables. If we want to make tweaks, we simply change them. For example, I've taken a section of the \texttt{theme.css} file and made the title and text size larger and made the background color a light blue.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.distill{-}site{-}header \{}
\NormalTok{  {-}{-}title{-}size:       28px;}
\NormalTok{  {-}{-}text{-}color:       rgba(255, 255, 255, 0.8);}
\NormalTok{  {-}{-}text{-}size:        20px;}
\NormalTok{  {-}{-}hover{-}color:      white;}
\NormalTok{  {-}{-}bkgd{-}color:       \#6cabdd;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Before we rebuild our site to see these changes, we need to do one other thing: tell \texttt{distill} to use this custom CSS when rendering. We do this by adding this line in the \texttt{\_site.yml} file: \texttt{theme:\ theme.css}. Our \texttt{\_site.yml} will now look like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{name}\KeywordTok{:}\AttributeTok{ }\StringTok{"covid{-}website"}
\FunctionTok{title}\KeywordTok{:}\AttributeTok{ }\StringTok{"COVID Website"}
\FunctionTok{description}\KeywordTok{: }\CharTok{|}
\NormalTok{  COVID Website}
\FunctionTok{theme}\KeywordTok{:}\AttributeTok{ theme.css}
\FunctionTok{output\_dir}\KeywordTok{:}\AttributeTok{ }\StringTok{"docs"}
\FunctionTok{navbar}\KeywordTok{:}
\AttributeTok{  }\FunctionTok{right}\KeywordTok{:}
\AttributeTok{    }\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{text}\KeywordTok{:}\AttributeTok{ }\StringTok{"Home"}
\AttributeTok{      }\FunctionTok{href}\KeywordTok{:}\AttributeTok{ index.html}
\AttributeTok{    }\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{text}\KeywordTok{:}\AttributeTok{ }\StringTok{"About"}
\AttributeTok{      }\FunctionTok{href}\KeywordTok{:}\AttributeTok{ about.html}
\FunctionTok{output}\KeywordTok{:}\AttributeTok{ distill::distill\_article}
\end{Highlighting}
\end{Shaded}

Now we can generate our site again using any of the three options above. The website with our CSS tweaks can be seen in Figure \ref{fig:covid-website-css-tweaks} below.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-website-css-tweaks} \caption{The COVID website with tweaks to the CSS}\label{fig:covid-website-css-tweaks}
\end{figure}

As you can see in the \texttt{theme.css} file, there are a lot of CSS variables we can change to tweak the appearance of our website. Playing around with them and rebuilding your site is a great way to figure out what does what.

\hypertarget{adding-content-to-our-website}{%
\section*{Adding Content to Our Website}\label{adding-content-to-our-website}}
\addcontentsline{toc}{section}{Adding Content to Our Website}

So far, we've only been talking about customizing what our website looks like. But if we look at our website, it only has placeholder content, and there's not much of it. Let's talk now about adding content to our \texttt{distill} website.

The advantage of creating content in a \texttt{distill} website, of course, is that you do it just as you would with any other R Markdown document. All of the markdown text and code chunks that we discussed in Chapter \ref{rmarkdown-chapter} will work in \texttt{distill} as well.

I've written some code below that creates a table, a map, and a chart on our COVID website. After the YAML and \texttt{setup} code chunk, we load several packages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{tidyverse} for data import, manipulation, and plotting (with ggplot)
\item
  \texttt{janitor} for the \texttt{clean\_names()} function, which makes our variable names easier to work with
\item
  \texttt{tigris} to import geospatial data on states
\item
  \texttt{gt} for making nice tables, as discussed in \ref{tables-chapter}
\item
  \texttt{lubridate} to work with dates
\end{enumerate}

In the next code chunk, we import and clean the data. We also create a variable called \texttt{most\_recent\_day}, which allow us to use inline R code to put an always-up-to-date latest day in our text (see the header directly below this code chunk).

We then make a table that shows the death rates per 100,000 people in four states (the table would be long if we showed all 50 states). Next, we make a map of this same data, but for all states. Finally, we make a chart that shows COVID death rates over time (for legibility in this book, we only show four states).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\AnnotationTok{title:}\CommentTok{ "COVID Website"}
\AnnotationTok{description:}\CommentTok{ "Information about COVID rates in the United States over time"}
\AnnotationTok{site:}\CommentTok{ distill::distill\_website}
\CommentTok{{-}{-}{-}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r setup, include=FALSE\}}
\InformationTok{knitr::opts\_chunk$set(echo = FALSE,}
\InformationTok{                      warning = FALSE,}
\InformationTok{                      message = FALSE)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{\# Load packages}

\InformationTok{library(tidyverse)}
\InformationTok{library(janitor)}
\InformationTok{library(tigris)}
\InformationTok{library(gt)}
\InformationTok{library(lubridate)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{\# Import data}

\InformationTok{us\_states \textless{}{-} states(cb = TRUE, }
\InformationTok{                    resolution = "20m",}
\InformationTok{                    progress\_bar = FALSE) \%\textgreater{}\%}
\InformationTok{  shift\_geometry() \%\textgreater{}\% }
\InformationTok{  clean\_names() \%\textgreater{}\% }
\InformationTok{  select(geoid, name) \%\textgreater{}\% }
\InformationTok{  rename(state = name) \%\textgreater{}\% }
\InformationTok{  filter(state \%in\% state.name)}

\InformationTok{covid\_data \textless{}{-} read\_csv("https://data.rwithoutstatistics.com/us{-}states{-}covid{-}rolling{-}average.csv") \%\textgreater{}\% }
\InformationTok{  filter(state \%in\% state.name) \%\textgreater{}\% }
\InformationTok{  mutate(geoid = str\_remove(geoid, "USA{-}")) }

\InformationTok{most\_recent\_day \textless{}{-} covid\_data \%\textgreater{}\% }
\InformationTok{  slice\_max(order\_by = date,}
\InformationTok{            n = 1) \%\textgreater{}\% }
\InformationTok{  distinct(date) \%\textgreater{}\% }
\InformationTok{  mutate(date\_nice\_format = str\_glue("\{month(date, label = TRUE, abbr = FALSE)\} \{day(date)\}, \{year(date)\}")) \%\textgreater{}\% }
\InformationTok{  pull(date\_nice\_format)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\FunctionTok{\# COVID Death Rates as of \textasciigrave{}r most\_recent\_day\textasciigrave{}}

\NormalTok{This table shows COVID death rates per 100,000 people in four states states.}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{\# Make table}

\InformationTok{covid\_data \%\textgreater{}\% }
\InformationTok{  filter(state \%in\% c("Alabama",}
\InformationTok{                      "Alaska",}
\InformationTok{                      "Arizona",}
\InformationTok{                      "Arkansas")) \%\textgreater{}\% }
\InformationTok{  slice\_max(order\_by = date,}
\InformationTok{            n = 1) \%\textgreater{}\% }
\InformationTok{  select(state, deaths\_avg\_per\_100k) \%\textgreater{}\% }
\InformationTok{  arrange(state) \%\textgreater{}\% }
\InformationTok{  set\_names("State", "Death rate") \%\textgreater{}\% }
\InformationTok{  gt() \%\textgreater{}\% }
\InformationTok{  tab\_style(}
\InformationTok{    style = cell\_text(weight = "bold"),}
\InformationTok{    locations = cells\_column\_labels()}
\InformationTok{  )}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\NormalTok{We can see this same death rate data for all states on a map.}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{\# Make map}

\InformationTok{most\_recent \textless{}{-} us\_states \%\textgreater{}\% }
\InformationTok{  left\_join(covid\_data, by = "state") \%\textgreater{}\% }
\InformationTok{  slice\_max(order\_by = date,}
\InformationTok{            n = 1) }

\InformationTok{most\_recent \%\textgreater{}\% }
\InformationTok{  ggplot(aes(fill = deaths\_avg\_per\_100k)) +}
\InformationTok{  geom\_sf() +}
\InformationTok{  scale\_fill\_viridis\_c(option = "rocket") +}
\InformationTok{  labs(fill = "Deaths per\textbackslash{}n100,000 people") +}
\InformationTok{  theme\_void()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\FunctionTok{\# COVID Death Rates Over Time}

\NormalTok{The following chart shows COVID death rates from the start of COVID in early 2020 until }\InformationTok{\textasciigrave{}r most\_recent\_day\textasciigrave{}}\NormalTok{.}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{\# Make chart}

\InformationTok{covid\_data \%\textgreater{}\% }
\InformationTok{  filter(state \%in\% c("Alabama",}
\InformationTok{                      "Alaska",}
\InformationTok{                      "Arizona",}
\InformationTok{                      "Arkansas")) \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = date,}
\InformationTok{             y = deaths\_avg\_per\_100k,}
\InformationTok{             group = state,}
\InformationTok{             fill = deaths\_avg\_per\_100k)) +}
\InformationTok{  geom\_col() +}
\InformationTok{  scale\_fill\_viridis\_c(option = "rocket") +}
\InformationTok{  theme\_minimal() +}
\InformationTok{  labs(title = "Deaths per 100,000 people over time") +}
\InformationTok{  theme(legend.position = "none",}
\InformationTok{        plot.title.position = "plot",}
\InformationTok{        plot.title = element\_text(face = "bold"),}
\InformationTok{        panel.grid.minor = element\_blank(),}
\InformationTok{        axis.title = element\_blank()) +}
\InformationTok{  facet\_wrap(\textasciitilde{}state,}
\InformationTok{             nrow = 2)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

We can see what this website looks like in Figure \ref{fig:covid-website-static-page} below.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-website-static-page} \caption{The COVID website with a table, map, and chart}\label{fig:covid-website-static-page}
\end{figure}

\hypertarget{using-different-layouts}{%
\section*{Using Different Layouts}\label{using-different-layouts}}
\addcontentsline{toc}{section}{Using Different Layouts}

One nice feature of \texttt{distill} is the ability to make the output of certain code chunks larger. To show how this works, let's focus on our map. Because many states are quite small, especially in the northeast, it's a bit challenging to see them. If we could make the entire map bigger, that would be helpful.

The \texttt{distill} package has four layouts that you can apply to a code chunk to make its output wider: \texttt{l-body-outset} (a bit wider than default), \texttt{l-page} (wider still), \texttt{l-screen} (full screen), and \texttt{l-screen-inset} (full screen with a bit of a buffer). Let's apply \texttt{l-screen-inset} to the map code chunk as follows:

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r layout = "l{-}screen{-}inset"\}}
\InformationTok{\# Make map}

\InformationTok{most\_recent \textless{}{-} us\_states \%\textgreater{}\% }
\InformationTok{  left\_join(covid\_data, by = "state") \%\textgreater{}\% }
\InformationTok{  slice\_max(order\_by = date,}
\InformationTok{            n = 1) }

\InformationTok{most\_recent \%\textgreater{}\% }
\InformationTok{  ggplot(aes(fill = deaths\_avg\_per\_100k)) +}
\InformationTok{  geom\_sf() +}
\InformationTok{  scale\_fill\_viridis\_c(option = "rocket") +}
\InformationTok{  labs(fill = "Deaths per\textbackslash{}n100,000 people") +}
\InformationTok{  theme\_void()}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

Doing this makes our map wider (and taller), and, as a result, much easier to read. You can see what the entire page looks like in Figure \ref{fig:covid-website-static-page-wide-map} below.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-website-static-page-wide-map} \caption{The COVID website with the map made larger}\label{fig:covid-website-static-page-wide-map}
\end{figure}

\hypertarget{making-our-content-interactive}{%
\section*{Making Our Content Interactive}\label{making-our-content-interactive}}
\addcontentsline{toc}{section}{Making Our Content Interactive}

Up to this point, all of the content we've added to our website has been static. There is none of the interactivity common in websites. Since we're developing a website, it makes sense to take advantage of the medium. Matt Herman uses interactive graphics and maps on his Westchester County COVID website. Figure \ref{fig:westchester-website-tooltip}, for example, shows a simple tooltip that allows the user to see results for any single day.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/westchester-website-tooltip} \caption{Interactive tooltips showing new cases by day}\label{fig:westchester-website-tooltip}
\end{figure}

Herman also makes interactive tables with the \texttt{DT} package, allowing the user to scroll through the data and sort by any of the variables in it by clicking on its name. The table can be seen in Figure \ref{fig:dt-table}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/dt-table} \caption{An interactive table made with the DT package}\label{fig:dt-table}
\end{figure}

Let's add some interactivity to our national COVID website. We'll begin by making our table interactive. Remember how we had to only include four states in order to keep our table from getting super long? With an interactive table, we can avoid this. The \texttt{reactable} package, like the \texttt{DT} package, is a great option for interactive tables. If we swap out the \texttt{gt} package code we used to make our static table with the \texttt{reactable()} function, we can show all states.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reactable)}

\NormalTok{covid\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{slice\_max}\NormalTok{(}\AttributeTok{order\_by =}\NormalTok{ date,}
            \AttributeTok{n =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(state, deaths\_avg\_per\_100k) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(state) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_names}\NormalTok{(}\StringTok{"State"}\NormalTok{, }\StringTok{"Death rate"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{reactable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

The \texttt{reactable} package shows ten rows by default, with pagination added below our table, as seen in Figure \ref{fig:covid-website-reactable}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-website-reactable} \caption{An interactive table built with reactable}\label{fig:covid-website-reactable}
\end{figure}

The \texttt{reactable()} function also enables sorting by default. Although we used the \texttt{arrange()} function in our code above to sort by state name, if users click the ``Death rate'' column, the table will be sorted by that variable. Figure \ref{fig:covid-website-reactable-sorted} shows this.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-website-reactable-sorted} \caption{The table sorted by death rate}\label{fig:covid-website-reactable-sorted}
\end{figure}

We can also give our chart some interactivity. To do this, we'll use the same package that Matt Herman uses: \texttt{plotly}. The basic idea with \texttt{plotly} is this: create a plot with ggplot and save it as an object. Then, pass it to the \texttt{ggplotly()} function, which turns it into an interactive plot. Here's how it would work with my chart showing COVID death rates over time.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(plotly)}

\NormalTok{covid\_chart }\OtherTok{\textless{}{-}}\NormalTok{ covid\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(state }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"Alabama"}\NormalTok{,}
                      \StringTok{"Alaska"}\NormalTok{,}
                      \StringTok{"Arizona"}\NormalTok{,}
                      \StringTok{"Arkansas"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date,}
             \AttributeTok{y =}\NormalTok{ deaths\_avg\_per\_100k,}
             \AttributeTok{group =}\NormalTok{ state,}
             \AttributeTok{fill =}\NormalTok{ deaths\_avg\_per\_100k)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{(}\AttributeTok{option =} \StringTok{"rocket"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Deaths per 100,000 people over time"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{,}
        \AttributeTok{plot.title.position =} \StringTok{"plot"}\NormalTok{,}
        \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{face =} \StringTok{"bold"}\NormalTok{),}
        \AttributeTok{panel.grid.minor =} \FunctionTok{element\_blank}\NormalTok{(),}
        \AttributeTok{axis.title =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{state,}
             \AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}


\FunctionTok{ggplotly}\NormalTok{(covid\_chart)}
\end{Highlighting}
\end{Shaded}

With this code, I get an interactive chart. But the tooltip that users see on hover (see Figure \ref{fig:covid-website-messy-tooltips} below) is cluttered and overwhelming because the \texttt{ggplotly()} function shows all data by default.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-website-messy-tooltips} \caption{Messy tooltips on our COVID death rates graph}\label{fig:covid-website-messy-tooltips}
\end{figure}

To make our tooltip more informative, we can also create a single variable and then tell \texttt{ggplotly()} to just use this. Below, I begin by creating a \texttt{date\_nice\_format} variable so that we get, say, January 1, 2021 instead of 2021-01-01. I then combine this with the state and death rates (\texttt{deaths\_avg\_per\_100k}) variables, saving my result as \texttt{tooltip\_text}. I then add a new aesthetic property in the \texttt{ggplot()} function: \texttt{text\ =\ tooltip\_text}. On its own, this doesn't do anything. But when I add \texttt{tooltip\ =\ "tooltip\_text"} to the \texttt{ggplotly()} function, it changes the tooltip.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{covid\_chart }\OtherTok{\textless{}{-}}\NormalTok{ covid\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(state }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"Alabama"}\NormalTok{,}
                      \StringTok{"Alaska"}\NormalTok{,}
                      \StringTok{"Arizona"}\NormalTok{,}
                      \StringTok{"Arkansas"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{date\_nice\_format =} \FunctionTok{str\_glue}\NormalTok{(}\StringTok{"\{month(date, label = TRUE, abbr = FALSE)\} \{day(date)\}, \{year(date)\}"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{tooltip\_text =} \FunctionTok{str\_glue}\NormalTok{(}\StringTok{"\{state\}\textless{}br\textgreater{}\{date\_nice\_format\}\textless{}br\textgreater{}\{deaths\_avg\_per\_100k\} per 100,000 people"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ date,}
             \AttributeTok{y =}\NormalTok{ deaths\_avg\_per\_100k,}
             \AttributeTok{group =}\NormalTok{ state,}
             \AttributeTok{text =}\NormalTok{ tooltip\_text,}
             \AttributeTok{fill =}\NormalTok{ deaths\_avg\_per\_100k)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{(}\AttributeTok{option =} \StringTok{"rocket"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Deaths per 100,000 people over time"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{,}
        \AttributeTok{plot.title.position =} \StringTok{"plot"}\NormalTok{,}
        \AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{face =} \StringTok{"bold"}\NormalTok{),}
        \AttributeTok{panel.grid.minor =} \FunctionTok{element\_blank}\NormalTok{(),}
        \AttributeTok{axis.title =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{state,}
             \AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}


\FunctionTok{ggplotly}\NormalTok{(covid\_chart,}
                 \AttributeTok{tooltip =} \StringTok{"tooltip\_text"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:covid-website-tooltip} shows what our new tooltip looks like: a simple summary of the state, nicely formatted date, and death rate on that day.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/covid-website-tooltip} \caption{Easy to read interactive tooltips on the COVID death rate chart}\label{fig:covid-website-tooltip}
\end{figure}

Adding interactivity in this way is a great way to take advantage of the medium of a website. Users who might feel overwhelmed looking at the static chart can explore the interactive version, hovering to see a summary of the results on any single day.

\hypertarget{hosting}{%
\section*{Hosting}\label{hosting}}
\addcontentsline{toc}{section}{Hosting}

Making a website is great, but you also need a way to share it. There are various ways to do this, ranging from quite simple to quite complex.

The simplest solution is to zip up the files in your \texttt{docs} folder (or whatever folder you put your rendered website in) and email your ZIP file to others. They can unzip it and open the HTML files in their browser. This works fine if you know you won't want to make changes to the data or styling of your website. But, as we discussed in \ref{rmarkdown-chapter}, what we think of as a one-time project rarely is.

A better approach is to put your entire \texttt{docs} folder in a place where others can see it. This could be an internal network, Dropbox, Google Drive, Box, or something similar. This has the advantage of being simple to implement while allowing you to only give access to those you want to see your website. You can even automate the process of copying your \texttt{docs} folder to various online file sharing sites using R packages: the \texttt{rdrop2} package works with Dropbox, \texttt{googledrive} works with Google Drive, and \texttt{boxr} works with Box. In the past, I have written code like that below, which renders my site, uses the \texttt{dir\_ls()} function from the \texttt{fs} package to identify all files in the \texttt{docs} directory, and then uploads these files to Dropbox. Having your code to render and upload it to Dropbox all in one file means you can just run your entire file, generating and uploading your website in one go.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(rmarkdown)}
\FunctionTok{library}\NormalTok{(fs)}
\FunctionTok{library}\NormalTok{(rdrop2)}

\CommentTok{\# Render the website}
\FunctionTok{render\_site}\NormalTok{()}

\CommentTok{\# Upload to Dropbox}
\NormalTok{website\_files }\OtherTok{\textless{}{-}} \FunctionTok{dir\_ls}\NormalTok{(}\AttributeTok{path =} \StringTok{"docs"}\NormalTok{,}
                        \AttributeTok{type =} \StringTok{"file"}\NormalTok{,}
                        \AttributeTok{recurse =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{walk}\NormalTok{(website\_files, drop\_upload, }\AttributeTok{path =} \StringTok{"COVID Website"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The most complicated yet most powerful solution is to use GitHub Pages (or a similar static hosting service). The idea is that, each time you commit your code to GitHub (or a similar service for posting code online), it deploys to URL you have set up. Learning to use GitHub is an investment (the book \emph{Happy Git and GitHub for the useR} by Jenny Bryan is a great resource), but being able to host your website for free makes it worth the time and effort.

Here's how GitHub Pages works. Most of the time, when you look at a file on GitHub, you see its underlying source code. If you look at an HTML file, you see the HTML code. GitHub Pages, on the other hand, doesn't show you the code of HTML files; it shows you the rendered HTML files. This is what we want when we create a website. To host your website on GitHub Pages, you'll need to first push your code to GitHub. Once you have a repository set up there, you'll go to it, then go to the Settings tab. From there, what you see should look like Figure \ref{fig:gh-pages}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/gh-pages} \caption{Setting up GitHub Pages}\label{fig:gh-pages}
\end{figure}

On this screen, you now choose how you want GitHub to deploy the raw HTML into a rendered website. The easiest approach is to keep the default source (``Deploy from a branch'') and then select your default branch (usually \texttt{main} or \texttt{master}). You then select a directory where the HTML files you want to be rendered are found. You have two options: \texttt{root} or \texttt{docs}. My files are in \texttt{docs} so I'll choose that. Do you remember, way back in the beginning, how we told RStudio to configure our website for GitHub pages? Doing so put our HTML files in the \texttt{docs} folder because that is one place that GitHub Pages looks for such files. After we hit save, wait a few minutes, and GitHub will show us a URL like that in Figure \ref{fig:gh-pages-published} where our website now lives.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/gh-pages-published} \caption{The location of our website published with GitHub Pages}\label{fig:gh-pages-published}
\end{figure}

The best part about hosting your website on GitHub Pages is that, any time you make updates to your code or data, the website will update as well. If I were to run my code next week, render my website again, and push it to GitHub, GitHub Pages would automatically update the website it serves online. RMarkdown-based websites made with \texttt{distill}, combined with GitHub Pages, makes building and maintaining websites a snap.

\hypertarget{conclusion-1}{%
\section*{Conclusion}\label{conclusion-1}}
\addcontentsline{toc}{section}{Conclusion}

During my conversation with Matt Herman, I asked him a basic but important question: why did you build the Westchester County COVID-19 website using R? Why not use a more well-known process for building websites? Herman's answer was twofold.

Herman first said that staying within R just made sense because it was where he was already doing everything else. ``As a pretty strong R user,'' he said, ``I was doing all of my data collection and manipulation and wrangling and visualization and R. Then I could also just stay in R to create the website and to create stuff that I couldn't make myself in HTML or JavaScript.''

The second reason Herman chose to build his website in R builds on the first. He's not a front-end web developer and his familiarity with HTML and Javascript is limited. But, using \texttt{distill}, \texttt{plotly}, and \texttt{DT}, he can get the benefit of HTML and Javascript because ``these R packages have wrapped the JavaScript libraries.'' If you look at the source code of the website Herman created, you'll see sophisticated HTML and Javascript. But because the packages he uses convert R code into HTML and Javascript, he is able to build websites he would not otherwise be capable of building.

Since we spoke, Herman has continued building websites with R.
He and and his current colleagues at the Council of State Governments Justice Center, have made a great website using Quarto, the language-agnostic version of R Markdown. This website, found at \url{https://projects.csgjusticecenter.org/tools-for-states-to-address-crime/}, highlights crime trends throughout the United States using many of the same techniques we've discussed in this chapter.

No matter which specific packages you use, using R gives you a quick way to develop complex websites without having to be a sophisticated front-end web developer. The websites look good and communicate well. They are one more way that R can help you share your results with the world.

\hypertarget{part-automate}{%
\part*{Automate}\label{part-automate}}
\addcontentsline{toc}{part}{Automate}

\hypertarget{googlesheets-chapter}{%
\chapter{Automatically Access the Latest Data}\label{googlesheets-chapter}}

In 2020, Meghan Harris started a job at the Primary Care Research Institute at the University of Buffalo. Her title was Data Integration Specialist, which was both generic and an accurate representation of the work she would do. One of the projects Harris worked on during her time in this job was looking at people affected by opioid use disorder, and data for this project came from a variety of surveys, all of which fed into a series of Google Sheets. She started her new job faced with a jumble of Google Sheets, tasked with helping the organization to make sense of and use its data.

For many people, especially those working in tools like SPSS, SAS, or Stata, the first step here would probably be to download the Google Sheets data. Exporting Google Sheets data to CSV or Excel files isn't complicated so you may be wondering why I'm devoting an entire chapter to working with data from Google Sheets. Here's why.

If R Markdown is an improvement on the typical multitool workflow discussed in Chapter \ref{rmarkdown-chapter}, using the \texttt{googlesheets4} package to access data directly from Google Sheets represents a similar improvement compared to downloading data each time you want to update a report. Rather than going through multiple steps (downloading data, copying it into your project, adjusting your code so it imports the new data), you can write code so that it automatically brings in new data directly from Google Sheets. Whenever you need to update your report, simply run your code and the report, generated with the latest data, will be created.

In this chapter I'll use a simple example to demonstrate how the \texttt{googlesheets4} package works. This example, using fake data on video game preferences, is one that Meghan Harris created to mirror her work with opioid survey data (which, for obvious reasons, is confidential). We'll then conclude with some reflections on how connecting directly to data sources such as Google Sheets through R can improve your workflow.

\hypertarget{using-the-googlesheets4-package-to-bring-in-up-to-date-data}{%
\section*{\texorpdfstring{Using the \texttt{googlesheets4} Package to Bring in Up-to-Date Data}{Using the googlesheets4 Package to Bring in Up-to-Date Data}}\label{using-the-googlesheets4-package-to-bring-in-up-to-date-data}}
\addcontentsline{toc}{section}{Using the \texttt{googlesheets4} Package to Bring in Up-to-Date Data}

After installing the \texttt{googlesheets4} package with the standard \texttt{install.packages("googlesheets4")}, you are ready to use it. Before you access data in a Google Sheet, you will need to connect your Google account. To do this, run the \texttt{gs4\_auth()} function in the console. If you have more than one Google account, you will need to select the account that has access to the Google Sheet you want to work with. Once you do so, you'll see a screen that looks like Figure \ref{fig:tidyverse-access-r}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/tidyverse-access-r} \caption{The screen asking for authorization to access your Google Sheets data}\label{fig:tidyverse-access-r}
\end{figure}

The most important thing is to check the box for ``See, edit, create, and delete all your Google Sheets spreadsheets''. This will ensure that R is able to access data from your Google Sheets account. Hit Continue and you'll be given the message ``Authentication complete. Please close this page and return to R.'' The \texttt{googlesheets4} package will now save your credentials so that you can use them in the future without having to authenticate each time.

Now that we've connected R to our Google account, we can import data. We'll import fake data that Meghan Harris created on video preferences. You can see in Figure \ref{fig:video-game-survey-data} what it looks like in Google Sheets.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/video-game-survey-data} \caption{The video game data in Google Sheets}\label{fig:video-game-survey-data}
\end{figure}

The \texttt{googlesheets4} package has a function called \texttt{read\_sheet()} that allows you to pull in data directly from a Google Sheet. We can import this data with this function in the following way:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(googlesheets4)}

\NormalTok{survey\_data\_raw }\OtherTok{\textless{}{-}} \FunctionTok{read\_sheet}\NormalTok{(}\StringTok{"https://docs.google.com/spreadsheets/d/1AR0\_RcFBg8wdiY4Cj{-}k8vRypp\_txh27MyZuiRdqScog/edit?usp=sharing"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can take a look at the \texttt{survey\_data\_raw} object to confirm that our data was imported. I'm using the \texttt{glimpse()} function from the \texttt{dplyr} package in order to make it easier to read.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}

\NormalTok{survey\_data\_raw }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

The output shows that we have indeed imported the data directly from Google Sheets:

\begin{verbatim}
#> Rows: 5
#> Columns: 5
#> $ Timestamp                         <dttm> 2022-05-16 15:2~
#> $ `How old are you?`                <chr> "25-34", "45-54"~
#> $ `Do you like to play video games` <chr> "Yes", "No", "Ye~
#> $ `What kind of games do you like?` <chr> "Sandbox, Role-P~
#> $ `What's your favorite game?`      <chr> "It's hard to ch~
\end{verbatim}

Once we have the data in R, we can now use the same workflow as always when creating reports with R Markdown. The code below is taken from an R Markdown report that Meghan Harris made to summarize the video games data. You can see the YAML, the \texttt{setup} code chunk, a chunk to load packages, followed by the code to read in data from Google Sheets. The next code chunk cleans the \texttt{survey\_data\_raw} object, saving the result as \texttt{survey\_data\_clean}. We then use this data to:

\begin{itemize}
\tightlist
\item
  Calculate the number of respondents and put this in the text using inline R code
\item
  Create a table that shows the respondents broken down by age group
\item
  Create a graph that shows how many respondents like video games
\end{itemize}

The code used to generate this report is below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\AnnotationTok{title:}\CommentTok{ "Video Game Survey"}
\AnnotationTok{output:}\CommentTok{ html\_document}
\CommentTok{{-}{-}{-}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r setup, include=FALSE\}}
\InformationTok{knitr::opts\_chunk$set(echo = FALSE,}
\InformationTok{                      warning = FALSE,}
\InformationTok{                      message = FALSE)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{library(tidyverse)}
\InformationTok{library(janitor)}
\InformationTok{library(googlesheets4)}
\InformationTok{library(gt)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{\# Import data from Google Sheets}
\InformationTok{survey\_data\_raw \textless{}{-} read\_sheet("https://docs.google.com/spreadsheets/d/1AR0\_RcFBg8wdiY4Cj{-}k8vRypp\_txh27MyZuiRdqScog/edit?usp=sharing")}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{\# Clean data}
\InformationTok{survey\_data\_clean \textless{}{-} survey\_data\_raw \%\textgreater{}\%}
\InformationTok{  clean\_names() \%\textgreater{}\%}
\InformationTok{  mutate("participant\_id" = as.character(row\_number())) \%\textgreater{}\%}
\InformationTok{  rename("age" = "how\_old\_are\_you",}
\InformationTok{         "like\_games" = "do\_you\_like\_to\_play\_video\_games",}
\InformationTok{         "game\_types" = "what\_kind\_of\_games\_do\_you\_like",}
\InformationTok{         "favorite\_game" = "whats\_your\_favorite\_game") \%\textgreater{}\%}
\InformationTok{  relocate(participant\_id, .before = "age") \%\textgreater{}\%}
\InformationTok{  mutate(age = factor(age, levels = c("Under 18", "18{-}24", "25{-}34", "35{-}44", "45{-}54", "55{-}64", "Over 65")))}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\FunctionTok{\# Respondent Demographics}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{\# Calculate number of respondents}
\InformationTok{number\_of\_respondents \textless{}{-} nrow(survey\_data\_clean)}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\NormalTok{We received responses from }\InformationTok{\textasciigrave{}r number\_of\_respondents\textasciigrave{}}\NormalTok{ respondents. Their ages are below.}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{survey\_data\_clean \%\textgreater{}\% }
\InformationTok{  select(participant\_id, age) \%\textgreater{}\% }
\InformationTok{  gt() \%\textgreater{}\% }
\InformationTok{  cols\_label(}
\InformationTok{    participant\_id = "Participant ID",}
\InformationTok{    age = "Age"}
\InformationTok{  ) \%\textgreater{}\% }
\InformationTok{  tab\_style(}
\InformationTok{    style = cell\_text(weight = "bold"),}
\InformationTok{    locations = cells\_column\_labels()}
\InformationTok{  ) \%\textgreater{}\% }
\InformationTok{  cols\_align(}
\InformationTok{    align = "left",}
\InformationTok{    columns = everything()}
\InformationTok{  ) \%\textgreater{}\% }
\InformationTok{  cols\_width(}
\InformationTok{    participant\_id \textasciitilde{} px(200),}
\InformationTok{    age \textasciitilde{} px(700)}
\InformationTok{  ) }
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\FunctionTok{\# Video Games}

\NormalTok{We asked if respondents liked video games. Their responses are below.}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\}}
\InformationTok{survey\_data\_clean \%\textgreater{}\%}
\InformationTok{  count(like\_games) \%\textgreater{}\% }
\InformationTok{  ggplot(aes(x = like\_games,}
\InformationTok{             y = n,}
\InformationTok{             fill = like\_games)) +}
\InformationTok{  geom\_col() +}
\InformationTok{  scale\_fill\_manual(values = c(}
\InformationTok{    "No" = "\#6cabdd",}
\InformationTok{    "Yes" = "\#ff7400"}
\InformationTok{  )) +}
\InformationTok{  labs(title = "How Many People Like Video Games?", }
\InformationTok{       x = NULL,}
\InformationTok{       y = "Number of Participants") +}
\InformationTok{  theme\_minimal(base\_size = 16) +}
\InformationTok{  theme(legend.position = "none",}
\InformationTok{        panel.grid.minor = element\_blank(),}
\InformationTok{        panel.grid.major.x = element\_blank(),}
\InformationTok{        axis.title.y = element\_blank(),}
\InformationTok{        plot.title = element\_text(face = "bold",}
\InformationTok{                                  hjust = 0.5))}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

The resulting report can be seen in Figure \ref{fig:video-game-report}.

\begin{figure}
\includegraphics[width=1\linewidth]{assets/video-game-report} \caption{The rendered video game report}\label{fig:video-game-report}
\end{figure}

The R Markdown document here isn't revolutionary (it's the same types of things we saw in Chapter \ref{rmarkdown-chapter}). What is different is the way we're importing our data. Because we're bringing it in directly from Google Sheets, there's no risk of, say, accidentally reading in the wrong CSV. Automating this step reduces the risk of error.

The best part is that we can re-run our code at any point to bring in updated data. The \texttt{read\_sheet()} function will look for all data on the Google Sheet we specify. Our survey had five responses today, but if we run it again tomorrow and it has additional responses, they will all be included in the import. If you use Google Forms to run your survey and have the results go to a Google Sheet, you can have an always up-to-date summary report simply by clicking the Knit button in RStudio. That workflow is one that helped Meghan Harris to collect surveys and manage a wide range of data on opiod use disorder.

\hypertarget{conclusion-2}{%
\section*{Conclusion}\label{conclusion-2}}
\addcontentsline{toc}{section}{Conclusion}

In this chapter, we've shown how you can use the \texttt{googlesheets4} package to import data directly from Google Sheets. This takes our reproducibility one step further, making it possible not only to generate reports automatically, but also automating the process of bringing in the latest data.

This process of bringing in data directly from the source applies beyond Google Sheets. There are packages to bring in data directly from Excel365 (\texttt{Microsoft365R}), Qualtrics (\texttt{qualtRics}), Survey Monkey (\texttt{surveymonkey}), and other sources. Before hitting the ``Download Data'' button in your data collection tool of choice, it's worth looking into whether a package exists to import data directly into R.

For Meghan Harris, working directly with data in Google Sheets was a game-changer. She used \texttt{googlesheets4} to bring in data in multiple Google Sheets. From there, she was able to streamline analysis and reporting, which ultimately had a big impact on her organization's work. Data that had once been largely unused because accessing it was so complicated came to inform research on opioid use disorder. Bringing in data from Google Sheets with a few lines of code may seem small at first, but it can have a big impact.

\hypertarget{tidycensus-chapter}{%
\chapter{\texorpdfstring{Access Census Data with the \texttt{tidycensus} Package}{Access Census Data with the tidycensus Package}}\label{tidycensus-chapter}}

If you've ever worked with data from the United States Census Bureau, you know what a hassle it can be. The typical process involves going to the Census Bureau website, finding the data you need, downloading it, and then analyzing it in your tool of choice. Working with Census Bureau data in this way involves a lot of pointing and clicking, and gets very tedious over time.

That tedium is what drove Texas Christian University geographer Kyle Walker to develop a package to automate the process of bringing Census Bureau data into R. Walker had previously created a package called \texttt{tigris} (introduced in Chapter \ref{maps-chapter}) to automatically bring in shape files from the Census Bureau. As he told me, ``I was using \texttt{tigris} pretty heavily in my own work to bring in the spatial data, but I didn't have a seamless way to get the demographic data as well.'' Drawing on his experience developing \texttt{tigris}, Walker, along with co-author Matt Herman (yes, he of the Westchester COVID-19 website discussed in Chapter \ref{websites-chapter}), would develop the \texttt{tidycensus} package, which allows R users to bring in data directly from various Census Bureau datasets. With \texttt{tidycensus}, a user can write just a few lines of code and get data on, say, the median income in all 3,000 plus counties in the United States.

In this chapter, we'll learn how the \texttt{tidycensus} package works. We'll do this using examples from two datasets that \texttt{tidyverse} makes it possible to work with: the decennial Census and the American Community Survey. We'll also show how we can use the data from these two sources for additional analysis and to make maps by accessing geospatial and demographic data simultaneously. While this chapter focuses on data from the United States Census Bureau, the conclusion lists other R packages that access analogous data for other countries. And finally, the conclusion highlights some of the reasons why using a package like \texttt{tidycensus} can improve your workflow.

\hypertarget{using-tidycensus}{%
\section*{\texorpdfstring{Using \texttt{tidycensus}}{Using tidycensus}}\label{using-tidycensus}}
\addcontentsline{toc}{section}{Using \texttt{tidycensus}}

The \texttt{tidycensus} package is available on CRAN so you can install it as you would most packages: with \texttt{install.packages("tidycensus")}. In order to use \texttt{tidycensus} you must also get an API (application programming interface) key from the Census Bureau. This key, which is free, can be obtained by going to \url{https://api.census.gov/data/key_signup.html} and entering your details. Once you receive your API key by email, you need to put it in a place where \texttt{tidycensus} can find it. The \texttt{census\_api\_key()} function does this for you. Your best bet, after loading the \texttt{tidycensus} package, is to run the function as follows (replacing 123456789 with your actual API key):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidycensus)}

\FunctionTok{census\_api\_key}\NormalTok{(}\StringTok{"123456789"}\NormalTok{, }\AttributeTok{install =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{install\ =\ TRUE} argument will save your API key in your \texttt{.Renviron} file (a file designed to keep confidential information like API keys). R will look for your API key there in the future so that you don't have to enter it every time you want to use \texttt{tidycensus}.

Having obtained and saved our API key, we're now ready to use \texttt{tidycensus} to access data. The Census Bureau puts out many datasets, several of which can be accessed using \texttt{tidycensus}. The most common datasets to access with \texttt{tidycensus} are the decennial Census and the American Community Survey (other datasets that can be accessed are discussed in Chapter 2 of Kyle Walker's book \emph{Analyzing US Census Data: Methods, Maps, and Models in R}).

\hypertarget{working-with-decennial-census-data}{%
\subsection*{Working with Decennial Census Data}\label{working-with-decennial-census-data}}
\addcontentsline{toc}{subsection}{Working with Decennial Census Data}

We'll start out by accessing data from the 2020 Census on the Asian population in each state. To do this, we use the \texttt{get\_decennial()} function with three arguments:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_decennial}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{, }
              \AttributeTok{variables =} \StringTok{"P1\_006N"}\NormalTok{,}
              \AttributeTok{year =} \DecValTok{2020}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The arguments we're using here are:

\begin{itemize}
\tightlist
\item
  \texttt{geography}, which tells \texttt{get\_decennial()} to access data at the state level. There are many other geographies, including county, census tract, and more.
\item
  \texttt{variables} is where we choose the variable or variables we want to access. I know that \texttt{P2\_002N} is the variable name for the total Asian, but below I'll demonstrate how to identify other variables you may want to use.
\item
  \texttt{year} is where we select the year from which we want to access data. We're using data from the 2020 Census.
\end{itemize}

Running this code returns the following:

\begin{verbatim}
#> # A tibble: 52 x 4
#>    GEOID NAME                 variable   value
#>    <chr> <chr>                <chr>      <dbl>
#>  1 42    Pennsylvania         P1_006N   510501
#>  2 06    California           P1_006N  6085947
#>  3 54    West Virginia        P1_006N    15109
#>  4 49    Utah                 P1_006N    80438
#>  5 36    New York             P1_006N  1933127
#>  6 11    District of Columbia P1_006N    33545
#>  7 02    Alaska               P1_006N    44032
#>  8 12    Florida              P1_006N   643682
#>  9 45    South Carolina       P1_006N    90466
#> 10 38    North Dakota         P1_006N    13213
#> # ... with 42 more rows
\end{verbatim}

The resulting data frame has four variables:

\begin{itemize}
\tightlist
\item
  \texttt{GEOID} is the geographic identifier given by the Census Bureau for the state. Each state has a geographic identifier, as do all counties, census tracts, and all other geographies.
\item
  \texttt{NAME} is the name of each state.
\item
  \texttt{variable} is the name of the variable we passed to the \texttt{get\_decennial()} function.
\item
  \texttt{value} is the numeric value for the state and variable in each row. In our case, it represents the total Asian population in each state.
\end{itemize}

Let's say we want to calculate the Asian population as a percentage of all people in each state. To do that, we'd need both the Asian population as well as the total population. How would we do this?

\hypertarget{identifying-variables}{%
\subsubsection*{Identifying Variables}\label{identifying-variables}}
\addcontentsline{toc}{subsubsection}{Identifying Variables}

First, we'd need to know the variable names. I looked up the variable name for Asian population (P1\_006N) without showing you how I did it. Let's backtrack so I can show you how to identify variable names. The \texttt{tidycensus} package has a function called \texttt{load\_variables()} that shows us all of the variables from the decennial Census. If we run it with the argument \texttt{year} set to 2020 and \texttt{dataset} set to ``pl'' (pl refers to public law 94-171, which requires the Census to produce so-called redistricting summary data files every ten years).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load\_variables}\NormalTok{(}\AttributeTok{year =} \DecValTok{2020}\NormalTok{, }
               \AttributeTok{dataset =} \StringTok{"pl"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Running this code returns the name, label (description), and concept (category) of all variables available to us. Looking at this, we can see variable \texttt{P1\_006N}. We can also see that variable \texttt{P1\_001N} gives us the total population.

\begin{verbatim}
#> # A tibble: 301 x 3
#>    name    label                                     concept
#>    <chr>   <chr>                                     <chr>  
#>  1 H1_001N " !!Total:"                               OCCUPA~
#>  2 H1_002N " !!Total:!!Occupied"                     OCCUPA~
#>  3 H1_003N " !!Total:!!Vacant"                       OCCUPA~
#>  4 P1_001N " !!Total:"                               RACE   
#>  5 P1_002N " !!Total:!!Population of one race:"      RACE   
#>  6 P1_003N " !!Total:!!Population of one race:!!Whi~ RACE   
#>  7 P1_004N " !!Total:!!Population of one race:!!Bla~ RACE   
#>  8 P1_005N " !!Total:!!Population of one race:!!Ame~ RACE   
#>  9 P1_006N " !!Total:!!Population of one race:!!Asi~ RACE   
#> 10 P1_007N " !!Total:!!Population of one race:!!Nat~ RACE   
#> # ... with 291 more rows
\end{verbatim}

\hypertarget{using-multiple-variables}{%
\subsubsection*{Using Multiple Variables}\label{using-multiple-variables}}
\addcontentsline{toc}{subsubsection}{Using Multiple Variables}

Now that we know which variables we need, we can use the \texttt{get\_decennial()} function again. We used just one variable above, but we can run our code again with two variables.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_decennial}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{, }
              \AttributeTok{variables =} \FunctionTok{c}\NormalTok{(}\StringTok{"P1\_001N"}\NormalTok{, }\StringTok{"P1\_006N"}\NormalTok{),}
              \AttributeTok{year =} \DecValTok{2020}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(NAME)}
\end{Highlighting}
\end{Shaded}

I've added \texttt{arrange(NAME)} after \texttt{get\_decennial()} so that the results are sorted by state name, allowing us to see that we have both variables for each state.

\begin{verbatim}
#> # A tibble: 104 x 4
#>    GEOID NAME       variable    value
#>    <chr> <chr>      <chr>       <dbl>
#>  1 01    Alabama    P1_001N   5024279
#>  2 01    Alabama    P1_006N     76660
#>  3 02    Alaska     P1_001N    733391
#>  4 02    Alaska     P1_006N     44032
#>  5 04    Arizona    P1_001N   7151502
#>  6 04    Arizona    P1_006N    257430
#>  7 05    Arkansas   P1_001N   3011524
#>  8 05    Arkansas   P1_006N     51839
#>  9 06    California P1_001N  39538223
#> 10 06    California P1_006N   6085947
#> # ... with 94 more rows
\end{verbatim}

\hypertarget{giving-variables-better-names}{%
\subsubsection*{Giving Variables Better Names}\label{giving-variables-better-names}}
\addcontentsline{toc}{subsubsection}{Giving Variables Better Names}

I often have trouble remembering what variable names like \texttt{P1\_001N} and \texttt{P1\_006N} mean. Fortunately, we can adjust our code in \texttt{get\_decennial()} to give our variables more meaningful names using the following syntax:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_decennial}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{, }
              \AttributeTok{variables =} \FunctionTok{c}\NormalTok{(}\AttributeTok{total\_population =} \StringTok{"P1\_001N"}\NormalTok{, }
                            \AttributeTok{asian\_population =} \StringTok{"P1\_006N"}\NormalTok{),}
              \AttributeTok{year =} \DecValTok{2020}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(NAME)}
\end{Highlighting}
\end{Shaded}

When we run this code, it is now much easier to remember which variables we are working with.

\begin{verbatim}
#> # A tibble: 104 x 4
#>    GEOID NAME       variable            value
#>    <chr> <chr>      <chr>               <dbl>
#>  1 01    Alabama    total_population  5024279
#>  2 01    Alabama    asian_population    76660
#>  3 02    Alaska     total_population   733391
#>  4 02    Alaska     asian_population    44032
#>  5 04    Arizona    total_population  7151502
#>  6 04    Arizona    asian_population   257430
#>  7 05    Arkansas   total_population  3011524
#>  8 05    Arkansas   asian_population    51839
#>  9 06    California total_population 39538223
#> 10 06    California asian_population  6085947
#> # ... with 94 more rows
\end{verbatim}

Instead of ``P1\_001N'' and ``P1\_006N'', we have ``total\_population'' and ``asian\_population.'' Much better!

\hypertarget{analyzing-census-data}{%
\subsubsection*{Analyzing Census Data}\label{analyzing-census-data}}
\addcontentsline{toc}{subsubsection}{Analyzing Census Data}

Let's now return to what started us down this path: calculating the Asian population in each state as a percentage of the total. To do this, we use the code from above and add a few things to it:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We use \texttt{group\_by(NAME)} to create one group for each state because we want to calculate the Asian population percentage in each state.
\item
  We use \texttt{mutate(pct\ =\ value\ /\ sum(value))} to calculate the percentage. This line takes the \texttt{value} in each row and divides it by the \texttt{total\_population} and \texttt{asian\_population} rows for each state.
\item
  We use \texttt{ungroup()} to remove the state-level grouping.
\item
  We use \texttt{filter(variable\ ==\ "asian\_population")} to only show the Asian population percentage.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_decennial}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{, }
              \AttributeTok{variables =} \FunctionTok{c}\NormalTok{(}\AttributeTok{total\_population =} \StringTok{"P1\_001N"}\NormalTok{, }
                            \AttributeTok{asian\_population =} \StringTok{"P1\_006N"}\NormalTok{),}
              \AttributeTok{year =} \DecValTok{2020}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(NAME) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(NAME) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pct =}\NormalTok{ value }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(value)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(variable }\SpecialCharTok{==} \StringTok{"asian\_population"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

When we run this code, we see the Asian population and the Asian population as a percentage of the total population in each state.

\begin{verbatim}
#> # A tibble: 52 x 5
#>    GEOID NAME                 variable          value    pct
#>    <chr> <chr>                <chr>             <dbl>  <dbl>
#>  1 01    Alabama              asian_population 7.67e4 0.0150
#>  2 02    Alaska               asian_population 4.40e4 0.0566
#>  3 04    Arizona              asian_population 2.57e5 0.0347
#>  4 05    Arkansas             asian_population 5.18e4 0.0169
#>  5 06    California           asian_population 6.09e6 0.133 
#>  6 08    Colorado             asian_population 2.00e5 0.0335
#>  7 09    Connecticut          asian_population 1.72e5 0.0456
#>  8 10    Delaware             asian_population 4.27e4 0.0413
#>  9 11    District of Columbia asian_population 3.35e4 0.0464
#> 10 12    Florida              asian_population 6.44e5 0.0290
#> # ... with 42 more rows
\end{verbatim}

\hypertarget{using-a-summary-variable}{%
\subsubsection*{Using a Summary Variable}\label{using-a-summary-variable}}
\addcontentsline{toc}{subsubsection}{Using a Summary Variable}

Kyle Walker knew that calculating summaries like this would be a common use case for \texttt{tidycensus}. So, to simplify things, he also gives us the \texttt{summary\_var} argument that we can use within \texttt{get\_decennial()}. Instead of putting ``P1\_001N'' (total population) in the \texttt{variables} argument, we can instead use it with the \texttt{summary\_var} argument as follows.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_decennial}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{, }
              \AttributeTok{variables =} \FunctionTok{c}\NormalTok{(}\AttributeTok{asian\_population =} \StringTok{"P1\_006N"}\NormalTok{),}
              \AttributeTok{summary\_var =} \StringTok{"P1\_001N"}\NormalTok{,}
              \AttributeTok{year =} \DecValTok{2020}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(NAME)}
\end{Highlighting}
\end{Shaded}

This returns a nearly identical data frame to what we got above, except that the total population is now a separate variable, rather than additional rows for each state.

\begin{verbatim}
#> # A tibble: 52 x 5
#>    GEOID NAME                 variable         value summa~1
#>    <chr> <chr>                <chr>            <dbl>   <dbl>
#>  1 01    Alabama              asian_populati~ 7.67e4  5.02e6
#>  2 02    Alaska               asian_populati~ 4.40e4  7.33e5
#>  3 04    Arizona              asian_populati~ 2.57e5  7.15e6
#>  4 05    Arkansas             asian_populati~ 5.18e4  3.01e6
#>  5 06    California           asian_populati~ 6.09e6  3.95e7
#>  6 08    Colorado             asian_populati~ 2.00e5  5.77e6
#>  7 09    Connecticut          asian_populati~ 1.72e5  3.61e6
#>  8 10    Delaware             asian_populati~ 4.27e4  9.90e5
#>  9 11    District of Columbia asian_populati~ 3.35e4  6.90e5
#> 10 12    Florida              asian_populati~ 6.44e5  2.15e7
#> # ... with 42 more rows, and abbreviated variable name
#> #   1: summary_value
\end{verbatim}

With our data in this new format, we can calculate the Asian population as a percentage of the whole using slightly different code.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_decennial}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{, }
              \AttributeTok{variables =} \FunctionTok{c}\NormalTok{(}\AttributeTok{asian\_population =} \StringTok{"P1\_006N"}\NormalTok{),}
              \AttributeTok{summary\_var =} \StringTok{"P1\_001N"}\NormalTok{,}
              \AttributeTok{year =} \DecValTok{2020}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(NAME) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pct =}\NormalTok{ value }\SpecialCharTok{/}\NormalTok{ summary\_value)}
\end{Highlighting}
\end{Shaded}

The resulting output is nearly identical.

\begin{verbatim}
#> # A tibble: 52 x 6
#>    GEOID NAME                 variable  value summa~1    pct
#>    <chr> <chr>                <chr>     <dbl>   <dbl>  <dbl>
#>  1 01    Alabama              asian_p~ 7.67e4  5.02e6 0.0153
#>  2 02    Alaska               asian_p~ 4.40e4  7.33e5 0.0600
#>  3 04    Arizona              asian_p~ 2.57e5  7.15e6 0.0360
#>  4 05    Arkansas             asian_p~ 5.18e4  3.01e6 0.0172
#>  5 06    California           asian_p~ 6.09e6  3.95e7 0.154 
#>  6 08    Colorado             asian_p~ 2.00e5  5.77e6 0.0346
#>  7 09    Connecticut          asian_p~ 1.72e5  3.61e6 0.0478
#>  8 10    Delaware             asian_p~ 4.27e4  9.90e5 0.0431
#>  9 11    District of Columbia asian_p~ 3.35e4  6.90e5 0.0486
#> 10 12    Florida              asian_p~ 6.44e5  2.15e7 0.0299
#> # ... with 42 more rows, and abbreviated variable name
#> #   1: summary_value
\end{verbatim}

How you choose to calculate summary statistics is up to you. The good thing is that \texttt{tidycensus} makes it easy to do either way!

\hypertarget{working-with-american-community-survey-data}{%
\subsection*{Working with American Community Survey Data}\label{working-with-american-community-survey-data}}
\addcontentsline{toc}{subsection}{Working with American Community Survey Data}

Let's switch now to accessing data from the American Community Survey (ACS). This survey, which is conducted every year, differs from the decennial Census in two major ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  It is given to a sample of people rather than the entire population.
\item
  It includes a wider range of questions.
\end{enumerate}

Despite these differences, accessing data from the ACS is nearly identical to how we accessed Census data. Instead of \texttt{get\_decennial()}, we use the function \texttt{get\_acs()}, but the arguments are the same. Here I've identified a variable I'm interested in (``B01002\_001'', which shows median age) and am using it to get the data for each state.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_acs}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{,}
        \AttributeTok{variables =} \StringTok{"B01002\_001"}\NormalTok{,}
        \AttributeTok{year =} \DecValTok{2020}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Here's what the output looks like:

\begin{verbatim}
#> # A tibble: 52 x 5
#>    GEOID NAME                 variable   estimate   moe
#>    <chr> <chr>                <chr>         <dbl> <dbl>
#>  1 01    Alabama              B01002_001     39.2   0.1
#>  2 02    Alaska               B01002_001     34.6   0.2
#>  3 04    Arizona              B01002_001     37.9   0.2
#>  4 05    Arkansas             B01002_001     38.3   0.2
#>  5 06    California           B01002_001     36.7   0.1
#>  6 08    Colorado             B01002_001     36.9   0.1
#>  7 09    Connecticut          B01002_001     41.1   0.2
#>  8 10    Delaware             B01002_001     41     0.2
#>  9 11    District of Columbia B01002_001     34.1   0.1
#> 10 12    Florida              B01002_001     42.2   0.2
#> # ... with 42 more rows
\end{verbatim}

There are two differences we can see in the \texttt{get\_acs()} output compared to that from \texttt{get\_decennial()}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The \texttt{value} column in \texttt{get\_decennial()} is now called \texttt{estimate}.
\item
  We have an additional column called \texttt{moe} for margin of error.
\end{enumerate}

Both of these changes are because the ACS is given to a sample of the population. As a result, we don't have precise values, but rather estimates, which are extrapolations from the sample to the population as a whole. And with an estimate comes a margin of error. In our state-level data, the margins of error are relatively low, but if you get data from smaller geographies, they tend to be higher. In cases where your margins of error are high relative to your estimates, you should interpret results with caution, as there is greater uncertainty about how well the data represents the population as a whole.

\hypertarget{using-acs-data-to-make-charts}{%
\subsubsection*{Using ACS Data to Make Charts}\label{using-acs-data-to-make-charts}}
\addcontentsline{toc}{subsubsection}{Using ACS Data to Make Charts}

As we saw with Census data on the Asian population in the United States, once you access data using the \texttt{tidycensus} package, you can do whatever else you want with it. We calculated the Asian population as a percentage of the total above. Here we could take the data on median age and pipe it into ggplot in order to create a bar chart.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_acs}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{,}
        \AttributeTok{variables =} \StringTok{"B01002\_001"}\NormalTok{,}
        \AttributeTok{year =} \DecValTok{2020}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ estimate,}
             \AttributeTok{y =}\NormalTok{ NAME)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:median-age-chart} add figure number shows our bar chart.

\begin{figure}
\includegraphics[width=1\linewidth]{tidycensus_files/figure-latex/median-age-chart-1} \caption{A bar chart showing the median age in each state}\label{fig:median-age-chart}
\end{figure}

This chart is nothing special, but the fact that it takes just six lines of code to create most definitely is.

\hypertarget{using-acs-data-to-make-maps}{%
\subsubsection*{Using ACS Data to Make Maps}\label{using-acs-data-to-make-maps}}
\addcontentsline{toc}{subsubsection}{Using ACS Data to Make Maps}

Kyle Walker's original motivation to build \texttt{tidycensus} came from wanting to make it easy to access demographic data, just as he had done with geospatial data in the \texttt{tigris} package. He succeeded. And one additional benefit of Walker working on both packages is that there is a tight integration between them. Using the \texttt{get\_acs()} function, you can add set the \texttt{geometry} argument to \texttt{TRUE} and you will get both demographic and geospatial data (which, under the hood comes from \texttt{tigris}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_acs}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{,}
        \AttributeTok{variables =} \StringTok{"B01002\_001"}\NormalTok{,}
        \AttributeTok{year =} \DecValTok{2020}\NormalTok{,}
        \AttributeTok{geometry =} \ConstantTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

If we take a look at the resulting data, we can see that it has the metadata and \texttt{geometry} column of simple features objects that we saw in Chapter \ref{maps-chapter}.

\begin{verbatim}
#> Simple feature collection with 52 features and 5 fields
#> Geometry type: MULTIPOLYGON
#> Dimension:     XY
#> Bounding box:  xmin: -179.1489 ymin: 17.88328 xmax: 179.7785 ymax: 71.36516
#> Geodetic CRS:  NAD83
#> First 10 features:
#>    GEOID        NAME   variable estimate moe
#> 1     35  New Mexico B01002_001     38.1 0.1
#> 2     72 Puerto Rico B01002_001     42.4 0.2
#> 3     06  California B01002_001     36.7 0.1
#> 4     01     Alabama B01002_001     39.2 0.1
#> 5     13     Georgia B01002_001     36.9 0.1
#> 6     05    Arkansas B01002_001     38.3 0.2
#> 7     41      Oregon B01002_001     39.5 0.1
#> 8     28 Mississippi B01002_001     37.7 0.2
#> 9     08    Colorado B01002_001     36.9 0.1
#> 10    49        Utah B01002_001     31.1 0.1
#>                          geometry
#> 1  MULTIPOLYGON (((-109.0502 3...
#> 2  MULTIPOLYGON (((-65.23805 1...
#> 3  MULTIPOLYGON (((-118.6044 3...
#> 4  MULTIPOLYGON (((-88.05338 3...
#> 5  MULTIPOLYGON (((-81.27939 3...
#> 6  MULTIPOLYGON (((-94.61792 3...
#> 7  MULTIPOLYGON (((-123.6647 4...
#> 8  MULTIPOLYGON (((-88.50297 3...
#> 9  MULTIPOLYGON (((-109.0603 3...
#> 10 MULTIPOLYGON (((-114.053 37...
\end{verbatim}

We can pipe this data into ggplot to make a map with the following code.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_acs}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{,}
        \AttributeTok{variables =} \StringTok{"B01002\_001"}\NormalTok{,}
        \AttributeTok{year =} \DecValTok{2020}\NormalTok{,}
        \AttributeTok{geometry =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ estimate)) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

The resulting map, seen in Figure \ref{fig:median-age-map-bad} below, is less than ideal. The problem with it is that the Aleutian Islands in Alaska cross the 180 degree line of longitude, also known as the international date line. As a result, most of Alaska is on one side of the map while a small part is on the other side. What's more, both Hawaii and Puerto Rico, both being decently far from the United States mainland and relatively small, are hard to see.

\begin{figure}
\includegraphics[width=1\linewidth]{tidycensus_files/figure-latex/median-age-map-bad-1} \caption{A hard-to-read map showing median age by state}\label{fig:median-age-map-bad}
\end{figure}

Fortunately for us, Kyle Walker has a solution. If we load the \texttt{tigris} package, we can then use the \texttt{shift\_geometry()} function to move Alaska, Hawaii, and Puerto Rico into places where they are more easily visible. We set the argument \texttt{preserve\_area} to \texttt{FALSE} so that the giant state of Alaska is shrunk while Hawaii and Puerto Rico are made larger.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tigris)}

\FunctionTok{get\_acs}\NormalTok{(}\AttributeTok{geography =} \StringTok{"state"}\NormalTok{,}
        \AttributeTok{variables =} \StringTok{"B01002\_001"}\NormalTok{,}
        \AttributeTok{year =} \DecValTok{2020}\NormalTok{,}
        \AttributeTok{geometry =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{shift\_geometry}\NormalTok{(}\AttributeTok{preserve\_area =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ estimate)) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_viridis\_c}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This lack of precision in the exact sizes of the states is more than made up for by having an easier to read map, which we can see in Figure \ref{fig:median-age-map-good}.

\begin{figure}
\includegraphics[width=1\linewidth]{tidycensus_files/figure-latex/median-age-map-good-1} \caption{An easier-to-read map showing median age by state}\label{fig:median-age-map-good}
\end{figure}

We've made a map that shows median age by state. But there's nothing to stop us from making the same map by county. Just change the \texttt{geography} argument to ``county'' and you'll get a map for all 3,000 plus counties. Chapter 2 of Kyle Walker's book \emph{Analyzing US Census Data: Methods, Maps, and Models in R} discusses the various geographies available. There are also many more arguments in both the \texttt{get\_decennial()} and \texttt{get\_acs()} functions. We've only shown a few of the most common arguments. If you want to learn more, Walker's book is a great resource.

\hypertarget{in-conclusion-tidycensus-takes-care-of-the-tedious-parts-of-working-with-census-data}{%
\section*{\texorpdfstring{In Conclusion: \texttt{tidycensus} Takes Care of the Tedious Parts of Working with Census Data}{In Conclusion: tidycensus Takes Care of the Tedious Parts of Working with Census Data}}\label{in-conclusion-tidycensus-takes-care-of-the-tedious-parts-of-working-with-census-data}}
\addcontentsline{toc}{section}{In Conclusion: \texttt{tidycensus} Takes Care of the Tedious Parts of Working with Census Data}

If you work with Census data, the \texttt{tidycensus} package is a huge timesaver. Rather than having to manually download data from the Census Bureau website, you can write R code that brings it in automatically, making it ready for analysis and reporting.

If you're looking for Census data from other countries, Chapter 12 of Walker's \emph{Analyzing US Census Data} book gives examples of packages that can help. There are R packages to bring Census data from Canada, Kenya, Mexico, Brazil, and other countries.

What all of these packages (and the \texttt{googlesheets4} package discussed in Chapter \ref{googlesheets-chapter}) have in common is that they use APIs to access data directly from its source. These packages are often referred to as ``wrapper packages'' because they wrap R code around the code needed to access data through APIs. You don't have to figure out how to access data through APIs yourself; you can just write some simple R code and the wrapper packages convert your code into the complex code needed to bring in the data. In the case of \texttt{tidycensus}, it not only brings in the data, but also transforms it into a tidy format that is easy to work with.

In talking with Kyle Walker, he nicely summarized the benefit of \texttt{tidycensus} , saying it does ``all of the tedious aspects of getting census data so that you can focus on the fun aspects.'' He continued: ``making maps is fun, analyzing data and finding out insights about your community is fun and interesting. But setting up a connector to an API or figuring out how to align columns \ldots{} it's more tedious.''

This is the benefit of working with an open source tool like R. Because it is extensible, others can create packages to do things that would take you extraordinary amounts of time to do on your own. You don't need to figure on your own out how to access the Census Bureau API by yourself. You can simply take advantage of the hours of work done by Kyle Walker and get all of the benefits of the \texttt{tidycensus} package.

\hypertarget{functions}{%
\chapter{Stop Copying and Pasting Code by Creating Your Own Functions}\label{functions}}

\url{https://twitter.com/hadleywickham/status/1574373127349575680}

\hypertarget{custom-packages}{%
\chapter{Bundle Your Functions Together in Your Own R Package}\label{custom-packages}}

\hypertarget{part-conclusion}{%
\part*{Conclusion}\label{part-conclusion}}
\addcontentsline{toc}{part}{Conclusion}

\hypertarget{come-for-the-data-stay-for-the-community}{%
\chapter{Come for the Data, Stay for the Community}\label{come-for-the-data-stay-for-the-community}}

\end{document}
