---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(tidycensus)
library(tigris)
```


# Access Up to Date Census Data with the `tidycensus` Package 

If you've ever worked with data from the United States Census Bureau, you know what a hassle it can be. The typical process involves going to the Census Bureau website, finding the data you need, downloading it, and then working with it in your data analysis tool of choice. Working with Census Bureau data in this way involves a lot of pointing and clicking, and gets very tedious over time.

That tedium is what drove Texas Christian University geographer Kyle Walker to develop a package to automate the process of bringing Census Bureau data into R. Walker had previously created a package called `tigris` to automatically bring in shape files from the Census Bureau. As he told me, "I was using `tigris` pretty heavily in my own work to bring in the spatial data, but I didn't have a seamless way to get the demographic data as well." Drawing on his experience developing `tigris`, Walker would develop the `tidycensus` package, which allows R users to bring in data from various Census Bureau datasets. With `tidycensus`, a user can write just a few lines of code and get data on, say, the median income in all counties in the United States. 

In this chapter, we'll learn how the `tidycensus` package works. We'll do this using examples from two datasets that `tidyverse` makes it possible to work with: the decennial Census and the American Community Survey. We'll also show how we can use the data from these two sources for additional analysis and to make maps by accessing geospatial and demographic data simultaneously. While this chapter focuses on data from the United States Census Bureau, the conclusion lists other R packages that access analogous data for other countries. And finally, the conclusion highlights some of the reasons why using a package like `tidycensus` can improve your workflow. 

## Using `tidycensus`

The `tidycensus` is available on CRAN so you can install it as you would most packages: with `install.packages("tidycensus")`. In order to use `tidycensus` you must get an API (application programming interface) key from the Census Bureau. This key, which is free, can be obtained by going to https://api.census.gov/data/key_signup.html and entering your details. Once you receive your API key by email, you need to put it in a place where `tidycensus` can find it. The `census_api_key()` function does this. Your best bet, after loading the `tidycensus` package, is to run the function as follows (replacing 123456789 with your actual API key, of course):

```{r}
library(tidycensus)

census_api_key("123456789", install = TRUE)
```

The `install = TRUE` argument will save your API key in your `.Renviron` file. R will look for your API key there in the future so that you don't have to enter it every time you want to use `tidycensus`. We're now ready to use `tidycensus` to access data. 

The Census Bureau puts out many datasets, several of which can be accessed using `tidycensus`. The most common datasets to access with `tidycensus` are the decennial Census and the American Community Survey (other datasets that can be accessed are discussed at https://walker-data.com/tidycensus/articles/other-datasets.html). 

### Census data

We'll start out by accessing data from the 2020 Census on the Asian population in each state. To do this, we use the `get_decennial()` function with three arguments: 

```{r eval = FALSE, echo = TRUE}
get_decennial(geography = "state", 
              variables = "P1_006N",
              year = 2020)
```

The arguments we're using here are:

- `geography`, which tells `get_decennial()` to access data at the state level. There are many other geographies, including county, tract (census tract), and more. 
- `variables` is where we choose the variables we want to access. I know that `P2_002N` is the variable name for the total Asian, but below I'll demonstrate how to identify variables you may want to use.
- `year` is where we select the year from which we want to access data. We're using data from the 2020 Census.

Running this code returns the following:

```{r}
get_decennial(geography = "state", 
              variables = "P1_006N",
              year = 2020)
```

The resulting data frame has four variables: 

- `GEOID` is the geographic identifier. Each state has one, as do all counties, census tracts, and all other geographies, which we'll soon discuss in greater depth.
- `NAME` is the name of each state.
- `variable` is the name of the variable we passed to the `get_decennial()` function.
- `value` is the numeric value for the state and variable in each row. In our case, it represents the total Asian population in each state.

Let's say we want to calculate the Asian population as a percentage of all people in each state. To do that, we'd need both the Asian population as well as the total population. How would we do this? 

#### Find variables

First, we'd need to know the variable names. I cheated a bit and looked up the variable name for Asian population without showing you how I did it. Let's backtrack so I can show you how to identify variable names. The `tidycensus` package has a function called `load_variables()` that shows us all of the variables from the decennial Census. If we run it with the argument `year` set to 2020 and `dataset` set to "pl" (pl refers to public law 94-171, which requires the Census to produce so-called redistricting summary data files every ten years).

```{r eval = FALSE, echo = TRUE}
load_variables(year = 2020, 
               dataset = "pl")
```

Running this code returns the name, label (description), and concept (category) of all variables available to us. Looking at this, we can see variable `P1_006N`. We can also see that variable `P1_001N` gives us the total population.

```{r}
load_variables(year = 2020, 
               dataset = "pl")
```

#### Use multiple variables

Now that we know which variables we need, we can use the `get_decennial()` function again. We used just one variable above, but we can run our code again with two variables. 

```{r eval = FALSE, echo = TRUE}
get_decennial(geography = "state", 
              variables = c("P1_001N", "P1_006N"),
              year = 2020) %>% 
  arrange(NAME)
```

I've added `arrange(NAME)` after `get_decennial()` so that the results are sorted by state name, allowing us to see that we have both variables for each state.

```{r}
get_decennial(geography = "state", 
              variables = c("P1_001N", "P1_006N"),
              year = 2020) %>% 
  arrange(NAME)
```

#### Name variables

Now I don't know about you, but I have trouble remembering what variable names like `P1_001N` and `P1_006N` mean. Fortunately, we can adjust our code in `get_decennial()` to give our variables more meaningful names using the following syntax:

```{r eval = FALSE, echo = TRUE}
get_decennial(geography = "state", 
              variables = c(total_population = "P1_001N", 
                            asian_population = "P1_006N"),
              year = 2020) %>% 
  arrange(NAME)
```

When we run this code, it is now much easier to remember which variables we are working with.

```{r}
get_decennial(geography = "state", 
              variables = c(total_population = "P1_001N", 
                            asian_population = "P1_006N"),
              year = 2020) %>% 
  arrange(NAME)
```

#### Calculate percentages

Let's now return to what started us down this path: calculating the Asian population in each state as a percentage of the total. To do this, we use the code from above and add a few things to it: 

1. We use `group_by(NAME)` to create one group for each state because we want to calculate the Asian population percentage in each state.
1. We use `mutate(pct = value / sum(value))` to calculate the percentage. This line takes the `value` in each row and divides it by the `total_population` and `asian_population` rows for each state.
1. We use `ungroup()` to remove the state-level grouping.
1. We use `filter(variable == "asian_population")` to only show the Asian population percentage. 

```{r echo = TRUE, eval = FALSE}
get_decennial(geography = "state", 
              variables = c(total_population = "P1_001N", 
                            asian_population = "P1_006N"),
              year = 2020) %>% 
  arrange(NAME) %>% 
  group_by(NAME) %>% 
  mutate(pct = value / sum(value)) %>% 
  ungroup() %>% 
  filter(variable == "asian_population")
```

When we run this, we see the total Asian population and the Asian population as a percentage in each state.

```{r}
get_decennial(geography = "state", 
              variables = c(total_population = "P1_001N", 
                            asian_population = "P1_006N"),
              year = 2020) %>% 
  arrange(NAME) %>% 
  group_by(NAME) %>% 
  mutate(pct = value / sum(value)) %>% 
  ungroup() %>% 
  filter(variable == "asian_population")
```

#### Use a summary variable

Kyle Walker knew that calculating summaries like this would be a common use case for `tidycensus`. So, to simplify things, he also gives us the `summary_var` argument that we can use within `get_decennial()`. Instead of putting "P1_001N" (total population) in the `variables` argument, we can instead use it with the `summary_var` argument as follows.

```{r eval = FALSE, echo = TRUE}
get_decennial(geography = "state", 
              variables = c(asian_population = "P1_006N"),
              summary_var = "P1_001N",
              year = 2020) %>% 
  arrange(NAME)
```

This returns a nearly identical data frame to what we got above, except that the total population is now a separate variable, rather than additional rows for each state.

```{r}
get_decennial(geography = "state", 
              variables = c(asian_population = "P1_006N"),
              summary_var = "P1_001N",
              year = 2020) %>% 
  arrange(NAME)
```

With our data in this new format, we can calculate the Asian population as a percentage of the whole using slightly different code.

```{r eval = FALSE, echo = TRUE}
get_decennial(geography = "state", 
              variables = c(asian_population = "P1_006N"),
              summary_var = "P1_001N",
              year = 2020) %>% 
  arrange(NAME) %>% 
  mutate(pct = value / summary_value)
```

The resulting output is nearly identical.

```{r}
get_decennial(geography = "state", 
              variables = c(asian_population = "P1_006N"),
              summary_var = "P1_001N",
              year = 2020) %>% 
  arrange(NAME) %>% 
  mutate(pct = value / summary_value)
```

How you choose to calculate summary statistics is up to you. The good thing is that `tidycensus` makes it easy to do!

### ACS data

Let's switch now to accessing data from the American Community Survey (ACS). This survey, which is conducted every year, differs from the decennial Census in two major ways:

1. It includes a wider range of questions.
1. It is given to a sample of people rather than the entire population.

Despite these differences, accessing data from the ACS is nearly identical to how we accessed Census data. Instead of `get_decennial()`, we use the function `get_acs()`, but the arguments are the same. Here I've identified a variable I'm interested in ("B01002_001", which shows median age) and am using it to get the data for each state.

```{r eval = FALSE, echo = TRUE}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020)
```

Here's what the output looks like:

```{r}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020)
```

There are two differences we can see in the `get_acs()` output compared to that from `get_decennial()`:

1. The `value` column in `get_decennial()` is now called `estimate`.
1. We have an additional column called `moe` for margin of error.

Both of these changes are because the ACS is given to a sample of the population. As a result, we don't have precise values, but rather estimates, which are extrapolations from the sample to the population as a whole. And with an estimate we also have a margin of error. In our state-level data, the margins of error are relatively low, but if you get data from smaller geographies, they tend to be higher. In cases where your margins of error are high relative to your estimates, you should interpret results with caution, as there is greater uncertainty about how well the data represents the population as a whole.

#### Pipe directly into ggplot

As we saw with Census data on the Asian population in the United States, once you access data using the `tidycensus` package, you can do whatever else you want. We calculated the Asian population as a percentage of the total above. Here we could take the data on median age and pipe it into ggplot in order to create a bar chart.

```{r eval = FALSE, echo = TRUE}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020) %>% 
  ggplot(aes(x = estimate,
             y = NAME)) +
  geom_col()
```

Figure TODO add figure number shows our bar chart.

```{r}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020) %>% 
  ggplot(aes(x = estimate,
             y = NAME)) +
  geom_col()
```

This chart is nothing special, but the fact that it takes just six lines of code to create most definitely is. 

#### Geospatial data

Kyle Walker's original motivation to build `tidycensus` came from wanting to make it easy to access demographic data, just as he had done with geospatial data in the `tigris` package. He succeeded. And one additional benefit of Walker working on both packages is that there is a tight integration between them. Using the `get_acs()` function, you can add set the `geometry` argument to `TRUE` and you will get both demographic and geospatial data.

```{r eval = FALSE, echo = TRUE}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020,
        geometry = TRUE) 
```

If we take a look at the resulting data, we can see that it has the metadata and `geometry` column of simple features objects that we saw in Chapter \@ref(maps-chapter).

```{r}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020,
        geometry = TRUE) 
```

We can pipe this data into ggplot to make a map with the following code.

```{r eval = FALSE, echo = TRUE}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020,
        geometry = TRUE) %>% 
  ggplot(aes(fill = estimate)) +
  geom_sf() +
  scale_fill_viridis_c()
```

The resulting map, seen in Figure \@ref(fig:TODO) below, is less than ideal. The problem with it is that the Aleutian Islands in Alaska cross the 180 degree line of longitude, also known as the international date line. As a result, most of Alaska is on one side of the map while a small part is on the other side. What's more, both Hawaii and Puerto Rico, being decently far from the United States mainland, are hard to see.

```{r}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020,
        geometry = TRUE) %>% 
  ggplot(aes(fill = estimate)) +
  geom_sf() +
  scale_fill_viridis_c()
```

Fortunately for us, Kyle Walker has a solution. If we load the `tigris` package, we can then use the `shift_geometry()` function to move Alaska, Hawaii, and Puerto Rico into places where they are more easily visible. We set the argument `preserve_area` to `FALSE` so that the giant state of Alaska is shrunk while Hawaii and Puerto Rico are made larger. 

```{r eval = FALSE, echo = TRUE}
library(tigris)

get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020,
        geometry = TRUE) %>% 
  shift_geometry(preserve_area = FALSE) %>% 
  ggplot(aes(fill = estimate)) +
  geom_sf() +
  scale_fill_viridis_c()
```

This lack of precision in the exact sizes of the states is more than made up for by having an easier to read map, which we can see in Figure \@ref(fig:TODO).

```{r}
get_acs(geography = "state",
        variables = "B01002_001",
        year = 2020,
        geometry = TRUE) %>% 
  shift_geometry(preserve_area = FALSE) %>% 
  ggplot(aes(fill = estimate)) +
  geom_sf() +
  scale_fill_viridis_c()
```

We've made a map that shows median age by state. But there's nothing to stop us from making the same map by county. Just change the `geography` argument to "county" and you'll get a map for all 3,000 plus counties. Chapter 2 of Kyle Walker's book *Analyzing US Census Data: Methods, Maps, and Models in R* discusses the various geographies available. There are also many more arguments in both the `get_decennial()` and `get_acs()` functions. We've only shown a few of the most common arguments. If you want to learn more, Walker's book is a great resource.

## Conclusion

If you work with Census data, the `tidycensus` package is a huge timesaver. Rather than having to manually download data from the Census Bureau website, you can write R code that brings it in automatically, making it ready for analysis and reporting. 

If you're looking for Census data from other countries, Chapter 12 of Walker's *Analyzing US Census Data* book gives examples of packages that can help. There are R packages to bring Census data from Canada, Kenya, Mexico, Brazil, and other countries. 

What all of these packages (and the `googlesheets4` package discussed in \@ref(googlesheets-chapter)) have in common is that they use APIs to access data directly from its source. These packages are often referred to as "wrapper packages" because they wrap R code around the code needed to access data through APIs. You don't have to figure out how to access data through APIs yourself; you can just write some simple R code and the wrapper packages will convert your code into the complex code needed to bring in the data. In the case of `tidycensus`, it not only brings in the data, but it also formats it into a tidy format that is easy to work with.

In talking with Kyle Walker, he nicely summarized the benefit of `tidycensus` , saying it does "all of the tedious aspects of getting census data so that you can focus on the fun aspects." He continued: "making maps is fun, analyzing data and finding out insights about your community is fun and interesting. But setting up a connector to an API or figuring out how to align columns ... it's more tedious." 

This is the benefit of working with an open source tool like R. Because it is extensible, others can create packages to do things that would take you extraordinary amounts of time to do on your own. You don't need to figure on your own out how to access the Census Bureau API. You can simply rely on the hours and hours of work done by Kyle Walker and get all of the benefits of the `tidycensus` package. 